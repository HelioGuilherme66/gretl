\chapter{Funzioni speciali in genr}
\label{chap-genr}

\section{Introduzione}
\label{genr-intro}

Il comando \verb+genr+ offre un modo flessibile per definire nuove
variabili. Il comando è documentato nella \GCR, mentre questo
capitolo offre una discussione più approfondita di alcune delle
funzioni speciali disponibili con \verb+genr+ e di alcune
particolarità del comando.

\section{Filtri per serie storiche}
\label{sec:filters}

Un tipo di funzioni speciali di \verb+genr+ consente il filtraggio delle serie
storiche. Oltre alle solite operazioni di ritardo e differenza, \app{gretl}
fornisce anche la differenza frazionaria e due filtri usati spesso in
macroeconomia per la scomposizione fra ciclo e trend: il filtro di
Hodrick--Prescott e quello passa banda di Baxter--King.

\subsection{Differenza frazionaria}
\label{sec:fracdiff}

Differenziare una serie storica per $d$ volte è un'operazione ovvia quando
$d$ è un numero intero, ma può sembrare strana quando $d$ è una frazione.
Tuttavia, questa idea ha un ben preciso fondamento matematico: si consideri la
funzione
\[
  f(z) = (1 - z)^{-d},
\]
dove $z$ e $d$ sono numeri reali. L'espansione in serie di Taylor intorno a 
$z=0$ mostra che
\[
  f(z) = 1 + dz + \frac{d (d+1)}{2} z^2 + \cdots 
\]
o, più sinteticamente,
\[
  f(z) = 1 + \sum_{i=1}^{\infty} \psi_i z^i
\]
con
\[
  \psi_k = \frac{\prod_{i=1}^{k} (d+i-1) }{k!} = \psi_{k-1} \frac{d+k-1}{k}
\]

La stessa espansione può essere usata con l'operatore ritardo, così che se
definiamo
\[
  Y_t = (1-L)^{0.5} X_t
\]
potrebbe essere considerata equivalente a
\[
Y_t = X_t - 0.5 X_{t-1} - 0.125 X_{t-2} - 0.0625 X_{t-3} - \cdots 
\]
    
In \app{gretl} questa trasformazione può essere eseguita con il comando
\begin{code}
  genr Y = fracdiff(X,0.5)
\end{code}
    
\subsection{Il filtro di Hodrick--Prescott}
\label{hodrick-prescott}

Questo filtro è utilizzabile tramite la funzione \verb+hpfilt()+, che accetta un
argomento: il nome della variabile da processare.

Una serie storica $y_t$ può essere scomposta in un trend, o componente di
crescita $g_t$ e in una componente ciclica $c_t$.  
%
\[
y_t = g_t + c_t, \quad t = 1,2,\dots,T
\]
%
Il filtro di Hodrick--Prescott effettua questa scomposizione, minimizzando
l'espressione seguente:
%
\[
    \sum_{t = 1}^T {(y_t - g_t )^2 } + \lambda \sum_{t = 2}^{T -
      1} \left((g_{t+1} - g_t) - (g_t - g_{t - 1} )\right)^2 .
\]
%
Il primo termine è la somma dei quadrati delle componenti cicliche $c_t =
y_t - g_t$. Il secondo termine è un multiplo $\lambda$ della somma dei quadrati
delle differenze seconde della componente di trend. Questo secondo termine
penalizza le variazioni nel tasso di crescita della componente di trend:
maggiore è il valore di $\lambda$, maggiore sarà la penalizzazione, e quindi più
regolare sarà la serie di trend.

Si noti che la funzione \cmd{hpfilt} in \app{gretl} produce la componente di
ciclo, $c_t$, della serie originale. Se si vuole il trend depurato, basta
sottrarre il ciclo dalla serie originale:

\begin{code}
genr ct = hpfilt(yt)
genr gt = yt - ct
\end{code}

Hodrick e Prescott (1997) suggeriscono che un valore $\lambda = 1600$ sia
ragionevole per dati trimestrali. Il valore predefinito in \app{gretl} è il
quadrato della frequenza dei dati, moltiplicato per 100 (che dà appunto 1600 per
dati trimestrali).  Il valore può essere modificato con il comando \cmd{set} sul
parametro \cmd{hp\_lambda}.  Ad esempio, \cmd{set hp\_lambda 1200}.

\subsection{Il filtro di Baxter e King}
\label{baxter-king}

Questo filtro è utilizzabile tramite la funzione \verb+bkfilt()+; anche questa
accetta come unico argomento il nome della variabile da processare.

Si consideri la rappresentazione spettrale di una serie storica $y_t$:
%	
\[ y_t = \int_{-\pi}^{\pi} e^{i\omega} \mathrm{d} Z(\omega) \]
%
Per estrarre la componente di $y_t$ che si trova tra le frequenze
$\underline{\omega}$ e $\overline{\omega}$ potremmo applicare un filtro passa
banda:
%	
\[ c^*_t = \int_{-\pi}^{\pi} F^*(\omega) e^{i\omega} \mathrm{d}
Z(\omega) \] 
%
dove $F^*(\omega) = 1$ per $\underline{\omega} < |\omega| <
\overline{\omega}$ e 0 altrove. Ciò implicherebbe, nel dominio
temporale, applicare alla serie un filtro con un numero infinito di
coefficienti, cosa non desiderabile. Il filtro passa banda di Baxter e
King applica a $y_t$ un polinomio finito nell'operatore di ritardo
$A(L)$:
%	
\[ c_t = A(L) y_t \]
%
dove $A$($L$) è definito come
%	
\[ A(L) = \sum_{i=-k}^{k} a_i L^i \]

I coefficienti $a_i$ sono scelti in modo che $F(\omega) =
A(e^{i\omega})A(e^{-i\omega})$ sia la migliore approssimazione di
$F^*(\omega)$ per un dato $k$. Chiaramente, maggiore è $k$, migliore è
l'approssimazione, ma poiché ciò implica scartare $2k$ osservazioni, di
solito si cerca un compromesso.  Inoltre, il filtro ha altre proprietà
teoriche interessanti, tra cui quella che $a(1) = 0$, quindi una serie
con una sola radice unitaria è resa stazionaria dall'applicazione del
filtro.

In pratica, il filtro è usato di solito con dati mensili o trimestrali
per estrarne la componente di ``ciclo economico'', ossia la componente
tra 6 e 36 trimestri. I valori usuali per $k$ sono 8 o 12 (o forse di
più per serie mensili).  I valori predefiniti per i limiti di
frequenza sono 8 e 32, mentre il valore predefinito per l'ordine di
approssimazione, $k$, è 8.  È possibile impostare questi valori usando
il comando \cmd{set}.  La parola chiave per impostare i limiti di
frequenza è \verb+bkbp_limits+, mentre quella per $k$ è \verb+bkbp_k+.
Quindi ad esempio, se si stanno usando dati mensili e si vuole
impostare i limiti di frequenza tra 18 e 96, e $k$ a 24, si può
eseguire

\begin{code}
    set bkbp_limits 18 96
    set bkbp_k 24
\end{code}

Questi valori resteranno in vigore per le chiamate alla funzione
\verb+bkfilt+ finché non saranno modificati da un altro uso di
\verb+set+.

\section{Dati panel}
\label{panel-genr}

\subsection{Variabili dummy}
\label{dummies}

In uno studio panel, può nascere l'esigenza di costruire delle
variabili dummy di uno dei seguenti tipi: (a) dummy che identificano
ciascuna delle unità cross-section, o (b) dummy che identificano
ciascuno dei periodi. Il primo tipo può essere usato per
permettere all'intercetta della regressione di variare tra le unità
cross-section, il secondo per permettere all'intercetta di variare tra
i periodi.

Per creare questo tipo di dummy, è possibile usare le due funzioni
speciali del menù \textsf{Aggiungi}, o del comando testuale \cmd{genr}.

\begin{enumerate}
\item ``Dummy per unità'' (comando testuale \cmd{genr unitdum}).
  Questo comando crea un insieme di variabili dummy che identificano
  le unità cross section.  La variabile \verb+du_1+ avrà valore 1 in
  ogni riga dei dati che corrisponde a un'osservazione della prima
  unità cross section, e 0 altrove; \verb+du_2+ avrà valore 1 in ogni
  riga dei dati che corrisponde a un'osservazione della seconda unità
  cross section, e così via.
        
\item ``Dummy temporali'' (comando testuale \cmd{genr timedum}).
  Questo comando crea un insieme di variabili dummy che identificano
  i periodi.  La variabile \verb+dt_1+ avrà valore 1 in ogni riga dei dati che
  corrisponde a un'osservazione del primo periodo, e 0 altrove; \verb+dt_2+ avrà
  valore 1 in ogni riga dei dati che corrisponde a un'osservazione del secondo
  periodo, e così via.

\end{enumerate}

Se un dataset panel contiene l'anno di ogni osservazione all'interno
della variabile \verb+ANNO+, è possibile creare una dummy periodica
per un anno particolare, ad esempio con \cmd{genr dum = (ANNO=1960)}.
È anche possibile creare variabili dummy periodiche usando l'operatore
modulo, \verb+%+.  Ad esempio, per creare una dummy che
valga 1 ogni trenta osservazioni a partire dalla prima e 0 altrove,
basta eseguire
%
\begin{code}
    genr index 
    genr dum = ((index-1)%30) = 0
\end{code}



\subsection{Ritardi, differenze, trend}
\label{panel-lagged}

Se i periodi temporali sono distanziati in modo uniforme, è possibile
usare valori ritardati delle variabili in una regressione panel (ma si
veda la sezione~\ref{panel-dyn}; è anche possibile costruire
differenze prime delle variabili.

Se un dataset è identificato correttamente come panel,  \app{gretl}
gestirà correttamente la generazione di questo tipo di variabili. Ad
esempio, il comando \verb+genr x1_1 = x1(-1)+ creerà una variabile che
contiene il primo ritardo di \verb+x1+, laddove è disponibile, e il
codice di valore mancante, laddove il ritardo non è disponibile (ad esempio
nella prima osservazione per ogni gruppo).  Quando si esegue una regressione che
include questo tipo di variabili, il programma escluderà automaticamente le
osservazioni mancanti.

Quando un dataset panel ha una dimensione temporale sostanziale, può essere
utile includere un trend nell'analisi. Il comando \cmd{genr time} 
crea una variabile di nome \varname{time} che assume valori compresi tra 1 e $T$
per ogni unità, dove $T$ è la lunghezza della dimensione temporale del panel.
Per creare un indice che assuma valori compresi tra 1 e $m\times T$, dove $m$
è il numero di unità nel panel, si usi invece \cmd{genr index}.

\subsection{Statistiche descrittive per unità}
\label{panel-stats}

Le funzioni \texttt{pmean()} e \texttt{psd()} possono essere usate per generare
semplici statistiche descrittive (media e deviazione standard) per una data
variabile, calcolate per gruppo.

Supponendo di avere un dataset panel che comprende 8 osservazioni temporali per
ciascuna di $N$ unità o gruppi. Il comando
%
\begin{code}
    genr pmx = pmean(x)
\end{code}
%
crea una serie di questo tipo: i primi 8 valori (che corrispondono all'unità 1)
contengono la media di \varname{x} per l'unità 1, i successivi 8 valori
contengono la media per l'unità 2 e così via. La funzione \texttt{psd()}
funziona in modo simile. La deviazione standard campionaria per il gruppo
$i$ è calcolata come
\[
s_i = \sqrt{\frac{\sum(x-\bar{x}_i)^2}{T_i-1}}
\]
dove $T_i$ denota il numero di osservazioni valide su \varname{x}
per l'unità data, $\bar{x}_i$ denota la media di gruppo, e la somma viene fatta
su tutte le osservazioni valide per il gruppo. Se però vale $T_i < 2$,
la deviazione standard viene impostata pari a 0.

È interessante notare un uso particolare di \texttt{psd()}: se si vuole formare
un sotto-campione di un panel che contenga solo quelle unità per cui la
variabile \varname{x} varia nel tempo, si può eseguire
%
\begin{code}
    smpl (psd(x) > 0) --restrict
\end{code}

\subsection{Funzioni speciali per manipolare i dati}
\label{panel-manip}

Oltre alle funzioni discusse sopra, ci sono alcune opzioni di \texttt{genr}
particolarmente utili per manipolare i dati panel, soprattutto quando i dati
sono stati importati da una fonte esterna e non sono nella forma corretta per
l'analisi panel. Queste funzionalità sono spiegate nel Capitolo~\ref{datafiles}.


\section{Ricampionamento e bootstrapping}
\label{genr-resample}

Un'altra funzione particolare è il ricampionamento, con reimmissione,
di una serie. Data una serie di dati originale \varname{x}, il comando
%
\begin{code}
    genr xr = resample(x)
\end{code}
%
crea una nuova serie in cui ognuno degli elementi è estratto in modo casuale
dagli elementi di \varname{x}. Se la serie originale ha 100 osservazioni, ogni
elemento di \varname{x} è scelto con probabilità $1/100$ ad ogni estrazione.
L'effetto è quindi di ``rimescolare'' gli elementi di \varname{x}, con la
particolarità che ogni elemento di \varname{x} può apparire più di una volta, o
non apparire affatto, in \varname{xr}.

L'uso principale di questa funzione è la costruzione di intervalli di confidenza
o p-value con il metodo bootstrap. Ecco un semplice esempio: si supponga di aver
stimato una semplice regressione OLS di $y$ su $x$ e di aver trovato che il
coefficiente della pendenza abbia un rapporto $t$ pari a 2.5 con 40 gradi di
libertà.  Il p-value a due code per l'ipotesi nulla che il parametro della
pendenza sia pari a zero vale quindi 0.0166, usando la distribuzione $t(40)$. A
seconda del contesto, però, potremmo dubitare del fatto che il rapporto tra il
coefficiente e l'errore standard segua veramente una distribuzione $t(40)$. In
questo caso, potremmo derivare un valore bootstrap per il p-value come mostrato
nell'esempio~\ref{resampling-loop}.  

Sotto l'ipotesi nulla che la pendenza rispetto a $x$ sia pari a zero,
$y$ è uguale alla sua media più un termine di errore. Simuliamo $y$
ricampionando i residui del modello OLS iniziale e ri-stimiamo il modello.
Ripetiamo questa procedura un gran numero di volte e registriamo il numero di
casi in cui il valore assoluto del rapporto $t$ è maggiore di 2.5: la
proporzione di questo numero di casi è il nostro valore bootstrap per il
p-value. Per una buona discussione dei test basati sulla simulazione e sui
metodi bootstrap, si veda Davidson e MacKinnon (2004, capitolo 4).

\begin{script}[htbp]
  \caption{Calcolo del p-value col metodo bootstrap}
  \label{resampling-loop}
\begin{code}
    ols y 0 x
    # salva i residui
    genr ui = $uhat
    scalar ybar = mean(y)
    # numero delle replicazioni per il bootstrap
    scalar replics = 10000
    scalar tcount = 0
    series ysim = 0
    loop replics --quiet
      # genera i valori simulati di y ricampionando
      ysim = ybar + resample(ui)
      ols ysim 0 x
      scalar tsim = abs($coeff(x) / $stderr(x))
      tcount += (tsim > 2.5)
    endloop      
    printf "Proporzione dei casi con |t| > 2.5 = %g\n", \
       tcount / replics
\end{code}
\end{script}
   

\section{Densità cumulate e p-value}
\label{genr-cdf}

Le due funzioni \cmd{cdf} e \cmd{pvalue} forniscono strumenti complementari per
esaminare i valori di varie distribuzioni di probabilità: la normale standard,
la $t$ di Student, la $\chi^2$, la $F$, la gamma, e la binomiale.
La sintassi di queste funzioni è spiegata nella \GCR; in questa sede viene
presentato un aspetto particolare riguardante la precisione dei risultati.

La funzione di ripartizione, o di densità cumulata (CDF), per una variabile
casuale è l'integrale della densità della variabile, dal suo limite inferiore
(tipicamente $-\infty$ o 0) fino a un certo valore $x$. Il p-value (almeno il
p-value destro, a una coda, fornito dalla funzione \cmd{pvalue}) è la
probabilità complementare, l'integrale da $x$ al limite superiore della
distribuzione, tipicamente $+\infty$.  

In linea di principio non c'è bisogno di due funzioni distinte: dato un valore
della funzione di ripartizione $p_0$ è possibile ricavare facilmente il p-value
come $1-p_0$ (o viceversa).  In pratica, poiché il computer usa aritmetica a
precisione finita, due funzioni non sono ridondanti. In \app{gretl}, come nella
maggior parte dei programmi statistici, i numeri a virgola mobile sono
rappresentati tramite dei ``double'' --- valori a precisione doppia, che sono
tipicamente memorizzati in 8 byte, o 64 bit. Visto che il numero di bit
disponibili è fisso, i numeri in virgola mobile che possono essere rappresentati
sono limitati: \textit{i ``double'' non modellano esattamente la retta reale}.
Tipicamente, i ``double'' possono rappresentare numeri che stanno all'incirca
nell'intervallo $\pm 1.7977 \times 10^{308}$, ma con circa solo 15 cifre di
precisione.

Supponiamo di essere interessati alla coda sinistra della distribuzione $\chi^2$
con 50 gradi di libertà, ossia di voler conoscere il valore della CDF per $x =
0.9$.  Vediamo la seguente sessione interattiva:
\begin{code}
  ? genr p1 = cdf(X, 50, 0.9)
  Generato lo scalare p1 (ID 2) = 8.94977e-35
  ? genr p2 = pvalue(X, 50, 0.9)
  Generato lo scalare p2 (ID 3) = 1
  ? genr test = 1 - p2
  Generato lo scalare test (ID 4) = 0
\end{code}

La funzione \cmd{cdf} ha prodotto un valore accurato, ma la funzione
\cmd{pvalue} ha dato come risultato 1, da cui non è possibile ricavare il valore
della CDF. Questo può sembrare sorprendente, ma si spiega considerando che se il
valore di \texttt{p1} è corretto, il valore corretto di \texttt{p2} è $1 -
8.94977 \times 10^{-35}$, ma non c'è modo di rappresentare questo valore con un
``double'': richiederebbe oltre 30 cifre di precisione.

Ovviamente questo è un esempio estremo. Se il valore di $x$ in questione non si
trova alle estremità di una delle due code della distribuzione, le funzioni
\cmd{cdf} e \cmd{pvalue} produrranno risultati complementari, come si vede da
questo esempio:
\begin{code}
  ? genr p1 = cdf(X, 50, 30)
  Generato lo scalare p1 (ID 2) = 0.0111648
  ? genr p2 = pvalue(X, 50, 30)
  Generato lo scalare p2 (ID 3) = 0.988835
  ? genr test = 1 - p2
  Generato lo scalare test (ID 4) = 0.0111648
\end{code}
La morale è che se occorre esaminare valori estremi, occorre scegliere
attentamente la funzione da usare, tenendo presente che valori molto vicini allo
zero possono essere rappresentati con ``double'', mentre valori molto vicini a 1
possono non esserlo.

\section{Gestione dei valori mancanti}
\label{genr-missing}

Sono disponibili quattro funzioni speciali per gestire i valori
mancanti.  La funzione booleana \verb+missing()+ richiede come unico
argomento il nome di una variabile e produce una serie con valore 1
per ogni osservazione in cui la variabile indicata ha un valore
mancante, 0 altrove (ossia dove la variabile indicata ha un valore
valido). La funzione \verb+ok()+ è il complemento di \verb+missing+,
ossia una scorciatoia per \verb+!missing+ (dove \verb+!+ è l'operatore
booleano NOT).  Ad esempio, è possibile contare i valori mancanti
della variabile \verb+x+ usando

\begin{code}
    genr nmanc_x = sum(missing(x))
\end{code}

La funzione \verb+zeromiss()+, che richiede anch'essa come unico
argomento il nome di una serie, produce una serie in cui tutti i
valori zero sono trasformati in valori mancanti. Occorre usarla con
attenzione (di solito non bisogna confondere valori mancanti col
valore zero), ma può essere utile in alcuni casi: ad esempio, è
possibile determinare la prima osservazione valida di una variabile
\verb+x+ usando

\begin{code}
    genr time
    genr x0 = min(zeromiss(time * ok(x)))
\end{code}


La funzione \verb+misszero()+ compie l'operazione opposta di
\verb+zeromiss+, ossia converte tutti i valori mancanti in zero.  

Può essere utile chiarire la propagazione dei valori mancanti
all'interno delle formule di \verb+genr+. La regola generale è che
nelle operazioni aritmetiche che coinvolgono due variabili, se una
delle variabili ha un valore mancante in corrispondenza
dell'osservazione $t$, anche la serie risultante avrà un valore
mancante in $t$. L'unica eccezione a questa regola è la
moltiplicazione per zero: zero moltiplicato per un valore mancante
produce sempre zero (visto che matematicamente il risultato è zero a
prescindere dal valore dell'altro fattore).
    

\section{Recupero di variabili interne}
\label{genr-internal}

Il comando \verb+genr+ fornisce un modo per recuperare vari valori
calcolati dal programma nel corso della stima dei modelli o della
verifica di ipotesi. Le variabili che possono essere richiamate in
questo modo sono elencate nella \GCR; qui ci occupiamo in particolare
delle variabili speciali \verb+$test+ e \verb+$pvalue+.

Queste variabili contengono, rispettivamente, il valore dell'ultima
statistica test calcolata durante l'ultimo uso esplicito di un comando
di test e il p-value per quella statistica test. Se non è stato
eseguito alcun comando di test, le variabili contengono il codice di
valore mancante. I ``comandi espliciti di test'' che funzionano in
questo modo sono i seguenti: \cmd{add} (test congiunto per la
significatività di variabili aggiunte a un modello); \cmd{adf} (test
di Dickey--Fuller aumentato, si veda oltre); \cmd{arch} (test per
ARCH); \cmd{chow} (test Chow per break strutturale); \cmd{coeffsum}
(test per la somma dei coefficienti specificati); \cmd{cusum}
(statistica \emph{t} di Harvey--Collier); \cmd{kpss} (test di
stazionarietà KPSS, p-value non disponibile); \cmd{lmtest} (si veda
oltre); \cmd{meantest} (test per la differenza delle medie);
\cmd{omit} (test congiunto per la significatività delle variabili
omesse da un modello); \cmd{reset} (test RESET di Ramsey);
\cmd{restrict} (vincolo lineare generale); \cmd{runs} (test delle
successioni per la casualità); \cmd{testuhat} (test per la normalità
dei residui) e \cmd{vartest} (test per la differenza delle varianze).
Nella maggior parte dei casi, vengono salvati valori sia in
\verb+$test+ che in \verb+$pvalue+; l'eccezione è il test KPSS, per
cui non è disponibile il p-value.
    
Un punto da tenere in considerazione a questo proposito è che le
variabili interne \verb+$test+ e \verb+$pvalue+ vengono sovrascritte
ogni volta che viene eseguito uno dei test elencati sopra. Se si
intende referenziare questi valori durante una sequenza di comandi
\app{gretl}, occorre farlo nel momento giusto.
    
Un'altra questione è data dal fatto che alcuni dei comandi di test di
solito generano più di una statistica test e più di un p-value: in questi casi
vengono salvati solo gli ultimi valori. Per controllare in modo
preciso quali valori vengono recuperati da \verb+$test+ e
\verb+$pvalue+ occorre formulare il comando di test in modo che il
risultato non sia ambiguo. Questa nota vale in particolare per i
comandi \verb+adf+ e \verb+lmtest+.

\begin{itemize}
\item Di solito, il comando \cmd{adf} genera tre varianti del test
  Dickey--Fuller: una basata su una regressione che include una
  costante, una che include costante e trend lineare, e una che
  include costante e trend quadratico. Se si intende estrarre valori
  da \verb+$test+ o \verb+$pvalue+ dopo aver usato questo comando, è
  possibile selezionare la variante per cui verranno salvati i valori,
  usando una delle opzioni \verb+--nc+, \verb+--c+, \verb+--ct+ o
  \verb+--ctt+ con il comando \verb+adf+.
\item Di solito, il comando \cmd{lmtest} (che deve seguire una
  regressione OLS) esegue vari test diagnostici sulla regressione in
  questione. Per controllare cosa viene salvato in \verb+$test+ e
  \verb+$pvalue+ occorre limitare il test usando una delle opzioni
  \verb+--logs+, \verb+--autocorr+, \verb+--squares+ 
  o \verb+--white+.
\end{itemize}

Un aspetto comodo per l'uso dei valori immagazzinati in \verb+$test+ e
\verb+$pvalue+ è dato dal fatto che il tipo di test a cui si
riferiscono questi valori viene scritto nell'etichetta descrittiva
della variabile generata. Per controllare di aver recuperato il valore
corretto, è possibile leggere l'etichetta con il comando \cmd{label}
(il cui unico argomento è il nome della variabile). La seguente
sessione interattiva illustra la procedura.
    
\begin{code}
    ? adf 4 x1 --c

    Test Dickey-Fuller aumentati, ordine 4, per x1
    ampiezza campionaria 59
    ipotesi nulla di radice unitaria: a = 1

      test con costante
      modello: (1 - L)y = b0 + (a-1)*y(-1) + ... + e
      valore stimato di (a - 1): -0.216889
      statistica test: t = -1.83491
      p-value asintotico 0.3638

    P-value basati su MacKinnon (JAE, 1996)
    ? genr pv = $pvalue
    Generato lo scalare pv (ID 13) = 0.363844
    ? label pv    
      pv=Dickey-Fuller pvalue (scalar)
\end{code}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide-it"
%%% End: 

