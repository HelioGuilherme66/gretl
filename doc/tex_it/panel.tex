\chapter{Dati panel}
\label{chap-panel}

\section{Struttura panel}
\label{panel-structure}

I dati panel possono essere visti sotto tre dimensioni, ossia le
variabili, le unità cross-section e i periodi temporali.  Per
rappresentarli in un file testuale (e anche per poterli manipolare),
queste tre dimensioni devono in qualche modo essere riportate a due.
Questa procedura di ``appiattimento'' richiede di prendere degli
``strati'' di dati che apparterrebbero alla terza dimensione e di
impilarli nella dimensione verticale del file.

\app{Gretl} si aspetta sempre di trovare dati organizzati ``per
osservazione'', ossia in modo che ogni riga rappresenti un'osservazione
(e che ogni variabile occupi esattamente una colonna). Alla luce di
questo fatto, l'appiattimento dei dati panel può essere realizzato in
due modi:
\begin{itemize}
\item Pila di dati cross section: ognuno dei blocchi di dati disposti
  verticalmente contiene i valori per tutte le unità cross-section
  (longitudinali) in un determinato periodo.
\item Pila di serie storiche: ognuno dei blocchi di dati disposti
  verticalmente contiene serie storiche per una determinata unità
  cross-section.
\end{itemize}

È possibile usare entrambi i metodi per inserire i dati. Internamente,
\app{gretl} usa il formato ``pila di serie storiche'' per immagazzinare i dati.

Quando si importano dati panel in \app{gretl} da un foglio di calcolo o
da un file con valori separati da virgole, la struttura panel non verrà
riconosciuta automaticamente (molto probabilmente i dati verranno
trattati come ``non datati'').  Per imporre un'interpretazione panel ai
dati, è possibile procedere in due modi.
    
\begin{enumerate}
\item Usando il comando dell'interfaccia grafica ``Campione, Struttura
  dataset''. Nella prima finestra di dialogo occorre selezionare
  ``Panel''; in quella successiva, occorre indicare se i dati sono
  organizzati sotto forma di pila di serie storiche o di dati cross
  section.  Nella finestra di dialogo successiva occorre indicare il
  numero di unità cross section nel dataset, infine è possibile
  controllare se la specificazione dei dati mostrata è corretta e
  confermare l'operazione.
        
\item Usando il comando testuale \cmd{setobs}. Per i dati panel, la
  sintassi del comando è \verb+setobs+ \textsl{freq} \verb+1:1+ struttura, dove
  \textsl{freq} indica la ``dimensione dei blocchi'' di dati (ossia, il numero
  di periodi nel caso delle pile di serie storiche, o il numero di
  unità cross section nel caso di pila di dati cross section), mentre
  struttura può essere uguale a \verb+--stacked-time-series+ o
  \verb+--stacked-cross-section+. Di seguito vengono mostrati due
  esempi: il primo per un dataset panel sotto forma di pila di serie
  storiche con osservazioni per 20 periodi, il secondo per un dataset
  panel sotto forma di pila di dati cross section, con 5 unità cross
  section.
\begin{code}
            setobs 20 1:1 --stacked-time-series
            setobs 5 1:1 --stacked-cross-section
\end{code}
\end{enumerate}

\subsection{Dati panel organizzati per variabile}

Talvolta i dati panel disponibili pubblicamente sono organizzati ``per variabile''.
Si supponga di avere dati per due variabili, \varname{x1} e \varname{x2},
relativi a 50 stati per 5 anni (per un totale di 250 osservazioni per
variabile). Una possibile rappresentazione testuale dei dati potrebbe iniziare
con un blocco per \varname{x1}, con 50 righe, corrispondenti agli stati e 5
colonne, corrispondenti agli anni. Seguirebbe, sotto, un blocco con una
struttura simile, relativo alla variabile \varname{x2}. Viene mostrato di seguito
un frammento di questo file di dati, con osservazioni quinquennali per il
periodo 1965--1985; occorre immaginare che la tabella continui per altri 48
stati, seguita da altre 50 righe per la variabile \varname{x2}.

\begin{center}
  \begin{tabular}{rrrrrr}
  \varname{x1} \\
     & 1965 & 1970 & 1975 & 1980 & 1985 \\
  AR & 100.0 & 110.5 & 118.7 & 131.2 & 160.4\\
  AZ & 100.0 & 104.3 & 113.8 & 120.9 & 140.6\\
  \end{tabular}
\end{center}

Se un tale file di dati viene importato in \app{gretl}, il programma
interpreterà le colonne come variabili diverse, rendendo inutilizzabili i dati.
Esiste però un meccanismo per gestire queste situazioni, ossia la funzione
\cmd{stack} del comando \cmd{genr}.

Si consideri la prima colonna di dati nel frammento visto sopra: le prime 50
righe di questa colonna costituiscono una cross-section per la variabile
\varname{x1} nell'anno 1965. Se potessimo creare una nuova variabile sistemando
le prime 50 voci nella seconda colonna direttamente sotto le prime 50 voci della
prima colonna, staremmo costruendo un dataset disposto ``per osservazione'' (nel
primo dei due sensi definiti in precedenza: una pila di dati cross-section).
Ossia, avremmo una colonna che contiene una cross-section per \varname{x1} nel
1965, seguita da una cross-section per la stessa variabile nel 1970.

Il seguente script di gretl illustra come possiamo effettuare l'operazione, per
\varname{x1} e \varname{x2}. Assumiamo che il file di dati originale si chiami
\texttt{panel.txt} e che le colonne al suo interno siano precedute da
intestazioni con i ``nomi variabile'' \varname{p1}, \varname{p2}, \dots, \varname{p5}
(le colonne non sono vere variabili, ma per il momento ``facciamo finta'' che lo
siano).

\begin{code}
    open panel.txt
    genr x1 = stack(p1..p5) --length=50
    genr x2 = stack(p1..p5) --offset=50 --length=50
    setobs 50 1.01 --stacked-cross-section
    store panel.gdt x1 x2
\end{code}

La seconda riga illustra la sintassi della funzione \cmd{stack}.
Il doppio punto nella parentesi indica un intervallo di variabili da impilare:
vogliamo impilare tutte le 5 colonne (per tutti i 5 anni). Il dataset completo
contiene 100 righe: per sistemare la variabile \varname{x1} vogliamo leggere solo
le prime 50 righe di ogni colonna: facciamo questo aggiungendo l'opzione
\verb+--length=50+. Si noti che se occorre impilare un insieme di colonne non
contigue, è possibile usare un elenco separato da virgole all'interno della
parentesi, come in

\begin{code}
    genr x = stack(p1,p3,p5)
\end{code}

Nella riga 3 creiamo una pila di dati per la variabile \varname{x2}.  Ancora,
vogliamo una lunghezza (\texttt{length}) di 50 per i componenti della serie
impilata, ma questa volta vogliamo che gretl inizi a leggere dalla cinquantesima
riga dei dati originali, quindi specifichiamo \verb+--offset=50+.

La riga 4 impone un'interpretazione panel sui dati, come spiegato nella
sezione~\ref{panel-structure}. Infine, salviamo i dati in formato gretl, con
un'interpretazione panel, eliminando le ``variabili'' originali da \varname{p1}
a \varname{p5}.

Lo script di esempio visto sopra è approprioato quando il numero delle variabili
da processare è piccolo. Quando ci sono molte variabili nel dataset, è più
efficiente usare un comando loop per costruire le nuove variabili, come mostrato
nell'esempio seguente, che ipotizza una situazione uguale a quella precedente
(50 unità, 5 periodi) ma con 20 variabili invece che 2.

\begin{code}
    open panel.txt
    loop for i=1..20
      genr k = ($i - 1) * 50
      genr x$i = stack(p1..p5) --offset=k --length=50
    endloop
    setobs 50 1.01 --stacked-cross-section
    store panel.gdt x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 \
      x11 x12 x13 x14 x15 x16 x17 x18 x19 x20
\end{code}


\section{Variabili generate}
\label{panel-genr}

\subsection{Variabili dummy}
\label{dummies}

In uno studio panel, può nascere l'esigenza di costruire delle
variabili dummy di uno dei seguenti tipi: (a) dummy che identificano
ciascuna delle unità cross-section, o (b) dummy che identificano
ciascuno dei periodi. Il primo tipo può essere usato per
permettere all'intercetta della regressione di variare tra le unità
cross-section, il secondo per permettere all'intercetta di variare tra
i periodi.

Per creare questo tipo di dummy, è possibile usare le due funzioni
speciali del menù \textsf{Dati, Aggiungi variabile}, o del comando
testuale \cmd{genr}.

\begin{enumerate}
\item ``Dummy per unità'' (comando testuale \cmd{genr unitdum}).
  Questo comando crea un insieme di variabili dummy che identificano
  le unità cross section.  La variabile \verb+du_1+ avrà valore 1 in
  ogni riga dei dati che corrisponde a un'osservazione della prima
  unità cross section, e 0 altrove; \verb+du_2+ avrà valore 1 in ogni
  riga dei dati che corrisponde a un'osservazione della seconda unità
  cross section, e così via.
        
\item ``Dummy temporali'' (comando testuale \cmd{genr timedum}).
  Questo comando crea un insieme di variabili dummy che identificano
  i periodi.  La variabile \verb+dt_1+ avrà valore 1 in ogni riga dei dati che
  corrisponde a un'osservazione del primo periodo, e 0 altrove; \verb+dt_2+ avrà
  valore 1 in ogni riga dei dati che corrisponde a un'osservazione del secondo
  periodo, e così via.

\end{enumerate}

Se un dataset panel contiene l'anno di ogni osservazione all'interno
della variabile \verb+ANNO+, è possibile creare una dummy periodica
per un anno particolare, ad esempio con \cmd{genr dum = (ANNO=1960)}.
È anche possibile creare variabili dummy periodiche usando l'operatore
modulo, \verb+%+.  Ad esempio, per creare una dummy che
valga 1 ogni trenta osservazioni a partire dalla prima e 0 altrove,
basta eseguire
\begin{code}
      genr index 
      genr dum = ((index-1)%30) = 0
\end{code}



\subsection{Ritardi e differenze}
\label{panel-lagged}

Se i periodi temporali sono distanziati in modo uniforme, è possibile
usare valori ritardati delle variabili in una regressione panel, come
anche costruire differenze prime delle variabili.

Se un dataset è identificato correttamente come panel,  \app{gretl}
gestirà correttamente la generazione di questo tipo di variabili. Ad
esempio, il comando \verb+genr x1_1 = x1(-1)+ creerà una variabile che
contiene il primo ritardo di \verb+x1+, laddove è disponibile, e il
codice di valore mancante, laddove il ritardo non è disponibile.  Quanto
si esegue una regressione che include questo tipo di variabili, il
programma escluderà automaticamente le osservazioni mancanti.

\section{Stima di modelli panel}

\subsection{Stima pooled OLS}
\label{pooled-est}

Lo stimatore più semplice per i dati panel è quello ``pooled OLS'' (ossia i
minimi quadrati ordinari utilizzando allo stesso modo tutte le osservazioni del
campione). In genere questo stimatore non fornisce risultati ottimali, ma
rappresenta un metro di paragone per stimatori più complessi.

Quando si stima un modello usando i minimi quadrati ordinari (OLS) su dati
panel, è disponibile un tipo di test aggiuntivo: nel menù \textsf{Test} della
finestra del modello è il comando ``Diagnosi panel'', mentre nella versione a
riga di comando del programma è il comando \cmd{hausman}.

Per eseguire questo test, occorre specificare un modello senza alcuna variabile
dummy relativa alle unità cross-section. Il test confronta il semplice modello
OLS con le due principali alternative: il modello a effetti fissi e quello a
effetti casuali.

Il modello a \emph{effetti fissi} sopprime la costante e aggiunge una variabile
dummy per tutte le unità cross section, permettendo così all'intercetta della
regressione di variare per ogni unità.  Viene eseguito un test \emph{F} per
testare l'ipotesi nulla che l'intercetta sia uguale per tutte le
unità: un basso p-value per questo test depone contro l'ipotesi nulla e a favore
dell'adeguatezza del modello a effetti fissi.

Il modello a \emph{effetti casuali}, d'altra parte, scompone la varianza dei
residui in due parti: una specifica all'unità cross section, o
``gruppo'', e una specifica all'osservazione particolare (la stima può
essere eseguita solo se il panel è abbastanza ``largo'', ossia se il
numero delle unità cross section nel dataset è maggiore del numero dei
parametri da stimare).  La statistica LM di Breusch--Pagan testa
l'ipotesi nulla che il modello pooled OLS sia adeguato, rispetto all'alternativo
modello a effetti casuali.

Può accadere che il modello pooled OLS sia rifiutato nei confronti di
entrambe le alternative, a effetti fissi o casuali. Come giudicare
quindi l'adeguatezza relativa dei due metodi alternativi di stima? Il
test di Hausman (i cui risultati sono mostrati a patto che il modello
a effetti casuali possa essere stimato) cerca di risolvere questo
problema.  A patto che gli errori specifici di unità o di gruppo siano
non correlati con le variabili indipendenti, lo stimatore a effetti
casuali è più efficiente dello stimatore a effetti fissi; nel caso
contrario lo stimatore a effetti casuali non è consistente e deve
essergli preferito lo stimatore a effetti fissi.  L'ipotesi nulla per
il test di Hausman è che l'errore specifico di gruppo non sia
correlato con le variabili indipendenti (e quindi che il modello a
effetti casuali sia preferibile). Un basso p-value per questo test
suggerisce di rifiutare il modello a effetti casuali in favore del
modello a effetti fissi.  

Per una discussione rigorosa di questo argomento, si veda il capitolo
14 di Greene (2000).
 
\section{I modelli a effetti fissi e casuali}
\label{panel-est}

La specificazione ``pooled OLS'' si può scrivere come
\[
y_{it} = X_{it}\beta + u_{it}
\]
dove $y_{it}$ è l'osservazione della variabile dipendente per l'unità cross
section $i$ nel periodo $t$, $X_{it}$ è un vettore $1\times k$ di variabili
indipendenti osservate per l'unità $i$ nel periodo $t$,
$\beta$ è un vettore $k\times 1$ di parametri, e $u_{it}$ è un termine di errore
o di disturbo specifico all'unità $i$ nel periodo $t$.

I modelli a effetti fissi e casuali rappresentano due modi di scomporre l'errore
unitario $u_{it}$.  Per il modello a effetti fissi possiamo scrivere
\[
u_{it} = \alpha_i + \varepsilon_{it}
\]
Ossia, scomponiamo $u_{it}$ in una componente specifica all'unità e invariante
nel tempo, $\alpha_i$, e un errore specifico all'osservazione,
$\varepsilon_{it}$.  Gli $\alpha_i$ sono quindi trattati come parametri fissi
(intercette $y$ specifiche per le unità) da stimare. Questo può essere fatto
includendo una variabile dummy per ogni unità cross section (e sopprimendo la
costante comune), oppure è possibile procedere sottraendo le medie di gruppo da
ognuna delle variabili e stimando un modello senza costante. Nell'ultimo caso la
variabile dipendente si può scrivere come
\[
\tilde{y}_{it} = y_{it} - \frac{1}{T_i} \sum_{t=1}^{T_i} y_{it}
\]
dove $T_i$ è il numero di osservazioni per l'unità $i$; in modo simile si
possono riscrivere le variabili indipendenti. È possibile ottenere stime degli
$\alpha_i$ usando
\[
\hat{\alpha}_i = \frac{1}{T_i} \sum_{t=1}^{T_i} 
   \left(y_{it} - X_{it}\hat{\beta}\right)
\]

Questi due metodi sono numericamente equivalenti, e \app{gretl} sceglie tra i
due a seconda del numero di unità cross section e di variabili indipendenti
(cercando di minimizzare l'uso delle memoria).

Per il modello a effetti casuali possiamo scrivere
\[
u_{it} = v_i + \varepsilon_{it}
\]
Invece di trattare gli $v_i$ come parametri fissi, li trattiamo come estrazioni
casuali da una certa distribuzione di probabilità. Per stimare questo modello
occorre per prima cosa fare un inferenza a proposito delle rispettive varianze
di $v_i$ e $\varepsilon_{it}$. La varianza di $v_i$, $\sigma^2_v$, è di solito
chiamata la varianza ``between'' (esterna, visto che si riferisce alla
variazione tra le unità cross section), mentre $\sigma^2_{\varepsilon}$ è
chiamata varianza ``within'' (interna).

\section{Esempio: la Penn World Table}
\label{PWT}

La Penn World Table (homepage a
\href{http://pwt.econ.upenn.edu/}{pwt.econ.upenn.edu}) è un ricco
dataset panel macroeconomico, che comprende 152 paesi sull'arco
temporale 1950--1992. I dati sono disponibili in formato \app{gretl}:
si veda la
\href{http://gretl.sourceforge.net/gretl_data_it.html}{pagina dei
  dati} di \app{gretl} (i dati sono liberamente scaricabili, anche se
non sono distribuiti nel pacchetto principale di
\app{gretl}).

L'esempio \ref{examp-pwt} apre il file
\verb+pwt56_60_89.gdt+, un sottoinsieme della Penn World Table che
contiene dati per 120 paesi negli anni 1960--89, su 20 variabili,
senza osservazioni mancanti (il dataset completo, anch'esso compreso
nel pacchetto pwt per \app{gretl}, contiene molte osservazioni
mancanti). Viene calcolata la crescita del PIL reale sul periodo
1960--89 per ogni paese, e viene regredita sul livello del PIL reale
dell'anno 1960, per analizzare l'ipotesi della ``convergenza'' (ossia
di una crescita più veloce da parte dei paesi che partono da una
situazione peggiore).

\begin{script}[htbp]
  \caption{Uso della Penn World Table}
  \label{examp-pwt}

\begin{code}
          open pwt56_60_89.gdt 
          # Per l'anno 1989 (l'ultima oss.) il ritardo 29 dà 1960, la prima oss. 
          genr gdp60 = RGDPL(-29) 
          # Calcola la crescita totale del PIL reale sui 30 anni
          genr gdpgro = (RGDPL - gdp60)/gdp60
          # Restringi il campione a una cross-section del 1989
          smpl --restrict YEAR=1989 
          # convergenza: i paesi che partono più indietro crescono di più?
          ols gdpgro const gdp60 
          # risultato: no! Proviamo una relazione inversa?
          genr gdp60inv = 1/gdp60 
          ols gdpgro const gdp60inv 
          # Ancora no. Proviamo a trattare l'Africa in modo speciale? 
          genr afdum = (CCODE = 1)
          genr afslope = afdum * gdp60 
          ols gdpgro const afdum gdp60 afslope 
\end{code}

\end{script}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide-it"
%%% End: 

