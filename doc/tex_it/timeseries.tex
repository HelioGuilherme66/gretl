\chapter{Modelli per serie storiche}
\label{chap:timeser}

\section{Modelli ARIMA}
\label{arma-estimation}

\subsection{Rappresentazione e sintassi}
\label{arma-repr}

Il comando \cmd{arma} effettua la stima di modelli autoregressivi a media mobile
(ARMA); la rappresentazione più generale di un modello ARMA stimabile con \app{gretl}
è la seguente:
\begin{equation}
  \label{eq:general-arma}
  A(L) B(L^s) y_t = x_t \beta + C(L) D(L^s) \epsilon_t ,
\end{equation}
dove $L$ è l'operatore di ritardo ($L^n x_t = x_{t-n}$), $s$ è il numero di
sotto-periodi per le serie stagionali (ad esempio, 12 per serie mensili),
$x_t$ è un vettore di variabili esogene, e $\epsilon_t$ è un processo a
rumore bianco.

Il modello ARMA ``basilare'' si ottiene quando vale $x_t = 1$ e non ci sono
operatori stagionali. In questo caso, $B(L^s) = D(L^s) = 1$ e il modello diventa
\begin{equation}
  \label{eq:plain-arma}
  A(L) y_t = \mu + C(L) \epsilon_t ,
\end{equation}
dove, nella solita notazione, il vettore $\beta$ si riduce all'intercetta $\mu$.
È possibile scrivere l'equazione precedente in modo più esplicito come
\[
  y_t = \mu + \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + 
  \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q
  \epsilon_{t-q}
\]
La sintassi corrispondente in \app{gretl} è semplicemente
\begin{code}
  gretl p q ; y
\end{code}
dove \verb|p| e \verb|q| sono gli ordini di ritardo desiderati; questi possono
essere sia numeri, sia scalari pre-definiti. Il parametro $\mu$ può essere
omesso se necessario, aggiungendo l'opzione \cmd{--nc} al comando.

Se si vuole stimare un modello con variabili esplicative, la sintassi vista
sopra può essere estesa in questo modo
\begin{code}
  gretl p q ; y const x1 x2
\end{code}
Questo comando stimerebbe il seguente modello:
\[
  y_t = \beta_0 + x_{1,t} \beta_1 + x_{2,t} \beta_2 + 
  \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + 
  \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q} .
\]
Quello che \app{gretl} stima in questo caso è un modello ARMAX (ARMA +
variabili esogene), che è diverso da ciò che alcuni altri programmi chiamano
``modello di regressione con errori ARMA''. La differenza è evidente
considerando il modello stimato da \app{gretl}
\begin{equation}
  \label{eq:armax}
  A(L) y_t = x_t \beta + C(L) \epsilon_t ,
\end{equation}
e un modello di regressione con errori ARMA, ossia
\begin{eqnarray}
  \label{eq:reg-arma}
  y_t & = & x_t \beta + u_t \\
  A(L) u_t & = & C(L) \epsilon_t ;
\end{eqnarray}
l'ultimo si tradurrebbe nell'espressione seguente
\[
  A(L) y_t = A(L) \left(x_t \beta \right) + C(L) \epsilon_t ;
\]
la formulazione ARMAX ha il vantaggio che il coefficiente $\beta$
può essere interpretato immediatamente come l'effetto marginale delle
variabili $x_t$ sulla media condizionale di $y_t$. Si noti comunque, che
i modelli di regressione che contengono errori puramente autoregressivi
possono essere stimati (sebbene non con tecniche di massima verosimiglianza) con
altri comandi di \app{gretl}, come \cmd{corc} e \cmd{pwe}.

Il comando \cmd{arma} può quindi essere usato anche per stimare \emph{Modelli a
funzione di trasferimento}, un tipo di generalizzazione dei modelli autoregressivi
a media mobile (ARMA) che aggiunge l'effetto di variabili esogene distribuite
nel tempo, come in questo esempio:
\begin{equation}
  \label{eq:tfunc-model}
  \phi (L) \cdot \Phi (L^s) y_t = \sum_{i=1}^kv_{i}(L)x_{it} + \theta (L)\cdot \Theta (L^s) \epsilon_t ,
\end{equation}

La struttura del comando \cmd{arma} non permette di specificare modelli con
buchi nella struttura dei ritardi. Una struttura di ritardi più flessibile
può essere necessaria quando si analizzano serie che mostrano un marcato
andamento stagionale. In questo caso è possibile usare il modello completo
(\ref{eq:general-arma}). Ad esempio, la sintassi
\begin{code}
  arma 1 1 ; 1 1 ; y
\end{code}
permette di stimare un modello con quattro parametri:
\[
  ( 1 - \phi L )  ( 1 - \Phi L^s ) y_t = \mu + ( 1 + \theta L ) ( 1 + \Theta L^s ) \epsilon_t;
\]
assumendo che $y_t$ è una serie trimestrale (e quindi $s=4$), l'equazione
precedente può essere scritta in modo più esplicito come
\[
  y_t = \mu + \phi y_{t-1} + \Phi y_{t-4} - (\phi \cdot \Phi) y_{t-5} + 
  \epsilon_t + \theta \epsilon_{t-1} + \Theta \epsilon_{t-4} +
  (\theta \cdot \Theta) \epsilon_{t-5} .
\]

Un tale modello è di solito chiamato un ``modello ARMA stagionale
moltiplicativo''.

Per modelli più generali questa limitazione può essere aggirata per quanto
riguarda la parte autoregressiva, includendo ritardi della variabile dipendente
nella lista delle variabili esogene.

Ad esempio, il comando seguente
\begin{code}
  arma 0 0 ; 0 1 ; y const y(-2)
\end{code}
su una serie trimestrale stimerebbe i parametri del modello
\[
  y_t = \mu + \phi y_{t-2} + \epsilon_t + \Theta \epsilon_{t-4}.
\]
Questo modo di procedere però non è consigliato: anche se si ottengono stime
corrette, la funzionalità di previsione risulterà inutilizzabile.

La discussione svolta presuppone che la serie storica $y_t$ sia già stata
soggetta a tutte le trasformazioni necessarie per assicurarne la stazionarietà
(si veda anche il capitolo \ref{sec:uroot}).  La trasformazione più usata in
questi casi è la differenziazione, quindi \app{gretl} fornisce un meccanismo per
includere questo passo nel comando \cmd{arma}: la sintassi
\begin{code}
  arma p d q ; y 
\end{code}
stimerebbe un modello ARMA(p,q) su $\Delta^d y_t$ ed è equivalente a
\begin{code}
  series tmp = y
  loop for i=1..d
    tmp = diff(tmp)
  end loop
  arma p q ; tmp 
\end{code}
Un tale modello è noto come ARIMA (autoregressivo integrato a media mobile); per
questo motivo \app{gretl} fornisce anche il comando \cmd{arima} come sinonimo di
\cmd{arma}. L'operazione di differenziazione stagionale viene gestita in modo
simile, con la sintassi
\begin{code}
  arma p d q ; P D Q ; y 
\end{code}
Così, il comando
\begin{code}
  arma 1 0 0 ; 1 1 1 ; y 
\end{code}
produce gli stessi risultati di
\begin{code}
  genr dsy = sdiff(y)
  arma 1 0 ; 1 1 ; dsy 
\end{code}

\subsection{Stima}
\label{arma-est}

L'algoritmo usato da \app{gretl} per stimare i parametri di un modello ARMA è
quello della massima verosimiglianza condizionale (CML), noto anche come ``somma
dei quadrati condizionale'' (si veda Hamilton 1994,
pagina 132).  Questo metodo è esemplificato nello script \ref{jack-arma}, quindi
ne verrà data solo una breve descrizione qui: dato un campione di ampiezza
$T$, il metodo CML minimizza la somma dei quadrati degli errori delle previsioni
generate dal modello per l'osservazione successiva, sull'intervallo $t_0,
\ldots, T$. Il punto di partenza $t_0$ dipende dall'ordine dei polinomi AR del
modello.

Questo metodo è quasi equivalente a quello della massima verosimiglianza in
ipotesi di normalità; la differenza sta nel fatto che le prime $(t_0 - 1)$
osservazioni sono considerate fisse ed entrano nella funzione di verosimiglianza
solo come variabili condizionanti. Di conseguenza, i due metodi sono
asintoticamente equivalenti sotto le consuete ipotesi.

Il metodo numerico usato per massimizzare la log-verosimiglianza è quello BHHH.
La matrice di covarianza per i parametri (e quindi gli errori standard) sono
calcolati col metodo del prodotto esterno dei gradienti (OPG, Outer Product of
the Gradients).

La stima di massima verosimiglianza vera e propria in ipotesi di normalità è
disponibile in \app{gretl} attraverso il plugin \verb|x-12|, che viene usato
automaticamente se si aggiunge l'opzione \verb|--x-12-arima| al comando
\cmd{arma}. Ad esempio, il codice seguente
\begin{code}
  open data10-1
  arma 1 1 ; r
  arma 1 1 ; r --x-12-arima
\end{code}
produce le stime mostrate nella tabella~\ref{tab:cml-ml}.

\begin{table}[htbp]
\caption{Stime CML e ML}
\label{tab:cml-ml}
\begin{center}
  \begin{tabular}{crrrr}
    \hline
    Parametro & \multicolumn{2}{c}{CML} &
    \multicolumn{2}{c}{ML (\app{X-12-ARIMA} plugin)} \\
    \hline 
    $\mu$ & 1.07322 & (0.488661) &  1.00232 & (0.133002) \\
    $\phi$ & 0.852772 & (0.0450252) & 0.855373  & (0.0496304) \\
    $\theta$ & 0.591838 & (0.0456662) & 0.587986 & (0.0799962) \\
    \hline
  \end{tabular}
\end{center}
\end{table}

Per confrontabilità con le stime di \app{gretl}, è possibile impostare
\app{X-12-ARIMA} per produrre le stime CML aggiungendo l'opzione
\verb|--conditional| oltre a \verb|--x-12-arima|.

\subsection{Previsione}
\label{arma-fcast}

To be written

\section{Unit root tests}
\label{sec:uroot}

To be completed

\subsection{The ADF test}
\label{sec:ADFtest}

Il test ADF (Augmented Dickey-Fuller) è implementanto in \app{gretl} sotto forma
della statistica $t$ su $\varphi$ nella regressione seguente:
\begin{equation}
  \label{eq:ADFtest}
  \Delta y_t = \mu_t + \varphi y_{t-1} + \sum_{i=1}^p \gamma_i \Delta
  y_{t-i} + \epsilon_t .
\end{equation}

Questa statistica test è probabilmente il più famoso e utilizzato test per
radici unitarie. È un test a una coda la cui ipotesi nulla è
$\varphi = 0$, mentre quella alternativa è $\varphi < 0$. Sotto l'ipotesi nulla,
$y_t$ deve essere differenziata almeno una volta per raggiungere la
stazionarietà. Sotto l'ipotesi alternativa, $y_t$ è già stazionaria e non
richiede differenziazione. Quindi, grandi valori negativi della statistica test
portano a rifiutare l'ipotesi nulla.

Un aspetto peculiare di questo test è che la sua distribuzion limite non è
standard sotto l'ipotesi nulla: inoltre, la forma della distribuzione, e quindi
i valori critici per il test, dipendono dalla forma del termine
$\mu_t$. Un'eccellente analisi di tutti i casi possibili è contenuta in
Hamilton (1994), ma il soggetto è trattato anche in qualsiasi testo recente
sulle serie storiche. Per quanto riguarda \app{gretl}, esso permette all'utente
di scegliere la specificazione di $\mu_t$ tra quanttro alternative:

\begin{center}
  \begin{tabular}{cc}
    \hline
    $\mu_t$ & Opzione del comando \\
    \hline
    0 & \verb|--nc| \\
    $\mu_0$ &  \verb|--c| \\
    $\mu_0 + \mu_1 t$ &  \verb|--ct| \\
    $\mu_0 + \mu_1 t + \mu_1 t^2$ &  \verb|--ctt| \\
    \hline
  \end{tabular}
\end{center}

Queste opzioni non sono mutualmente esclusive e possono essere usate insieme; in
questo caso, la statistica verrà calcolata separatamente per ognuno dei casi.
La scelta predefinita in \app{gretl} è quella di usare la combinazione
\verb|--c --ct --ctt|. Per ognuno dei casi, vengono calcolati p-value
approssimativi usando l'algoritmo descritto in MacKinnon 1996.

Il comando di \app{gretl} da usare per eseguire il test è \cmd{adf}; ad esempio
\begin{code}
  adf 4 x1 --c --ct
\end{code}
calcola la statistica test come statistica-t per $\varphi$ nell'equazione
\ref{eq:ADFtest} con $p=4$ nei due casi $\mu_t = \mu_0$ e
$\mu_t = \mu_0 + \mu_1 t$.

Il numero di ritardi ($p$ nell'equazione \ref{eq:ADFtest}) deve essere scelto
per assicurarsi che (\ref{eq:ADFtest}) sia una parametrizzazione abbastanza
flessibile per rappresentare adeguatamente la persistenza di breve termine di
$\Delta y_t$. Scegliere un $p$ troppo basso può portare a distorsioni di
dimensione nel test, mentre sceglierlo troppo alto porta a una perdita di
potenza del test. Per comodità dell'utente, il parametro $p$ può essere
determinato automaticamente. Impostando $p$ a un numero negativo viene attivata
una procedura sequenziale che parte da $p$ ritardi e decrementa $p$ fino a quando la statistica $t$
per il parametro $\gamma_p$ supera 1.645 in valore assoluto.

\subsection{The KPSS test}
\label{sec:KPSStest}

\begin{equation}
  \label{eq:KPSStest}
  \eta = \frac{\sum_{i=1}^T S_t^2 }{ T^2 \bar{\sigma}^2 }
\end{equation}
where $S_t = \sum_{s=1}^t e_s$ and $\bar{\sigma}^2$ is an
estimate of the long-run variance of $e_t = (y_t - \bar{y})$.
\begin{itemize}
\item $H_0$: $y_t$ is I(0);
\item one-sided test: $H_0$ is rejected if $\eta$ is ``big'';
\item extension to deterministic trend ($e_t$ are the residuals from
  an OLS regression of $y_t$ on a constant and a linear trend);
\item nonstandard distribution --- we provide 90\%, 95\%, 97.5\% and
  99\% quantiles.
\end{itemize}
Syntax:
\begin{code}
  kpss n x1
\end{code}
\begin{itemize}
\item \verb|--trend| option;
\item \verb|n| is used for estimating $\bar{\sigma}^2$; in the GUI,
  default is the integer part of $4 \left( \frac{T}{100}
  \right)^{1/4}$.
\end{itemize}

\subsection{I test di Johansen}
\label{sec:Joh-test}

In senso stretto, questi sono test per la cointegrazione, ma possono essere
usati anche come test multivariati per radici unitarie, visto che sono la
generalizzazione multivariata del test ADF.
\begin{equation}
  \label{eq:Joh-tests}
  \Delta y_t = \mu_t + \Pi y_{t-1} + \sum_{i=1}^p \Gamma_i \Delta
  y_{t-i} + \epsilon_t
\end{equation}
Se il rango di $\Pi$ è 0, i processi sono tutti I(1); se il rango di
$\Pi$ è pieno, i processi sono tutti I(0); nei casi intermedi, si ha
cointegrazione.

Il rango di $\Pi$ viene analizzato calcolando gli autovalori di una matrice ad
essa strettamente legata (chiamata $M$) che ha rango pari a quello di $\Pi$:
i test sul rango di $\Pi$ possono quindi essere condotti verificando quanti
autovalori di $M$ sono pari a 0. I due test di Johansen sono i test
``$\lambda$-max'', per le ipotesi sui singoli autovalori, e il test
``trace'', per le ipotesi congiunte.

Il comando \cmd{coint2} di \app{gretl} esegue questi due test.
Esempio:
\begin{code}
  coint2 n x1 x2 x3
\end{code}
imposta $p$ nell'equazione (\ref{eq:Joh-tests}) a $(n-1)$ e mostra una tabella
con le due batterie di test per le tre serie \verb|x1|, \verb|x2| e \verb|x3|.
 
\ldots Options for the deterministic kernel \ldots
More on this in section \ref{sec:johansen-test}

\section{ARCH e GARCH}
\label{sec:arch}

Il fenomeno dell'eteroschedasticità rappresenta la varianza non costante del
termine di errore in un modello di regressione. L'eteroschedasticità
condizionale autoregressiva (ARCH) è un fenomeno specifico dei modelli per serie
storiche, in cui la varianza del termine di errore presenta un comportamento
autoregressivo, ad esempio, la serie presenta periodi in cui la varianza
dell'errore è relativamente ampia e periodi in cui è relativamente piccola.

Un modello GARCH può essere descritto brevemente dalle equazioni seguenti:
\begin{eqnarray}
  \label{eq:garch-meaneq}
  y_t &  = & x_t \beta + \epsilon_t \\
  \label{eq:garch-epseq}
  \epsilon_t &  = & u_t \sigma_t \\
  \label{eq:garch-vareq}
  A(L) \sigma^2_t &  = & \omega + B(L) \epsilon_{t-1}^2 ,
\end{eqnarray}
dove $u_t$ è una sequenza iid con varianza unitaria. Al momento
\app{gretl} gestisce solo modelli in cui $u_t$ è ipotizzato essere un
rumore bianco gaussiano. In ogni caso, l'opzione \verb|--robust| calcola la
matrice di covarianza dei parametri usando lo stimatore
``sandwich'' di Bollerslev-Wooldridge, quindi le stime prodotte da
\app{gretl} possono essere considerate QML anche con disturbi non normali.

Esempio:
\begin{code}
  garch p q ; y const x
\end{code}
dove \verb|p| è il grado (non negativo) di $A(L)$ e \verb|q| è il grado
(strettamente positivo) di $B(L)$.

\section{Cointegrazione e modelli vettoriali a correzione d'errore}
\label{vecm-explanation}

\subsection{Il test di cointegrazione di Johansen}
\label{sec:johansen-test}

Il test di Johansen per la cointegrazione deve tenere conto di quali
ipotesi vengono fatte a proposito dei termini deterministici, per cui
si possono individuare i ben noti ``cinque casi''. Una presentazione
approfondita dei cinque casi richiede una certa quantità di algebra
matriciale, ma è possibile dare un'intuizione del problema per mezzo
di un semplice esempio.
    
Si consideri una serie $x_t$ che si comporta nel modo seguente
%      
\[ x_t = m + x_{t-1} + \varepsilon_t \]
%
dove $m$ è un numero reale e $\varepsilon_t$ è un processo ``white
noise''.  Come si può facilmente mostrare, $x_t$ è un ``random walk''
che fluttua intorno a un trend deterministico con pendenza $m$. Nel
caso particolare in cui $m$ = 0, il trend deterministico scompare e
$x_t$ è un puro random walk.
    
Si consideri ora un altro processo $y_t$, definito da
%      
\[ y_t = k + x_t + u_t \]
%
dove, ancora, $k$ è un numero reale e $u_t$ è un processo white noise.
Poiché $u_t$ è stazionario per definizione, $x_t$ e $y_t$ sono
cointegrate, ossia la loro differenza
%      
\[ z_t = y_t - x_t = k + u_t \]
%	
è un processo stazionario. Per $k$ = 0, $z_t$ è un semplice white
noise a media zero, mentre per $k$ $\ne$ 0 il processo $z_t$ è white
noise con media diversa da zero.
  
Dopo alcune semplici sostituzioni, le due equazioni precedenti possono
essere rappresentate congiuntamente come un sistema VAR(1)
%      
\[ \left[ \begin{array}{c} y_t \\ x_t \end{array} \right] = \left[
  \begin{array}{c} k + m \\ m \end{array} \right] + \left[
  \begin{array}{rr} 0 & 1 \\ 0 & 1 \end{array} \right] \left[
  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \left[
  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array}
\right] \]
%	
o in forma VECM
%      
\begin{eqnarray*}
  \left[  \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{rr} -1 & 1 \\ 0 & 0 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{r} -1 \\ 0 \end{array} \right]
  \left[  \begin{array}{rr} 1 & -1 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = &
  \mu_0 + \alpha \beta^{\prime} \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \eta_t = 
  \mu_0 + \alpha z_{t-1} + \eta_t ,
\end{eqnarray*}
%	
dove $\beta$ è il vettore di cointegrazione e $\alpha$ è il vettore
dei ``loading'' o ``aggiustamenti''.
     
Possiamo ora considerare tre casi possibili:
    
\begin{enumerate}
\item $m \ne 0$: In questo caso $x_t$ ha un trend, come abbiamo appena
  visto; ne consegue che anche $y_t$ segue un trend lineare perché in
  media si mantiene a una distanza di $k$ da $x_t$.  Il vettore
  $\mu_0$ non ha restrizioni. Questo è il caso predefinito per il
  comando \cmd{vecm} di gretl.
	
\item $m = 0$ e $k \ne 0$: In questo caso, $x_t$ non ha un trend, e di
  conseguenza neanche $y_t$.  Tuttavia, la distanza media tra $y_t$ e
  $x_t$ è diversa da zero. Il vettore $\mu_0$ è dato da
%	  
  \[
  \mu_0 = \left[ \begin{array}{c} k \\ 0 \end{array} \right]
  \]
%	    
  che è non nullo, quindi il VECM mostrato sopra ha un termine
  costante.  La costante, tuttavia è soggetta alla restrizione che il
  suo secondo elemento deve essere pari a 0. Più in generale,
  $\mu$\ensuremath{_{0}} è un multiplo del vettore $\alpha$. Si noti
  che il VECM potrebbe essere scritto anche come
%	  
  \[
  \left[ \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]
  = \left[ \begin{array}{r} -1 \\ 0 \end{array} \right] \left[
    \begin{array}{rrr} 1 & -1 & -k \end{array} \right] \left[
    \begin{array}{c} y_{t-1} \\ x_{t-1} \\ 1 \end{array} \right] +
  \left[ \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t
    \end{array} \right]
  \]
%	   
  che incorpora l'intercetta nel vettore di cointegrazione. Questo è
  il caso di ``costante vincolata''; può essere specificato nel
  comando \cmd{vecm} di gretl usando l'opzione \verb+--rc+.
	
\item $m = 0$ e $k = 0$: Questo caso è il più vincolante: chiaramente,
  né $x_t$ né $y_t$ hanno un trend, e la loro distanza media è zero.
  Anche il vettore $\mu_0$ vale 0, quindi questo caso può essere
  chiamato ``senza costante''.  Questo caso è specificato usando
  l'opzione \verb+--nc+ con \cmd{vecm}.
	
\end{enumerate}


Nella maggior parte dei casi, la scelta tra le tre possibilità si basa
su un misto di osservazione empirica e di ragionamento economico. Se
le variabili in esame sembrano seguire un trend lineare, è opportuno
non imporre alcun vincolo all'intercetta. Altrimenti occorre chiedersi
se ha senso specificare una relazione di cointegrazione che includa
un'intercetta diversa da zero. Un esempio appropriato potrebbe essere
la relazione tra due tassi di interesse: in generale questi non hanno
un trend, ma il VAR potrebbe comunque avere un'intercetta perché la
differenza tra i due (lo ``spread'' sui tassi d'interesse) potrebbe
essere stazionaria attorno a una media diversa da zero (ad esempio per
un premio di liquidità o di rischio).
    
L'esempio precedente può essere generalizzato in tre direzioni:
    
\begin{enumerate}
\item Se si considera un VAR di ordine maggiore di 1, l'algebra si
  complica, ma le conclusioni sono identiche.
\item Se il VAR include più di due variabili endogene, il rango di
  cointegrazione $r$ può essere maggiore di 1. In questo caso $\alpha$
  è una matrice con $r$ colonne e il caso con la costante vincolata
  comporta che $\mu_0$ sia una combinazione lineare delle colonne di
  $\alpha$.
\item Se si include un trend lineare nel modello, la parte
  deterministica del VAR diventa $\mu_0$ + $\mu_1$. Il ragionamento è
  praticamente quello visto sopra, tranne per il fatto che
  l'attenzione è ora posta su $\mu_1$ invece che su $\mu_0$. La
  controparte del caso con ``costante vincolata'' discusso sopra è un
  caso con ``trend vincolato'', così che le relazioni di
  cointegrazione includono un trend, ma la differenza prima delle
  variabili in questione no. Nel caso di un trend non vincolato, il
  trend appare sia nelle relazioni di cointegrazione sia nelle
  differenze prime, il che corrisponde alla presenza di un trend
  quadratico nelle variabili (espresse in livelli). Questi due casi
  sono specificati rispettivamente con le opzioni \verb+--crt+ e
  \verb+--ct+ del comando \cmd{vecm}.
\end{enumerate}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide-it"
%%% End: 

