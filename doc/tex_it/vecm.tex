\chapter{Cointegrazione e modelli vettoriali a correzione d'errore}
\label{chap:vecm}

\section{Introduzione}
\label{sec:VECM-intro}

I concetti correlati di cointegrazione e correzione d'errore sono stati al
centro della ricerca in macroeconometria negli ultimi anni. L'aspetto
interessante del Modello Vettoriale a Correzione di Errore (VECM) consiste nel
fatto che permette al ricercatore di inserire una rappresentazione di relazioni
di equilibrio economico in una specificazione abbastanza ricca basata sulle
serie storiche. Questo approccio supera l'antica dicotomia tra i modelli
strutturali, che rappresentavano fedelmente la teoria macroeconomica ma non si
adattavano ai dati, e l'analisi delle serie storiche, che era più precisa nel
riprodurre l'andamento dei dati, ma di difficile, se non impossibile,
interpretazione in termini di teoria economica.

L'idea basilare della cointegrazione è strettamente collegata al concetto di
radici unitarie (si veda la sezione~\ref{sec:uroot}).  Si supponga di avere un
insieme di variabili macroeconomiche di interesse, e di non poter rifiutare
l'ipotesi che alcune di queste variabili, considerate individualmente, siano
non-stazionarie. In particolare, si supponga che un sottoinsieme di queste
variabili siano individualmente integrate di ordine 1, o I(1), ossia che non
siano stazionarie, ma che la loro differenza prima sia stazionaria. Dati i
problemi di tipo statistico che sono associati all'analisi dei dati non
stazionari (ad esempio il problema della regressione spuria), l'approccio
tradizionale in questo caso consiste nel prendere la differenza prima delle
variabili prima di procedere con l'analisi statistica.

In questo modo però, si perde informazione importante. Può darsi che mentre le
variabili sono I(1) prese singolarmente, esista una loro combinazione lineare
che sia invece stazionaria, ossia I(0) (potrebbe esserci anche più di una
combinazione lineare). In altri termini, mentre l'insieme delle variabili è
libero di muoversi nel tempo, esistono comunque delle relazioni che legano fra
di loro le variabili; è possibile interpretare queste relazioni, o
\emph{vettori di cointegrazione} come condizioni di equilibrio.

Ad esempio, ipotizziamo di scoprire che la quantità di moneta, $M$, il livello
dei prezzi, $P$, il tasso di interesse nominale, $R$, e l'output, $Y$, siano
tutti I(1). Secondo la teoria standard della domanda di moneta, dovremmo
comunque aspettarci una relazione di equilibrio tra la quantità di moneta reale,
il tasso d'interesse e l'output; ad esempio
\[
m - p = \gamma_0 + \gamma_1 y + \gamma_2 r \qquad \gamma_1 > 0,
\gamma_2 < 0
\]
dove le variabili in minuscolo indicano i logaritmi. In equilibrio si ha quindi
\[
m - p - \gamma_1 y - \gamma_2 r = \gamma_0
\]
Nella realtà non ci si aspetta che questa condizione sia soddisfatta in ogni
periodo, ma occorre ammettere la possibilità di disequilibri di breve periodo.
Ma se il sistema ritorna all'equilibrio dopo un disturbo, ne consegue che
il vettore $x = (m, p, y, r)'$ è limitato da un vettore di cointegrazione
$\beta' = (\beta_1, \beta_2, \beta_3, \beta_4)$, tale che $\beta'x$ è
stazionario (con una media pari a $\gamma_0$). Inoltre, se l'equilibrio è
caratterizzato correttamente dal semplice modello visto sopra, si ha $\beta_2 =
-\beta_1$, $\beta_3 < 0$ e $\beta_4 > 0$. Queste proprietà sono testabili
attraverso l'analisi di cointegrazione.

Questa analisi consiste tipicamente in tre passi:
\begin{enumerate}
\item Test per verificare il numero di vettori di cointegrazione, ossia il 
  \emph{rango di cointegrazione} del sistema.
\item Stima di un VECM di rango appropriato, non soggetto ad altre restrizioni.
\item Test dell'interpretazione dei vettori di cointegrazione come condizioni di
  equilibrio, usando le restrizioni sugli elementi di questi vettori.
\end{enumerate}

Le sezioni seguenti approfondiscono ognuno dei passi, aggiungendo altre
considerazioni econometriche e spiegando come implementare l'analisi usando
\app{gretl}.

\section{Modelli vettoriali a correzione di errore (VECM) come rappresentazione di
un sistema cointegrato}
\label{sec:VECM-rep}

Si consideri un VAR di ordine $p$ con una parte deterministica data da $\mu_t$
(tipicamente un polinomio nel tempo). È possibile scrivere il processo
$n$-variato $y_t$ come
\begin{equation}
  \label{eq:VECM-VAR}
  y_t = \mu_t + A_1 y_{t-1} + A_2 y_{t-2} + \cdots + A_p y_{t-p} +
  \epsilon_t 
\end{equation}
Ma poiché $y_t \equiv y_{t-1} - \Delta y_t$ e $y_{t-i} \equiv
y_{t-1} - (\Delta y_{t-1} + \Delta y_{t-2} + \cdots + \Delta
y_{t-i+1})$, è possibile riscrivere l'equazione nel modo seguente:
\begin{equation}
  \label{eq:VECM}
  \Delta y_t = \mu_t + \Pi y_{t-1} + \sum_{i=1}^{p-1} \Gamma_i \Delta
  y_{t-i} + \epsilon_t ,
\end{equation}
dove $\Pi = \sum_{i=1}^p A_i$ e $\Gamma_k = -\sum_{i=k}^p A_i$.
Questa è la rappresentazione VECM della (\ref{eq:VECM-VAR}).

L'interpretazione della (\ref{eq:VECM}) dipende in modo cruciale da $r$, il
rango della matrice $\Pi$.
\begin{itemize}
\item Se $r = 0$, i processi sono tutti I(1).
\item Se $r = n$, $\Pi$ è invertibile e i processi sono tutti I(0).
\item La cointegrazione accade in tutti i casi intermedi, quando
  $0 < r < n$ e $\Pi$ può essere scritta come $\alpha \beta'$. In 
  questo caso, $y_t$ è I(1), ma la combinazione $z_t = \beta'y_t$ è I(0).
  Se, ad esempio, $r=1$ e il primo elemento di $\beta$ fosse $-1$, si
  potrebbe scrivere $z_t = -y_{1,t} + \beta_2 y_{2,t} + \cdots + \beta_n y_{n,t}$,
  che è equivalente a dire che
  \[
    y_{1_t} = \beta_2 y_{2,t} + \cdots + \beta_n y_{n,t} - z_t
  \]
  è una relazione di equilibrio di lungo periodo: le deviazioni
  $z_t$ possono non essere pari a zero, ma sono stazionarie. In questo caso,
  la (\ref{eq:VECM}) può essere scritta come
  \begin{equation}
    \label{eq:VECMab}
    \Delta y_t = \mu_t + \alpha \beta' y_{t-1} + \sum_{i=1}^{p-1} \Gamma_i 
    \Delta y_{t-i} + \epsilon_t ,
  \end{equation}
  e la stima viene effettuata simultaneamente su tutti i parametri.
  D'altra parte è utile notare che se $\beta$ fosse noto, $z_t$ sarebbe
  osservabile e tutti i restanti parametri potrebbero essere stimati con OLS. In
  pratica, la procedura stima per prima cosa $\beta$ e tutto il resto poi.
\end{itemize}

Il rango di $\Pi$ viene analizzato calcolando gli autovalori di una matrice ad
essa strettamente legata che ha rango pari a quello di $\Pi$, ma che per
costruzione è simmetrica e semidefinita positiva. Di conseguenza, tutti i suoi
autovalori sono reali e non negativi e i test sul rango di $\Pi$ possono quindi
essere condotti verificando quanti autovalori sono pari a 0.

Se tutti gli autovalori sono significativamente diversi da 0, tutti i processi
sono stazionari. Se, al contrario, c'è almeno un autovalore pari a 0, allora
il processo $y_t$ è integrato, anche se qualche combinazione lineare $\beta'y_t$
potrebbe essere stazionaria. All'estremo opposto, se non ci sono autovalori
significativamente diversi da 0, non solo il processo $y_t$ è non-stazionario,
ma vale lo stesso per qualsiasi combinazione lineare $\beta'y_t$; in altre
parole non c'è alcuna cointegrazione.

La stima procede tipicamente in due passi: per prima cosa si esegue una serie di
test per determinare $r$, il rango di cointegrazione. Quindi, per un certo rango
vengono stimati i parametri dell'equazione (\ref{eq:VECMab}). I due comandi
offerti da \app{gretl} per compiere queste operazioni sono rispettivamente
\texttt{coint2} e \texttt{vecm}.

La sintassi di \texttt{coint2} è
\begin{code}
  coint2 p ylist [ ; xlist ]
\end{code}
dove \texttt{p} è il numero di ritardi nella (\ref{eq:VECM-VAR}),
\texttt{ylist} è una lista che contiene le variabili $y_t$, e
\texttt{xlist} è una lista opzionale di variabili esogene.

La sintassi di \texttt{vecm} è
\begin{code}
  vecm p r ylist [ ; xlist [ ; zlist ] ]
\end{code}
dove \texttt{p} è il numero di ritardi nella (\ref{eq:VECM-VAR}),
\texttt{r} è il rango di cointegrazione, \texttt{ylist} è una lista
che contiene le variabili $y_t$, \texttt{xlist} è una lista opzionale di
variabili esogene, e \texttt{zlist} è un'altra lista opzionale di variabili
esogene che si ipotizza facciano parte delle relazioni di cointegrazione.

Entrambi i comandi supportano opzioni specifiche per trattare il kernel
deterministico $\mu_t$; queste sono illustrate nella sezione seguente.

\section{Interpretazione del kernel deterministico}
\label{sec:coint-5cases}

Alcuni importanti aspetti di tipo inferenziale dei sistemi cointegrati dipendono
dalle ipotesi fatte a proposito dei termini deterministici, per cui si possono
individuare i ben noti ``cinque casi''.

Nell'equazione (\ref{eq:VECM}), il termine $\mu_t$ di solito assume la forma
seguente:
\[
  \mu_t = \mu_0 + \mu_1 \cdot t .
\]
Affinché il modello si adatti nel modo migliore alle caratteristiche dei dati,
occorre risolvere una questione preliminare. I dati sembrano seguire un trend
deterministico? In caso positivo, si tratta di un trend lineare o quadratico?

Una volta stabilito questo, bisogna imporre restrizioni coerenti su $\mu_0$
e $\mu_1$. Ad esempio, se i dati non esibiscono un trend evidente, ciò
significa che $\Delta y_t$ vale zero in media, quindi è ragionevole assumere
che anche il suo valore atteso sia zero. Scriviamo l'equazione
(\ref{eq:VECM}) come
\begin{equation}
  \label{eq:VECM-poly}
  \Gamma(L) \Delta y_t = \mu_0 + \mu_1 \cdot t + \alpha z_{t-1} +
  \epsilon_t ,
\end{equation}
dove si ipotizza che $z_{t} = \beta' y_{t}$ sia stazionario e quindi possieda
momenti finiti. Prendendo i valori attesi non condizionati, otteniamo
\[ 
  0 = \mu_0 + \mu_1 \cdot t + \alpha m_z .
\]
Visto che il termine al primo membro non dipende da $t$, il vincolo
$\mu_1 = 0$ pare appropriato. Per quanto riguarda $\mu_0$, ci sono solo due
modi per rendere vera l'espressione vista sopra: $\mu_0 = 0$ oppure, in modo
meno restrittivo, $\mu_0$ esattamente uguale a $-\alpha m_z$. Questa possibilità
è meno restrittiva nel senso che il vettore $\mu_0$ può non essere pari a zero,
ma è vincolato ad essere una combinazione lineare delle colonne di
$\alpha$. Ma in questo caso $\mu_0$ può essere scritto come
$\alpha \cdot c$, si può scrivere la (\ref{eq:VECM-poly}) come
\[
  \Gamma(L) \Delta y_t = \alpha \left[ \beta' \quad c \right] 
  \left[ \begin{array}{c} y_{t-1} \\ 1 \end{array} \right]  
  + \epsilon_t ,
\]
e la relazione di lungo periodo contiene un'intercetta. Questo tipo
di restrizione è scritta di solito nel modo seguente:
\[
  \alpha'_{\perp} \mu_0 = 0 ,
\]
dove $\alpha_{\perp}$ è lo spazio nullo sinistro della matrice $\alpha$.

È possibile dare un'intuizione del problema per mezzo di un semplice esempio.
Si consideri una serie $x_t$ che si comporta nel modo seguente:
%      
\[ x_t = m + x_{t-1} + \varepsilon_t \] 
%
dove $m$ è un numero reale e $\varepsilon_t$ è un processo ``rumore bianco''
(``white noise''). Come si può facilmente mostrare, $x_t$ è una ``passeggiata aleatoria''
(``random walk'') che fluttua intorno a un trend deterministico con pendenza $m$. Nel
caso particolare in cui $m$ = 0, il trend deterministico scompare e
$x_t$ è una passeggiata aleatoria pura.
    
Si consideri ora un altro processo $y_t$, definito da
%      
\[ y_t = k + x_t + u_t \] 
%
dove, ancora, $k$ è un numero reale e $u_t$ è un processo a rumore bianco.
Poiché $u_t$ è stazionario per definizione, $x_t$ e $y_t$ sono
cointegrate, ossia la loro differenza
%      
\[ z_t = y_t - x_t = k + u_t \]
%	
è un processo stazionario. Per $k$ = 0, $z_t$ è un semplice rumore bianco
a media zero, mentre per $k$ $\ne$ 0 il processo $z_t$ è un rumore bianco
con media diversa da zero.
  
Dopo alcune semplici sostituzioni, le due equazioni precedenti possono
essere rappresentate congiuntamente come un sistema VAR(1)
%      
\[ \left[ \begin{array}{c} y_t \\ x_t \end{array} \right] = \left[
  \begin{array}{c} k + m \\ m \end{array} \right] + \left[
  \begin{array}{rr} 0 & 1 \\ 0 & 1 \end{array} \right] \left[
  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \left[
  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array}
\right] \]
%	
o in forma VECM
%      
\begin{eqnarray*}
  \left[  \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{rr} -1 & 1 \\ 0 & 0 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{r} -1 \\ 0 \end{array} \right]
  \left[  \begin{array}{rr} 1 & -1 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = & 
  \mu_0 + \alpha \beta^{\prime} \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \eta_t = 
  \mu_0 + \alpha z_{t-1} + \eta_t ,
\end{eqnarray*}
%	
dove $\beta$ è il vettore di cointegrazione e $\alpha$ è il vettore
dei ``loading'' o ``aggiustamenti''.
     
Possiamo ora considerare tre casi possibili:
    
\begin{enumerate}
\item $m$ $\ne$ 0: in questo caso $x_t$ ha un trend, come abbiamo appena
  visto; ne consegue che anche $y_t$ segue un trend lineare perché in
  media si mantiene a una distanza fissa da $x_t$ pari a $k$.  Il vettore
  $\mu_0$ non ha restrizioni.
	
\item $m$ = 0 e $k$ $\ne$ 0: in questo caso, $x_t$ non ha un trend, e di
  conseguenza neanche $y_t$.  Tuttavia, la distanza media tra $y_t$ e
  $x_t$ è diversa da zero. Il vettore $\mu_0$ è dato da
%	  
  \[
  \mu_0 = \left[ \begin{array}{c} k \\ 0 \end{array} \right]
  \]
%	    
  che è non nullo, quindi il VECM mostrato sopra ha un termine
  costante.  La costante, tuttavia è soggetta alla restrizione che il
  suo secondo elemento deve essere pari a 0. Più in generale,
  $\mu_0$ è un multiplo del vettore $\alpha$. Si noti
  che il VECM potrebbe essere scritto anche come
%	  
  \[
  \left[ \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]
  = \left[ \begin{array}{r} -1 \\ 0 \end{array} \right] \left[
    \begin{array}{rrr} 1 & -1 & -k \end{array} \right] \left[
    \begin{array}{c} y_{t-1} \\ x_{t-1} \\ 1 \end{array} \right] +
  \left[ \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t
    \end{array} \right]
  \]
%	   
  che incorpora l'intercetta nel vettore di cointegrazione. Questo è
  il caso chiamato ``costante vincolata''.
	
\item $m$ = 0 and $k$ = 0: questo caso è il più vincolante: chiaramente,
  né $x_t$ né $y_t$ hanno un trend, e la loro distanza media è zero.
  Anche il vettore $\mu_0$ vale 0, quindi questo caso può essere
  chiamato ``senza costante''.

\end{enumerate}

Nella maggior parte dei casi, la scelta tra le tre possibilità si basa
su un misto di osservazione empirica e di ragionamento economico. Se
le variabili in esame sembrano seguire un trend lineare, è opportuno
non imporre alcun vincolo all'intercetta. Altrimenti occorre chiedersi
se ha senso specificare una relazione di cointegrazione che includa
un'intercetta diversa da zero. Un esempio appropriato potrebbe essere
la relazione tra due tassi di interesse: in generale questi non hanno
un trend, ma il VAR potrebbe comunque avere un'intercetta perché la
differenza tra i due (lo ``spread'' sui tassi d'interesse) potrebbe
essere stazionaria attorno a una media diversa da zero (ad esempio per
un premio di liquidità o di rischio).
    
L'esempio precedente può essere generalizzato in tre direzioni:
    
\begin{enumerate}
\item Se si considera un VAR di ordine maggiore di 1, l'algebra si
  complica, ma le conclusioni sono identiche.
\item Se il VAR include più di due variabili endogene, il rango di
  cointegrazione $r$ può essere maggiore di 1. In questo caso $\alpha$
  è una matrice con $r$ colonne e il caso con la costante vincolata
  comporta che $\mu_0$ sia una combinazione lineare delle colonne di
  $\alpha$.
\item Se si include un trend lineare nel modello, la parte
  deterministica del VAR diventa $\mu_0$ + $\mu_1$. Il ragionamento è
  praticamente quello visto sopra, tranne per il fatto che
  l'attenzione è ora posta su $\mu_1$ invece che su $\mu_0$. La
  controparte del caso con ``costante vincolata'' discusso sopra è un
  caso con ``trend vincolato'', così che le relazioni di
  cointegrazione includono un trend, ma la differenza prima delle
  variabili in questione no. Nel caso di un trend non vincolato, il
  trend appare sia nelle relazioni di cointegrazione sia nelle
  differenze prime, il che corrisponde alla presenza di un trend
  quadratico nelle variabili (espresse in livelli).
\end{enumerate}

Per gestire i cinque casi, \app{gretl} fornisce le seguenti opzioni per i
comandi \texttt{coint2} e \texttt{vecm}:
\begin{center}
  \begin{tabular}{cc}
    \hline
    $\mu_t$ & Opzione per il comando \\
    \hline
    0 & \verb|--nc| \\
    $\mu_0, \alpha_{\perp}'\mu_0 = 0 $ &  \verb|--rc| \\
    $\mu_0$ &  predefinito \\
    $\mu_0 + \mu_1 t , \alpha_{\perp}'\mu_1 = 0$ &  \verb|--crt| \\
    $\mu_0 + \mu_1 t$ &  \verb|--ct| \\
    \hline
  \end{tabular}
\end{center}
Si noti che le opzioni viste sopra sono mutualmente esclusive. Inoltre, è
possibile usare l'opzione \verb|--seasonal| per aggiungere a $\mu_t$ delle
dummy stagionali centrate. In ogni caso, i p-value sono calcolati con le
approssimazioni indicate in Doornik (1998).

\section{I test di cointegrazione di Johansen}
\label{sec:johansen-test}

I due test di cointegrazione di Johansen vengono usati per stabilire il
rango di $\beta$, in altre parole il numero di vettori di cointegrazione
del sistema. Essi sono il test ``$\lambda$-max'', per le ipotesi sui singoli
autovalori, e il test ``traccia'', per le ipotesi congiunte.
Si supponga che gli autovalori $\lambda_i$ siano ordinati dal maggiore al
minore. L'ipotesi nulla per il test  ``$\lambda$-max'' sul
$i$-esimo autovalore è che sia $\lambda_i = 0$. Invece, il test traccia
corrispondente considera l'ipotesi che sia $\lambda_j = 0$ per ogni
$j \ge i$.

Il comando \cmd{coint2} di \app{gretl} esegue questi due test; la voce
corrispondente nel menù dell'interfaccia grafica è ``Modello, Serie Storiche,
COINT - Test di cointegrazione, Johansen''.

Come nel test ADF, la distribuzione asintotica dei test varia a seconda
del kernel deterministico $\mu_t$ incluso nel VAR (si veda la sezione
\ref{sec:coint-5cases}). Il codice seguente usa il file di dati
\cmd{denmark}, fornito insieme a \app{gretl}, per replicare l'esempio proposto
da Johansen nel suo libro del 1995.
%
\begin{code}
open denmark
coint2 2 LRM LRY IBO IDE --rc --seasonal
\end{code}
%
In questo caso, il vettore $y_t$ nell'equazione (\ref{eq:VECM}) comprende le
quattro variabili \cmd{LRM}, \cmd{LRY}, \cmd{IBO}, \cmd{IDE}. Il numero dei
ritardi equivale a $p$ nella (\ref{eq:VECM}) (ossia, il numero dei ritardi del
modello scritto in forma VAR). Di seguito è riportata parte
dell'output:

\begin{center}
\begin{code}
Test di Johansen:
Numero di equazioni = 4
Ordine dei ritardi = 2
Periodo di stima: 1974:3 - 1987:3 (T = 53)

Caso 2: costante vincolata
Rango Autovalore Test traccia p-value   Test Lmax  p-value
   0    0,43317     49,144 [0,1284]     30,087 [0,0286]
   1    0,17758     19,057 [0,7833]     10,362 [0,8017]
   2    0,11279     8,6950 [0,7645]     6,3427 [0,7483]
   3   0,043411     2,3522 [0,7088]     2,3522 [0,7076]
\end{code}
\end{center}

Sia il test traccia, sia quello $\lambda$-max portano ad accettare l'ipotesi nulla
che il più piccolo autovalore valga 0 (ultima riga della tabella), quindi possiamo
concludere che le serie non sono stazionarie. Tuttavia, qualche loro combinazione
lineare potrebbe essere I(0), visto che il test $\lambda$-max rifiuta l'ipotesi che
il rango di $\Pi$ sia 0 (anche se il test traccia dà un'indicazione meno netta
in questo senso, con un p-value pari a $0.1284$).

\section{Identificazione dei vettori di cointegrazione}
\label{sec:johansen-ident}

Il problema centrale nella stima dell'equazione (\ref{eq:VECM}) consiste nel
trocare una stima di $\Pi$ che abbia rango $r$ per costruzione, così che possa
essere scritta come $\Pi = \alpha \beta'$, dove $\beta$ è la matrice che
contiene i vettori di cointegrazione e $\alpha$ contiene i coefficienti di
``aggiustamento'' o ``loading'', per cui le variabili endogene rispondono
a una deviazione dall'equilibrio nel periodo precedente.

Senza ulteriore specificazione, il problema ha molte soluzioni (in effetti
ne ha infinite). I parametri $\alpha$ e $\beta$ sono sotto-identificati: se
tutte le colonne di $\beta$ sono vettori di cointegrazione, anche qualsiasi loro
combinazione lineare arbitraria è un vettore di cointegrazione. In altre parole,
se $\Pi = \alpha_0 \beta_0'$ per specifiche matrici $\alpha_0$ e $\beta_0$, allora
$\Pi$ è anche uguale a $(\alpha_0 \Sigma)(\Sigma^{-1} \beta_0')$ per qualsiasi
matrice conformabile e non singolare $\Sigma$. Per trovare una soluzione unica,
è quindi necessario imporre alcune restrizioni su $\alpha$ e/o
$\beta$. Si può dimostrare che il numero minimo di restrizioni necessarie per
garantire l'identificazione è pari a $r^2$. Un primo passo banale consiste nel
normalizzare un coefficiente per ogni colonna rendendolo pari a 1 (o a -1, a
seconda dei gusti), il che aiuta anche a interpretare i restanti coefficienti
come parametri delle relazioni di equilibrio; tuttavia, questo basta solo nel
caso in cui $r=1$.

Il metodo usato da \app{gretl} in modo predefinito è chiamato ``normalizzazione
di Phillips'', o ``rappresentazione triangolare''\footnote{Per fare confronti
  con altri studi, potrebbe essere necessario normalizzare $\beta$ in modo
  diverso. Usando il comando \texttt{set} è possibile scrivere
  \verb|set vecm_norm diag| per scegliere la normalizzazione che scala
  le colonne della $\beta$ originaria in modo che valga $\beta_{ij} = 1$ per $i=j$
  e $i \leq r$, come è mostrato nella sezione empirica di Boswijk e
  Doornik (2004).  Una soluzione alternativa è \verb+set vecm_norm first+,
  che scala $\beta$ in modo che gli elementi della prima riga siano pari a 1.
  Per tornare all'impostazione predefinita: \texttt{set vecm\_norm phillips}.
}. Il punto di partenza consiste nello scrivere $\beta$ in forma partizionata, come in
\[
  \beta = \left[
    \begin{array}{c} \beta_1 \\ \beta_2  \end{array}
    \right] ,
\]
dove $\beta_1$ è una matrice $r \times r$ e  $\beta_2$ è $(n-r)
\times r$. Assumendo che $\beta_1$ abbia rango pieno, $\beta$ può essere
post-moltiplicata da $\beta_1^{-1}$, ottenendo
\[
  \hat{\beta} = \left[
    \begin{array}{c} I \\ \beta_2 \beta_1^{-1}  \end{array}
    \right] =
    \left[
    \begin{array}{c} I \\ -B \end{array}
  \right]  ,
\]

I coefficienti prodotti da \app{gretl} sono i $\hat{\beta}$, mentre
$B$ è nota come matrice dei coefficienti non vincolati. Nei termini della
relazione di equilibrio sottostante, la normalizzazione di Phillips
esprime il sistema di $r$ relazioni di equilibrio come
  \begin{eqnarray}
    y_{1,t} & = & b_{1,r+1} y_{r+1,t} + \ldots + b_{1,n} y_{n,t} \\
    y_{2,t} & = & b_{2,r+1} y_{r+1,t} + \ldots + b_{2,n} y_{n,t} \\
    & \vdots & \\
    y_{r,t} & = & b_{r,r+1} y_{r+1,t} + \ldots + b_{r,n} y_{r,t} 
  \end{eqnarray}
dove le prime $r$ variabili sono espresse come funzione delle restanti
$n-r$.

Anche se la rappresentazione triangolare assicura la soluzione del problema
statistico della stima di $\beta$, le relazioni di equilibrio che risultano
possono essere difficili da interpretare. In questo caso, l'utente potrebbe
voler cercare l'identificazione specificando manualmente il sistema di
$r^2$ vincoli che \app{gretl} userà per produrre una stima di
$\beta$.

Come esempio, si consideri il sistema di domanda di moneta presentato nella
sezione 9.6 di Verbeek (2004). Le variabili usate sono \texttt{m} (il logaritmo
della quantità di moneta reale M1), \texttt{infl} (l'inflazione), \texttt{cpr}
(i tassi di interesse sui ``commercial paper''), \texttt{y} (il logaritmo del
PIL reale) e \texttt{tbr} (i tassi di interesse sui ``Treasury bill'')\footnote{Questo
dataset è disponibile nel pacchetto \texttt{verbeek}; si veda la pagina
  \url{http://gretl.sourceforge.net/gretl_data_it.html}.}.

La stima di $\beta$ si può ottenere con questi comandi:
\begin{code}
  open money.gdt 
  smpl 1954:1 1994:4 
  vecm 6 2 m infl cpr y tbr --rc
\end{code}
e la parte rilevante dei risultati è questa:
\begin{code}
Stime Massima verosimiglianza usando le osservazioni 1954:1-1994:4 (T = 164)
Rango di cointegrazione = 2
Caso 2: costante vincolata

Vettori di cointegrazione (errori standard tra parentesi)

m           1.0000       0.0000 
           (0.0000)     (0.0000) 
infl        0.0000       1.0000 
           (0.0000)     (0.0000) 
cpr        0.56108      -24.367 
          (0.10638)     (4.2113) 
y         -0.40446     -0.91166 
          (0.10277)     (4.0683) 
tbr       -0.54293       24.786 
          (0.10962)     (4.3394) 
const      -3.7483       16.751 
          (0.78082)     (30.909) 
\end{code}
L'interpretazione dei coefficienti della matrice di cointegrazione $\beta$
sarebbe più semplice se si potesse associare un significato ad ognuna delle sue
colonne. Questo è possibile ipotizzando l'esistenza di due relazioni di lungo
periodo: una equazione di domanda di moneta
\begin{equation}
  \label{eq:verbeek-mondem}
  \mbox{\tt m} = c_1 + \beta_1 \mbox{\tt infl} + \beta_2 \mbox{\tt
    y} + \beta_3 \mbox{\tt tbr}
\end{equation}
e una equazione per premio sul rischio
\begin{equation}
  \label{eq:verbeek-premium}
 \mbox{\tt cpr} = c_2 + \beta_4 \mbox{\tt infl} +
   \beta_5 \mbox{\tt y} + \beta_6 \mbox{\tt tbr}
\end{equation}
che implica che la matrice di cointegrazione può essere normalizzata come
\[
  \beta = \left[
    \begin{array}{rr}
      -1 & 0 \\ \beta_1 & \beta_4 \\ 0 & -1 \\ \beta_2 & \beta_5
      \\ \beta_3 & \beta_6 \\ c_1 & c_2
    \end{array}
    \right]
\]

Questa rinormalizzazione può essere compiuta per mezzo del comando
\texttt{restrict}, da eseguire dopo il comando \texttt{vecm}, oppure, se si usa
l'interfaccia grafica, scegliendo la voce dal menù ``Test, Vincoli lineari''.
La sintassi per specificare i vincoli è abbastanza intuitiva\footnote{Si noti che
  in questo contesto, stiamo trasgredendo la convenzione usata di solito per gli
  indici delle matrici, visto che usiamo il primo indice per riferirci alla
  \textit{colonna} di $\beta$ (il particolare vettore di cointegrazione).
  Questa è la pratica usata di solito nella letteratura sulla cointegrazione,
  visto che sono le colonne di $\beta$ (le relazioni di cointegrazione o gli
  errori di equilibrio) che interessano in modo particolare.}:
\begin{code}
restrict
  b[1,1] = -1
  b[1,3] = 0
  b[2,1] = 0
  b[2,3] = -1
end restrict
\end{code}
che produce

\begin{code}
Vettori di cointegrazione (errori standard tra parentesi)

m          -1.0000       0.0000 
           (0.0000)     (0.0000) 
infl     -0.023026     0.041039 
        (0.0054666)   (0.027790) 
cpr         0.0000      -1.0000 
           (0.0000)     (0.0000) 
y          0.42545    -0.037414 
         (0.033718)    (0.17140) 
tbr      -0.027790       1.0172 
        (0.0045445)   (0.023102) 
const       3.3625      0.68744 
          (0.25318)     (1.2870) 
\end{code}

\section{Over-identifying restrictions}
\label{sec:johansen-overid}

Although $r^2$ restrictions must be imposed on a VECM system to
ensure identification of $\beta$, extra restrictions can be specified
in order to check via a likelihood-ratio statistic whether they hold
in the data. These extra restrictions are usually imposed to test
constraints stemming from the economic theory underlying the
equilibrium relationships.

\app{Gretl} is capable of testing general linear restrictions of the
form 
\begin{equation}
\label{eq:Rb}
R_b \vec{\beta} = q
\end{equation}
and/or
\begin{equation}
\label{eq:Ra}
R_a \vec{\alpha} = 0
\end{equation}
%
Note that the $\beta$ restriction may be non-homogeneous ($q \neq 0$)
but the $\alpha$ restriction must be homogeneous.  Nonlinear
restrictions are not supported, and neither are restrictions that
cross between $\beta$ and $\alpha$.  In the case where $r > 1$ such
restrictions may be in common across all the columns of $\beta$ (or
$\alpha$) or may be specific to certain columns of these matrices.
This is the case discussed in Boswijk (1995) and Boswijk and Doornik
(2004, section 4.4).

The restrictions (\ref{eq:Rb}) and (\ref{eq:Ra}) may be written in
explicit form as
\begin{equation}
\label{eq:vecbeta}
\vec{\beta} = H\phi + h_0
\end{equation}
and
\begin{equation}
\label{eq:vecalpha}
\vec{\alpha'} = G\psi
\end{equation}
respectively, where $\phi$ and $\psi$ are the free parameter vectors
associated with $\beta$ and $\alpha$ respectively.  We may refer
to the free parameters collectively as $\theta$ (the column vector
formed by concatenating $\phi$ and $\psi$).  \app{Gretl} uses this
representation internally when testing the restrictions.

If the list of restrictions that is passed to the \texttt{restrict}
command contains more constraints than necessary to achieve
identification, then an LR test is performed; moreover, the
\texttt{restrict} command can be given the \verb|--full| switch, in
which case full estimates for the restricted system are printed
(including the $\Gamma_i$ terms), and the system thus restricted
becomes the ``current model'' for the purposes of further tests.  Thus
you are able to carry out cumulative tests, as in Chapter 7 of
Johansen (1995).

\subsection{Syntax}
\label{sec:vecm-restr-syntax}

The full syntax for specifying the restriction is an extension of the
one exemplified in the previous section. Inside a
\texttt{restrict}\ldots\texttt{end restrict} block, valid statements
are of the form
\begin{center}
  \texttt{\emph{parameter linear combination}} = \emph{\texttt{scalar}}
\end{center}
where a parameter linear combination involves a weighted sum of
individual elements of $\beta$ or $\alpha$ (but not both in the same
combination); the scalar on the right-hand side must be 0 for
combinations involving $\alpha$, but can be any real number for
combinations involving $\beta$. Below, we give a few examples of valid
restrictions:
\begin{code}
  b[1,1] = 1.618
  b[1,4] + 2*b[2,5] = 0
  a[1,3] = 0
  a[1,1] - a[1,2] = 0
\end{code}

A special syntax is reserved for the case when a certain constraint
should be applied to all columns of $\beta$: in this case, one index is
given for each \texttt{b} term, and the square brackets are dropped.
Hence, the following syntax
\begin{code}
restrict
  b1 + b2 = 0
end restrict
\end{code}
corresponds to
\[
\beta = \left[
\begin{array}{rr}
\beta_{11} & \beta_{21} \\
-\beta_{11} & -\beta_{21} \\
\beta_{13} & \beta_{23} \\
\beta_{14} & \beta_{24}
\end{array}
\right]
\]
The same convention is used for $\alpha$: when only one index is given for
each \texttt{a} term, the restriction is presumed to apply to all $r$
rows of $\alpha$, or in other words the given variables are weakly
exogenous. For instance, the formulation
%
\begin{code}
restrict
  a3 = 0
  a4 = 0
end restrict
\end{code}
%
specifies that variables 3 and 4 do not respond to the deviation from
equilibrium in the previous period.  

Finally, a short-cut is available for setting up complex restrictions (but
currently only in relation to $\beta$): you can specify $R_b$ and $q$,
as in $R_b \vec{\beta} = q$, by giving the names of previously
defined matrices.  For example,
%
\begin{code}
matrix I4 = I(4)
matrix vR = I4**(I4~zeros(4,1))
matrix vq = mshape(I4,16,1)
restrict
  R = vR
  q = vq
end restrict
\end{code}
%
which manually imposes Phillips normalization on the $\beta$ estimates
for a system with rango di cointegrazione 4.
 
\subsection{An example}
\label{sec:vecm-overid-ex}

Brand and Cassola (2004) propose a money demand system for the Euro
area, in which they postulate three long-run equilibrium
relationships:
%
\begin{center}
\begin{tabular}{ll}
  money demand & $m = \beta_l l + \beta_y y$ \\
  Fisher equation & $\pi = \phi l$ \\
  Expectation theory of & $l = s$ \\ [-4pt]
  interest rates
\end{tabular}
\end{center}
%
where $m$ is real money demand, $l$ and $s$ are long- and short-term
interest rates, $y$ is output and $\pi$ is inflation.\footnote{A
  traditional formulation of the Fisher equation would reverse the
  roles of the variables in the second equation, but this detail is
  immaterial in the present context; moreover, the expectation theory
  of interest rates implies that the third equilibrium relationship
  should include a constant for the liquidity premium. However, since
  in this example the system is estimated with the constant term
  unrestricted, the liquidity premium gets merged in the system
  intercept and disappears from $z_t$.}  (The names for these
variables in the \app{gretl} data file are \verb|m_p|, \texttt{rl},
\texttt{rs}, \texttt{y} and \texttt{infl}, respectively.)

The rango di cointegrazione assumed by the authors is 3 and there are 5
variables, giving 15 elements in the $\beta$ matrix.  $3 \times 3 = 9$
restrictions are required for identification, and a just-identified
system would have $15 - 9 = 6$ unrestricted parameters.  However, the
three postulated long-run relationships feature only three
unrestricted parameters, so the over-identification rank is 3.

\begin{script}[htbp]
  \caption{Estimation of a money demand system with constraints on $\beta$}
  \label{brand-cassola-script}
Input:
\begin{scodebit}
open brand_cassola.gdt

# perform a few transformations
m_p = m_p*100
y = y*100
infl = infl/4
rs = rs/4
rl = rl/4

# replicate table 4, page 824
vecm 2 3 m_p infl rl rs y -q
genr ll0 = $lnl

restrict --full
  b[1,1] = 1
  b[1,2] = 0
  b[1,4] = 0
  b[2,1] = 0
  b[2,2] = 1
  b[2,4] = 0
  b[2,5] = 0
  b[3,1] = 0
  b[3,2] = 0
  b[3,3] = 1
  b[3,4] = -1
  b[3,5] = 0
end restrict
genr ll1 = $rlnl
\end{scodebit}
Partial output:
\begin{scodebit}
Unrestricted loglikelihood (lu) = 116.60268
Restricted loglikelihood (lr) = 115.86451
2 * (lu - lr) = 1.47635
P(Chi-Square(3) > 1.47635) = 0.68774

beta (vettori di cointegrazione, standard errors in parentheses)

m_p        1.0000       0.0000       0.0000 
          (0.0000)     (0.0000)     (0.0000) 
infl       0.0000       1.0000       0.0000 
          (0.0000)     (0.0000)     (0.0000) 
rl         1.6108     -0.67100       1.0000 
         (0.62752)   (0.049482)     (0.0000) 
rs         0.0000       0.0000      -1.0000 
          (0.0000)     (0.0000)     (0.0000) 
y         -1.3304       0.0000       0.0000 
        (0.030533)     (0.0000)     (0.0000) 
\end{scodebit}
%$
\end{script}

Example \ref{brand-cassola-script} replicates Table 4 on page 824 of
the Brand and Cassola article.\footnote{Modulo what appear to be a few
  typos in the article.} Note that we use the \verb|$lnl| accessor
after the \texttt{vecm} command to store the unrestricted
log-likelihood and the \verb|$rlnl| accessor after \texttt{restrict}
for its restricted counterpart. 

The example continues in script~\ref{brand-cassola-tab5}, where we
perform further testing to check whether (a) the income elasticity in
the money demand equation is 1 ($\beta_y = 1$) and (b) the Fisher
relation is homogeneous ($\phi = 1$). Since the \verb|--full| switch
was given to the initial \texttt{restrict} command, additional
restrictions can be applied without having to repeat the previous
ones.  (The second script contains a few \texttt{printf} commands,
which are not strictly necessary, to format the output nicely.)  It
turns out that both of the additional hypotheses are rejected by the
data, with p-values of $0.002$ and $0.004$.

\begin{script}[htbp]
  \caption{Further testing of money demand system}
  \label{brand-cassola-tab5}
Input:
\begin{scodebit}
restrict
  b[1,5] = -1
end restrict
genr ll_uie = $rlnl

restrict
  b[2,3] = -1
end restrict
genr ll_hfh = $rlnl

# replicate table 5, page 824
printf "Testing zero restrictions in cointegrazione space:\n"
printf "  LR-test, rank = 3: chi^2(3) = %6.4f [%6.4f]\n", 2*(ll0-ll1), \
	pvalue(X, 3, 2*(ll0-ll1))

printf "Unit income elasticity: LR-test, rank = 3:\n"
printf "  chi^2(4) = %g [%6.4f]\n", 2*(ll0-ll_uie), \
	pvalue(X, 4, 2*(ll0-ll_uie))

printf "Homogeneity in the Fisher hypothesis:\n"
printf "  LR-test, rank = 3: chi^2(4) = %6.3f [%6.4f]\n", 2*(ll0-ll_hfh), \
	pvalue(X, 4, 2*(ll0-ll_hfh))
\end{scodebit}
Output:
\begin{scodebit}
Testing zero restrictions in cointegrazione space:
  LR-test, rank = 3: chi^2(3) = 1.4763 [0.6877]
Unit income elasticity: LR-test, rank = 3:
  chi^2(4) = 17.2071 [0.0018]
Homogeneity in the Fisher hypothesis:
  LR-test, rank = 3: chi^2(4) = 15.547 [0.0037]  
\end{scodebit}
\end{script}

Another type of test that is commonly performed is the ``weak
exogeneity'' test. In this context, a variable is said to be weakly
exogenous if all coefficients on the corresponding row in the $\alpha$
matrix are zero. If this is the case, that variable does not adjust to
deviations from any of the long-run equilibria and can be considered
an autonomous driving force of the whole system.

The code in Example~\ref{brand-cassola-exog} performs this test for
each variable in turn, thus replicating the first column of Table 6 on
page 825 of Brand and Cassola (2004).  The results show that weak
exogeneity might perhaps be accepted for the long-term interest rate
and real GDP (p-values $0.07$ and $0.08$ respectively).

\begin{script}[htbp]
  \caption{Testing for weak exogeneity}
  \label{brand-cassola-exog}
Input:
\begin{scodebit}
restrict
  a1 = 0
end restrict
ts_m = 2*(ll0 - $rlnl)

restrict
  a2 = 0
end restrict
ts_p = 2*(ll0 - $rlnl)

restrict
  a3 = 0
end restrict
ts_l = 2*(ll0 - $rlnl)

restrict
  a4 = 0
end restrict
ts_s = 2*(ll0 - $rlnl)

restrict
  a5 = 0
end restrict
ts_y = 2*(ll0 - $rlnl)

loop foreach i m p l s y --quiet
  printf "\Delta $i\t%6.3f [%6.4f]\n", ts_$i, pvalue(X, 6, ts_$i)
end loop
\end{scodebit}
Output (variable, LR test, p-value):
\begin{scodebit}
\Delta m	18.111 [0.0060]
\Delta p	21.067 [0.0018]
\Delta l	11.819 [0.0661]
\Delta s	16.000 [0.0138]
\Delta y	11.335 [0.0786]
\end{scodebit}
%$
\end{script}

\subsection{Numerical solution methods}
\label{sec:vecm-opt}

In general, the ML estimator for the restricted VECM problem has no
closed form solution, hence the maximum must be found via numerical
methods.\footnote{The exception is restrictions that are homogeneous,
  common to all $\beta$ or all $\alpha$ (in case $r>1$), and involve
  either $\beta$ only or $\alpha$ only.  Such restrictions are handled
  via the modified eigenvalues method set out by Johansen (1995).  We
  solve directly for the ML estimator, without any need for iterative
  methods.}  In some cases convergence may be difficult, and
\app{gretl} provides several choices to solve the problem.

Two maximization methods are available in \app{gretl}. The default is
the switching algorithm set out in Boswijk and Doornik (2004).  The
alternative is a limited-memory variant of the BFGS algorithm (LBFGS),
using analytical derivatives.  This is invoked using the
\verb+--lbfgs+ flag with the \texttt{restrict} command.

The switching algorithm works by explicitly maximizing the likelihood
at each iteration, with respect to $\hat{\phi}$, $\hat{\psi}$ and
$\hat{\Omega}$ (the covariance matrix of the residuals) in turn.  This
method shares a feature with the basic Johansen eigenvalues procedure,
namely, it can handle a set of restrictions that does not fully
identify the parameters.

LBFGS, on the other hand, requires that the model be fully identified.
When using LBFGS, therefore, you may have to supplement the
restrictions of interest with normalizations that serve to identify
the parameters.  For example, one might use all or part of the
Phillips normalization (see section \ref{sec:johansen-ident}).

Neither the switching algorithm nor LBFGS is guaranteed to find the
global ML solution.\footnote{In developing \app{gretl}'s VECM-testing
  facilities we have considered a fair number of ``tricky cases'' from
  various sources. We'd like to thank Luca Fanelli of the University
  of Bologna and Sven Schreiber of Johann Wolfgang Goethe-Universit\"at,
  for their help in devising torture-tests for \app{gretl}'s VECM
  code.} The optimizer may end up at a local maximum (or, in the case
of the switching algorithm, at a saddle point).

The solution (or lack thereof) may be sensitive to the initial value
selected for $\theta$.  By default, \app{gretl} selects a starting
point using a deterministic method based on Boswijk (1995), but two
further options are available: the initialization may be adjusted
using simulated annealing (with the \verb+--jitter+ flag), or the user
may supply an explicit initial value for $\theta$.

The default initialization method is:
%
\begin{enumerate}
\item Calculate the unrestricted ML $\hat{\beta}$ using the
  Johansen procedure.
\item If the restriction on $\beta$ is non-homogeneous, use the
  method proposed by Boswijk (1995):
\begin{equation}
\phi_0 = -[(I_r \otimes \hat{\beta}_{\perp})'H]^+ 
  (I_r \otimes \hat{\beta}_{\perp})' h_0
\end{equation}
where $\hat{\beta}'_{\perp} \hat{\beta} = 0$ and $A^+$ denotes
the Moore--Penrose inverse of $A$.  Otherwise
\begin{equation}
\phi_0 = (H'H)^{-1} H' \vec{\hat{\beta}}
\end{equation}
\item $\vec{\beta_0} = H\phi_0 + h_0$.
\item Calculate the unrestricted ML $\hat{\alpha}$ conditional on
  $\beta_0$, as per Johansen:
\begin{equation}
\label{eq:Jalpha}
\hat{\alpha} = S_{01} \beta_0 (\beta'_0S_{11}\beta_0)^{-1}
\end{equation}
\item If $\alpha$ is restricted by $\vec{\alpha'} = G\psi$, then
  $\psi_0 = (G'G)^{-1}G'\,{\rm vec}(\hat{\alpha}')$ and
  $\vec{\alpha'_0} = G\psi_0$.
\end{enumerate}

However, as mentioned above, \app{gretl} offers the option of adjusting the
initialization using simulated annealing.  

The basic idea is this: we start at a certain point in the parameter
space, and for each of $n$ iterations (currently $n=4096$) we randomly
select a new point within a certain radius of the
previous one, and determine the likelihood at the new point.  If the
likelihood is higher, we jump to the new point; otherwise, we jump
with probability $P$ (and remain at the previous point with
probability $1-P$).  As the iterations proceed, the system gradually
``cools''---that is, the radius of the random perturbation is
reduced, as is the probability of making a jump when the likelihood
fails to increase.

In the course of this procedure many points in the parameter space are
evaluated, starting with the point arrived at by the deterministic
method, which we'll call $\theta_0$.  One of these points will be
``best'' in the sense of yielding the highest likelihood: call it
$\theta^*$.  This point may or may not have a greater likelihood than
$\theta_0$.  And the procedure has an end point, $\theta_n$, which may
or may not be ``best''.

The rule followed by \app{gretl} in selecting an initial value for $\theta$
based on simulated annealing is this: use $\theta^*$ if $\theta^* >
\theta_0$, otherwise use $\theta_n$.  That is, if we get an
improvement in the likelihood via annealing, we make full use of this;
on the other hand, if we fail to get an improvement we nonetheless
allow the annealing to randomize the starting point.  Experiments
indicated that the latter effect can be helpful.

If the default deterministic initialization fails, the alternative to
relying on randomization is for the user to specify initial values.
This is done by passing a predefined vector to the \texttt{set}
command with parameter \texttt{initvals}, as in
%
\begin{verbatim}
set initvals myvec
\end{verbatim}

The details depend on whether the switching algorithm or LBFGS is
used.  For the switching algorithm, there are two options for
specifying the initial values.  The more user-friendly one (for most
people, we suppose) is to specify a matrix that contains $\vec{\beta}$
followed by $\vec{\alpha}$. For example:
\begin{code}
open denmark.gdt
vecm 2 1 LRM LRY IBO IDE --rc --seasonals

matrix BA = {1, -1, 6, -6, -6, -0.2, 0.1, 0.02, 0.03}
set initvals BA
restrict
  b[1] = 1
  b[1] + b[2] = 0
  b[3] + b[4] = 0
end restrict
\end{code}

The other option, which is compulsory when using LBFGS, is to specify
the initial values in terms of the unrestricted parameters, $\phi$ and
$\psi$.  Getting this right is somewhat less obvious.  As mentioned
above, the implicit-form restriction $R\vec{\beta} = q$ has explicit
form $\vec{\beta} = H\phi + h_0$, where $H = R_{\perp}$, the right
nullspace of $R$.  The vector $\phi$ is shorter, by the number of
restrictions, than $\vec{\beta}$.  The savvy user will then see what
needs to be done.  The other point to take into account is that if
$\alpha$ is unrestricted, the \textit{effective} length of $\psi$ is
0, since it is then optimal to compute $\alpha$ using Johansen's
formula, conditional on $\beta$ (equation \ref{eq:Jalpha} above). An
example follows:
\begin{code}
open denmark.gdt
vecm 2 1 LRM LRY IBO IDE --rc --seasonals

matrix phi = {-8, -6}
set initvals phi
restrict --lbfgs
  b[1] = 1
  b[1] + b[2] = 0
  b[3] + b[4] = 0
end restrict
\end{code}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide"
%%% End: 
