  <appendix id="app-a"><title>Crash course in econometrics</title>

    <section id="metrics-intro"><title>Introduction</title>

      <para> This highly condensed discussion is no substitute for a
	proper training in econometrics, but hopefully it may serve to
	orient people without an econometrics background who
	nonetheless have some interest in experimenting with
	<application>gretl</application>, or even hacking on it (dream
	on!).
      </para>

      <para>
	The substance of econometrics is the quantification of
	relationships between economic variables using statistical
	methods.  The larger purposes served by this work include
	forecasting, policy analysis, and the assessment or refinement
	of economic theories.
      </para>

      <para>
	Much of econometrics is based on the classical statistical
	paradigm of sampling theory. Econometric relationships are
	generally represented as stochastic equations, the simplest of
	which is the simple linear regression model</para> 

	<informalequation>
	<alt role="tex">
	  \[y_t = \alpha + \beta x_t + \epsilon_t\]
	</alt>
	<graphic fileref="figures/linreg.png"/>
        </informalequation>
	      
	<para>This model represents the <emphasis>dependent
	  variable</emphasis>, <emphasis>y</emphasis>, at observation
	<emphasis>t</emphasis>, as a linear function (with intercept
	&alpha; and slope &beta;) of a single <emphasis>independent
	  variable</emphasis>,
	<emphasis>x</emphasis><subscript><emphasis>t</emphasis></subscript>, 
	plus a random <quote>error</quote> or
	<quote>disturbance</quote> term
	&egr;<subscript><emphasis>t</emphasis></subscript>. The random
	term may be thought of as summing up various influences on
	<emphasis>y</emphasis><subscript><emphasis>t</emphasis></subscript> 
	not specified in the equation, or as reflecting inherently
	stochastic behavior in <emphasis>y</emphasis>, or in various
	other ways. The task of econometric estimation is to provide
	estimates of the parameters &alpha; and &beta; (and the
	variance, &sigma;<superscript>2</superscript>, of the error
	term), given some actual data on <emphasis>x</emphasis> and
	<emphasis>y</emphasis>.</para> 

    </section>

    <section id="metrics-ols"><title>Least Squares</title>

      <para>Provided that the distribution of &egr; satisfies
	certain conditions (it has a mean or expected value of zero;
	it has a constant variance; it is uncorrelated across
	observations; it is uncorrelated with the independent
	variable, <emphasis>x</emphasis>), the Gauss&ndash;Markov
	Theorem tells us that optimal estimates of the regression
	parameters are delivered by the method of <emphasis>least
	  squares</emphasis>.
      </para>

      <para>
	Let the least-squares estimates of &alpha; and &beta; be
	denoted by <emphasis>a</emphasis> and <emphasis>b</emphasis>:
	we then represent the equation <quote>fitted</quote> via least
	squares as 

	<informalequation>
	  <alt role="tex">
	    \[\hat{y}_t = a + b x_t\]
	  </alt>
	  <graphic fileref="figures/yhat.png"/>
	</informalequation> 

	We define the regression <quote>residual</quote> as 

	<informalequation>
	  <alt role="tex">
	    \[\hat{\epsilon}_t = y_t - \hat{y}_t\]
	  </alt>
	  <graphic fileref="figures/resid.png"/>
	</informalequation> 

	the difference between actual
	<emphasis>y</emphasis> at observation <emphasis>t</emphasis>
	and the <quote>fitted</quote> or predicted value (which lies
	on the least-squares regression line). The least squares
	method consists in finding the specific coefficient values
	<emphasis>a</emphasis> and <emphasis>b</emphasis> which
	produce the smallest possible sum of squared residuals.
	Provided the equation in view is indeed linear, this is just
	an exercise in the differential calculus. The sum of squared
	residuals (or estimated errors), ESS, is a function of
	<emphasis>a</emphasis> and <emphasis>b</emphasis> (and the
	data).  One takes the partial derivatives of ESS with respect
	to both <emphasis>a</emphasis> and <emphasis>b</emphasis> and
	sets them to zero, then solves the resulting two equations for
	the implied <emphasis>a</emphasis> and <emphasis>b</emphasis>
	values. The same principle extends to higher-dimensional
	systems.</para>

    </section>

    <section id="pop-and-sample"><title>Population and sample</title>

      <para>On the classical sampling paradigm, the actual observed
	data
	(<emphasis>x</emphasis><subscript><emphasis>t</emphasis></subscript>, 
	<emphasis>y</emphasis><subscript><emphasis>t</emphasis></subscript>) 
	from any given period are conceived as a particular sample
	<emphasis>realization</emphasis> of the (potentially infinite)
	<emphasis>population</emphasis> of
	<emphasis>x</emphasis><subscript><emphasis>t</emphasis></subscript>, 
	<emphasis>y</emphasis><subscript><emphasis>t</emphasis></subscript> 
	pairs that could have been observed, given different possible
	<quote>drawings</quote> from the distribution of the error
	term, &egr;<subscript><emphasis>t</emphasis></subscript>, in
	each sub-period.  Application of the least-squares method
	guarantees the <quote>best fit</quote> (in a well-defined
	sense) to any given set of sample data, but data from any
	finite sample may be more or less unrepresentative of the
	larger population from which they are drawn.
      </para>

      <para>
	One sort of question of interest in econometrics is: Given
	that the conditions of optimality of the least-squares
	estimates are satisfied, how much confidence can one have that
	the coefficients derived via least squares lie within a
	specified distance of the <quote>true</quote> underlying
	parameters that characterize the data-generating process (DGP)
	itself?  This is the issue of <quote>confidence
	  intervals.</quote>  As a rough rule of thumb, a 95 percent
	confidence interval for a parameter can be constructed as the
	point estimate plus-or-minus two standard errors: that is
	(again, roughly) one can have 95 percent confidence that a
	given coefficient estimate is within 2 standard errors of the
	corresponding unknown parameter. Standard errors for
	coefficient estimates are reported routinely within
	<application>gretl</application>.
      </para>

      <para>
	One is also interested in hypothesis tests: For instance,
	given a certain non-zero value for a least-squares regression
	coefficient, how confident can we be that the corresponding
	unknown parameter is non-zero? It's always possible that even
	if <emphasis>x</emphasis> and <emphasis>y</emphasis> are
	<quote>truly</quote> statistically independent, one derives a
	non-zero correlation between observations of these variables
	in a finite sample by the <quote>luck of the draw.</quote> The
	larger the sample, and the larger the (absolute value of the)
	sample correlation, presumably the smaller the probability
	that this correlation could be a <quote>luck of the
	draw</quote> phenomenon.
      </para>

      <para>
	So-called <quote>p-values</quote> for hypothesis tests
	(reported in various contexts within
	<application>gretl</application>) address this issue: the
	p-value is the probability of observing a sample effect of the
	given, observed magnitude or greater, conditional on there
	being no real effect at the population level.  Thus a small
	p-value counts against the Null Hypothesis (no real effect).
	If the p-value for a given coefficient estimate is less than
	&alpha; one says that the coefficient is <quote>statistically
	  significant</quote> at the &alpha; level (e.g. a
	coefficient with a p-value &lt; .05 is significant at the 5
	percent level).</para> 

    </section>

    <section id="metrics-pathol"><title>Regression pathologies</title> 

      <para>Two other questions of interest in econometrics are:  How
	can we tell if the conditions for optimality of the least
	squares estimates are <emphasis>not</emphasis> satisfied?  And if it
	appears these conditions are violated, what better
	alternatives to least squares are available?
	<application>gretl</application> offers a battery of tests and
	alternative estimators. The tests are available under the
	menus in the model window after running a regression; the
	alternative estimators are under the Model menu in the main
	window, while details on their use are in the online help
	file. I can't hope to teach much about these topics here.
	Please consult, for instance, Ramanathan (2002) or, for a
	comprehensive treatment, Greene (2000).  Ruud (2000) is also a
	rather comprehensive resource.</para>

    </section>

    <section id="linearity"><title>Linearity: how restrictive?</title>


      <para>As mentioned above, the least squares regression routines
	in <application>gretl</application> presuppose a linear model.
	This is not quite as restrictive as it may seem.  We require
	an equation that is linear in its
	<emphasis>parameters</emphasis>, but this does not necessarily
	mean that it is linear in the variables of interest.  For
	example, all of the following equations represent nonlinear
	relationships between <emphasis>y</emphasis> and
	<emphasis>x</emphasis> that can readily be estimated using OLS
	or similar:

	<informalequation>
	<alt role="tex"><![CDATA[
         \begin{eqnarray*}
	  y_t &=& \alpha + \beta(1/x_t) + \epsilon_t\\
	  y_t &=& \alpha + \beta x_t + \gamma x^2_t + \epsilon_t\\
	  y_t &=& \alpha + \beta \log x_t + \epsilon_t\\
	  \log y_t &=& \alpha + \beta \log x_t + \epsilon_t
         \end{eqnarray*}]]>
	</alt>
	<graphic fileref="figures/nonlin.png"/>
	</informalequation>

	Of course there are nonlinear relationships that cannot
	be reduced to linearity by this sort of change of variables:
	OLS cannot deal with these; more complex estimators are
	required. Of these additional estimators,
	<application>gretl</application> offers only the logit and
	probit models for a binomial dependent variable (but see also
	<xref linkend="ils"/> above for the use of iterated least
	squares in estimating nonlinear models).  As mentioned above,
	<application>gretl</application> can be complemented by GNU R
	or GNU Octave for further analysis of nonlinear relationships.
      </para>
    </section>

  </appendix>

  <appendix id="app-b"><title>Technical notes</title>

    <para>
      <application>Gretl</application> is written in the C programming
      language.  I have abided as far as possible by the ISO/ANSI C
      Standard (C89), although the graphical user interface and some
      other components necessarily make use of platform-specific
      extensions.
    </para>

    <para>
      <application>gretl</application> is being developed under Linux.
      The shared library and command-line client should compile and
      run on any platform that supports ISO/ANSI C and has the zlib
      compression library installed. The homepage for zlib can be
      found at <ulink
	url="http://www.info-zip.org/pub/infozip/zlib/">info-zip.org</ulink>. 
      If the GNU readline library is found on the host system this
      will be used for <application>gretcli</application>, providing a
      much enhanced editable command line. See the <ulink
	url="http://cnswww.cns.cwru.edu/~chet/readline/rltop.html">readline 
	homepage</ulink>.
    </para>

    <para> The graphical client program should compile and run on any
      system that, in addition to the above requirements, offers GTK
      version 1.2.3 or higher (see <ulink
	url="http://www.gtk.org/">gtk.org</ulink>).
    </para>

    <para>
      <application>gretl</application> calls gnuplot for graphing. You
      can find gnuplot at <ulink
	url="http://www.gnuplot.org/">gnuplot.org</ulink>.  As of this
      writing the curent version is 3.7.1.
    </para>

    <para>
      Some features of <application>gretl</application> (the built-in
      spreadsheet, the <quote>session</quote> icon window, some file
      selection dialogs) make use of Adrian Feguin's
      <application>gtkextra</application> library. You can find
      gtkextra at <ulink
	url="http://gtkextra.sourceforge.net/">gtkextra.sourceforge.net</ulink>. 
    </para>

    <para>
      A binary version of the program is available for the Microsoft
      Windows platform (32-bit version, i.e. Windows 95 or higher).
      This version was cross-compiled under Linux using mingw (the GNU
      C compiler, <application>gcc</application>, ported for use with
      win32) and linked against the Microsoft C library,
      <filename>msvcrt.dll</filename>.  It uses Tor Lillqvist's port
      of GTK to win32. The (free, open-source) Windows installer
      program is courtesy of Jordan Russell (<ulink
      url="http://www.jrsoftware.org/">jrsoftware.org</ulink>).
    </para>

    <para>I'm hopeful that some users with coding skills may consider
      <application>gretl</application> sufficiently interesting to be
      worth improving and extending.  To date I have not attempted to
      document the libgretl API (other than via the header files
      you'll find in the <filename>lib/src</filename> subdirectory of
      the source package).  But I welcome email on this subject and if
      there's sufficient interest I'll put some time into
      documentation. 
    </para>

  </appendix>

    <appendix id="app-c"><title>Advanced econometric analysis
	with free software</title>

      <para>As mentioned in the main text,
	<application>gretl</application> offers a reasonably full
	selection of least-squares based estimators, plus a few
	additional estimators sych as (binomial) logit and probit.
	Advanced users may, however, find
	<application>gretl</application>'s menu of statistical
	routines restrictive.</para>

      <para>No doubt some advanced users will prefer to write their
	own statistical code in a fundamental computer language such
	as C, C++ or Fortran.  Another option is to use a relatively
	high-level language that offers easy matrix manipulation and
	that already has numerous statistical routines built in, or
	available as add-on packages. If the latter option sounds
	attractive, and you are interested in using free, open source
	software, I would recommend taking a look at either GNU R
	(<ulink url="http://www.r-project.org/">r-project.org</ulink>)
	or (<ulink url="http://www.octave.org/">GNU Octave</ulink>).
	These programs are very close to the commercial programs S and
	Matlab respectively. 
      </para>

      <para>
	Also as mentioned above, <application>gretl</application>
	offers the facility of exporting data in the formats of both
	Octave and R.  In the case of Octave, the
	<application>gretl</application> data set is saved thus: the
	first variable listed for export is treated as the dependent
	variable and is saved as a vector, <varname>y</varname>, while
	the remaining variables are saved jointly as a matrix,
	<varname>X</varname>. You can pull the <varname>X</varname>
	matrix apart if you wish, once the data are loaded in Octave.
	See the Octave manual for details. As for R, the exported data
	file preserves any time series structure that is apparent to
	<application>gretl</application>. The series are saved as
	individual structures. The data should be brought into R using
	the <command>source()</command> command.
      </para>

      <para>
	Of these two programs, R is perhaps more likely to be of
	immediate interest to econometricians since it offers more in
	the way of statistical routines (e.g. generalized linear
	models, maximum likelihood estimation, time series methods).
	I have therefore supplied <application>gretl</application>
	with a convenience function for moving data quickly into R.
	Under <application>gretl</application>'s Session menu, you
	will find the entry <quote>Start GNU R</quote>.  This writes
	out an R version of the current
	<application>gretl</application> data set
	(<filename>Rdata.tmp</filename>, in the user's gretl
	directory), and sources it into a new R session. A few details
	on this follow.
      </para>

      <para>
	First, the data are brought into R by writing a temporary
	version of <filename>.Rprofile</filename> in the current
	working directory.  (If such a file exists it is referenced by
	R at startup.)  In case you already have a personal
	<filename>.Rprofile</filename> in place, the original file is
	temporarily moved to <filename>.Rprofile.gretltmp</filename>,
	and on exit from <application>gretl</application> it is
	restored.  (If anyone can suggest a cleaner way of doing this
	I'd be happy to hear of it.)
      </para>

      <para>
	Second, the particular way R is invoked depends on the
	internal <application>gretl</application> variable
	<varname>Rcommand</varname>, whose value may be set under the
	File, Preferences menu.  The default command is
	<command>RGui.exe</command> under MS Windows. Under X it is
	either <command>R --gui=gnome</command> if an installation of
	the Gnome desktop (<ulink
	  url="http://www.gnome.org/">gnome.org</ulink>) was detected
	at compile time, or <command>xterm -e R</command> if Gnome was
	not found. Please note that at most three
	space-separated elements in this command string will be
	processed; any extra elements are ignored.
      </para>

  </appendix>

  <appendix id="app-d"><title>Listing of URLs</title>

<para>Below is a listing of the full URLs of websites mentioned in the
      text, in their order of appearance.</para>

<variablelist>

<varlistentry><term>GNU R homepage</term>
 <listitem><para><ulink url="http://www.r-project.org/">
  <literal>http://www.r-project.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GNU Octave homepage</term>
 <listitem><para><ulink url="http://www.octave.org/">
  <literal>http://www.octave.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gretl homepage</term>
 <listitem><para><ulink url="http://gretl.sourceforge.net/">
  <literal>http://gretl.sourceforge.net/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Census Bureau, Data Extraction Service</term>
 <listitem><para><ulink url="http://www.census.gov/ftp/pub/DES/www/welcome.html">
  <literal>http://www.census.gov/ftp/pub/DES/www/welcome.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gretl data page</term>
 <listitem><para><ulink url="http://ricardo.ecn.wfu.edu/gretl/gretl_data.html">
  <literal>http://ricardo.ecn.wfu.edu/gretl/gretl_data.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Estima (RATS)</term>
 <listitem><para><ulink url="http://www.estima.com/">
  <literal>http://www.estima.com/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Penn World Table</term>
 <listitem><para><ulink url="http://pwt.econ.upenn.edu/">
  <literal>http://pwt.econ.upenn.edu/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gnuplot homepage</term>
 <listitem><para><ulink url="http://www.gnuplot.org/">
  <literal>http://www.gnuplot.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gnuplot online manual</term>
 <listitem><para><ulink url="http://ricardo.ecn.wfu.edu/gnuplot.html">
  <literal>http://ricardo.ecn.wfu.edu/gnuplot.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GNU Readline manual</term>
 <listitem><para><ulink url="http://cnswww.cns.cwru.edu/~chet/readline/readline.html">
  <literal>http://cnswww.cns.cwru.edu/~chet/readline/readline.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>NIST regression test main page</term>
 <listitem><para><ulink url="http://www.nist.gov/itl/div898/strd/general/main.html">
  <literal>http://www.nist.gov/itl/div898/strd/general/main.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>NIST data page</term>
 <listitem><para><ulink url="http://www.nist.gov/itl/div898/strd/general/dataarchive.html">
  <literal>http://www.nist.gov/itl/div898/strd/general/dataarchive.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>InfoZip homepage</term>
 <listitem><para><ulink url="http://www.info-zip.org/pub/infozip/zlib/">
  <literal>http://www.info-zip.org/pub/infozip/zlib/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GNU Readline homepage</term>
 <listitem><para><ulink url="http://cnswww.cns.cwru.edu/~chet/readline/rltop.html">
  <literal>http://cnswww.cns.cwru.edu/~chet/readline/rltop.html</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GTK+ homepage</term>
 <listitem><para><ulink url="http://www.gtk.org/">
  <literal>http://www.gtk.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gtkextra homepage</term>
 <listitem><para><ulink url="http://gtkextra.sourceforge.net/">
  <literal>http://gtkextra.sourceforge.net/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Mingw (gcc for win32) homepage</term>
 <listitem><para><ulink url="http://www.mingw.org/">
  <literal>http://www.mingw.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GTK+ port for win32</term>
 <listitem><para><ulink url="http://user.sgic.fi/~tml/gimp/win32/">
  <literal>http://user.sgic.fi/~tml/gimp/win32/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>JRSoftware</term>
 <listitem><para><ulink url="http://www.jrsoftware.org/">
  <literal>http://www.jrsoftware.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>Gnome desktop homepage</term>
 <listitem><para><ulink url="http://www.gnome.org/">
  <literal>http://www.gnome.org/</literal></ulink></para>
 </listitem>
</varlistentry>

<varlistentry><term>GNU R manual</term>
 <listitem><para><ulink url="http://cran.r-project.org/doc/manuals/R-intro.pdf">
  <literal>http://cran.r-project.org/doc/manuals/R-intro.pdf</literal></ulink></para>
 </listitem>
</varlistentry>

    </variablelist>

  </appendix>

<!-- Keep this comment at the end of the file
Local variables:
sgml-default-dtd-file:"../manual.ced"
mode: sgml
sgml-parent-document:("../manual.xml" "book" "chapter")
End:
-->

