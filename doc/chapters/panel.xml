<?PSGML NOFILL programlisting example informalequation?>

  <chapter id="chap-panel"><title>Panel data</title>

  <sect1 id="panel-structure"><title>Panel structure</title>

    <para>Panel data are inherently three dimensional &mdash; the
      dimensions being variable, cross-sectional unit, and
      time-period.  For representation in a textual computer file (and
      also for gretl's internal calculations) these three dimensions
      must somehow be flattened into two.  This
      <quote>flattening</quote> involves taking layers of the data
      that would naturally stack in a third dimension, and stacking
      them in the vertical dimension.</para>

    <para><application>Gretl</application> always expects data to be
      arranged <quote>by observation</quote>, that is, such that each
      row represents an observation (and each variable occupies one
      and only one column).  In this context the flattening of a panel
      data set can be done in either of two ways:</para>

    <itemizedlist>
      <listitem><para>
	  Stacked cross-sections: the successive vertical blocks each
	  comprise a cross-section for a given period.</para>
      </listitem>
      <listitem><para>
	  Stacked time-series: the successive vertical blocks each
	  comprise a time series for a given cross-sectional
	  unit.</para>
      </listitem>
    </itemizedlist>

    <para>You may use whichever arrangement is more convenient. Under
      <application>gretl</application>'s <guimenu>Sample</guimenu>
      menu you will find an item <quote>Restructure panel</quote>
      which allows you to convert from stacked cross section form to
      stacked time series.</para>

    <para>When you import panel data into
      <application>gretl</application> from a spreadsheet or comma
      separated format, the panel nature of the data will not be
      recognized automatically (most likely the data will be treated
      as <quote>undated</quote>).  Getting the data recognized
      correctly is a two-step process: first, establish the
      periodicity of the data and the starting observation; second,
      establish the structure of the data (stacked time series or
      stacked cross-sections).</para>

    <orderedlist>
      <listitem>
	<para>In the context of panel data the
	  <emphasis>periodicity</emphasis> equals the number of rows
	  per block of data.  In the case of stacked time series, this
	  is the number of time periods; in the case of stacked
	  cross-sections it is the number of cross-sectional units.
	</para> 
	<para>In most cases the <emphasis>starting
	    observation</emphasis> should be set as
	  <literal>1:1</literal>.  In this colon-separated pair of
	  numbers, the leading number represents the data-block and
	  the trailing number represents the entry within that block.
	  (Thus for example, with stacked time series the observation
	  label <literal>3:2</literal> denotes the observation for
	  unit 3, period 2.)</para>
	<para>The periodicity and starting observation can be set
	  using the script command <command>setobs</command> or the
	  GUI menu item <quote>Sample, Set frequency,
	    startobs&hellip;</quote>.</para>
      </listitem>
      <listitem>
	<para>Once the periodicity and starting observation are set
	  appropriately, you can impose the correct interpretation of
	  the data structure using the script command
	  <command>panel</command> or the GUI menu item <quote>Sample,
	    interpret as panel</quote>.  The <command>panel</command>
	  takes an option, either <literal>--time-series</literal>
	  (for stacked time series) or
	  <literal>--cross-section</literal> (for stacked
	  cross-sections).  If no option is given, stacked time series
	  is assumed.  The <quote>interpret as panel</quote> menu item
	  brings up a dialog box where you select stacked time series
	  or stacked cross sections.</para>
      </listitem>
    </orderedlist>

  </sect1>

  <sect1 id="dummies"><title>Dummy variables</title>

    <para>In a panel study you may wish to construct dummy variables
      of one or both of the following sorts: (a) dummies as unique
      identifiers for the cross-sectional units, and (b) dummies as
      unique identifiers for the time periods.  The former may be used
      to allow the intercept of the regression to differ across the
      units, the latter to allow the intercept to differ across
      periods.</para>

    <para>You can use three special functions to create such dummies.
      These are found under the <quote>Data, Add variables</quote>
      menu in the GUI, or under the <command>genr</command> command in
      script mode or <application>gretlcli</application>.</para>

    <orderedlist>
      <listitem><para><quote>periodic dummies</quote> (script command
	  <command>genr dummy</command>).  This command creates a set
	  of dummy variables identifying the periods.  The variable
	  <varname>dummy_1</varname> will have value 1 in each row
	  corresponding to a period 1 observation, 0 otherwise;
	  <varname>dummy_2</varname> will have value 1 in each row
	  corresponding to a period 2 observation, 0 otherwise; and so
	  on.</para>
      </listitem>
      <listitem><para><quote>unit dummies</quote> (script command
	  <command>genr unitdum</command>).  This command creates a
	  set of dummy variables identifying the cross-sectional
	  units.  The variable <varname>du_1</varname> will have value
	  1 in each row corresponding to a unit 1 observation, 0
	  otherwise; <varname>du_2</varname> will have value 1 in each
	  row corresponding to a unit 2 observation, 0 otherwise; and
	  so on.</para>
      </listitem>
      <listitem><para><quote>panel dummies</quote> (script command
	  <command>genr paneldum</command>).  This creates both period
	  and unit dummy variables. The unit dummies are named
	  <varname>du_1</varname>, <varname>du_2</varname> and so on,
	  while the period dummies are named <varname>dt_1</varname>,
	  <varname>dt_2</varname>, etc.</para>
      </listitem>
    </orderedlist>

    <para>If a panel data set has the <literal>YEAR</literal> of the
      observation entered as one of the variables you can create a
      periodic dummy to pick out a particular year, e.g. <command>genr
	dum = (YEAR=1960)</command>.  You can also create periodic
      dummy variables using the modulus operator,
      <literal>%</literal>.  For instance, to create a dummy with
      value 1 for the first observation and every thirtieth
      observation thereafter, 0 otherwise, do</para>

    <programlisting>
      genr index 
      genr dum = ((index-1)%30) = 0
    </programlisting>

  </sect1>

  <sect1 id="panel-lagged"><title>Lags and differences with panel
      data</title>

    <para>If the time periods are evenly spaced you may want to use
      lagged values of variables in a panel regression; you may also
      with to construct first differences of variables of
      interest.</para>

    <para>Once a dataset is properly identified as a panel (as
      described in the previous section),
      <application>gretl</application> will handle the generation of
      such variables correctly.  For example the command <command>genr
	x1_1 = x1(-1)</command> will create a variable that contains
      the first lag of <literal>x1</literal> where available, and the
      missing value code where the lag is not available.
    </para>

    <para>If a lag of this sort is to be included in a regression you
      must ensure that the first observation from each unit block is
      dropped. One way to achieve this is to use Weighted Least
      Squares (<command>wls</command>) using an appropriate dummy
      variable as weight.  This dummy (call it
      <command>lagdum</command>) should have value 0 for the
      observations to be dropped, 1 otherwise.  In other words, it is
      complementary to a dummy variable for period 1.  Thus if you
      have already issued the command <command>genr dummy</command>
      you can now do <command>genr lagdum = 1 - dummy_1</command>.  If
      you have used <command>genr paneldum</command> you would now say
      <command>genr lagdum = 1 - dt_1</command>. Either way, you can
      now do</para>

    <para>
      <command>wls lagdum y const x1_1 ...</command>
    </para>

    <para>to get a pooled regression using the first lag of
      <varname>x1</varname>, dropping all observations from period
      1.</para>

    <para>Another option is to use the <command>smpl</command> with
      the <command>--restrict</command> or <command>--dummy</command>
      option.
      <xref linkend="examp-pwt"/> shows illustrative commands,
      assuming the unit data blocks each contain 30 observations and
      we want to drop the first row of each.  You can then run
      regressions on the restricted data set without having to use the
      <command>wls</command> command.  If you plan to reuse the
      restricted data set you may wish to save it using the
      <command>store</command> command (see <xref
	linkend="cmdref"/> below).
    </para>

    <example id="examp-panel-lags">
      <title>Lags with panel data</title>
    <programlisting>
      # create index variable 
      genr index 
      # create dum = 0 for every 30th obs 
      genr dum = ((index-1)%30) > 0 
      # sample based on this dummy
      smpl --dummy dum 
      # recreate the obs. structure, for 29 periods
      setobs 29 1.01 
    </programlisting>
    </example>

  </sect1>

  <sect1 id="pooled-est"><title>Pooled estimation</title>

    <para>There is a special purpose estimation command for use with
      panel data, the <quote>Pooled OLS</quote> option under the
      <guimenu>Model</guimenu> menu. This command is available only if
      the data set is recognized as a panel.  To take advantage of it,
      you should specify a model without any dummy variables
      representing cross-sectional units.  The routine presents
      estimates for straightforward pooled OLS, which treats
      cross-sectional and time-series variation at par.  This model
      may or may not be appropriate.  Under the
      <guimenu>Tests</guimenu> menu in the model window, you will find
      an item <quote>panel diagnostics</quote>, which tests pooled OLS
      against the principal alternatives, the fixed effects and random
      effects models.</para>

    <para>The fixed effects model adds a dummy variable for all but
      one of the cross-sectional units, allowing the intercept of the
      regression to vary across the units.  An
      <emphasis>F</emphasis>-test for the joint significance of these
      dummies is presented: if the p-value for this test is small,
      that counts against the null hypothesis (that the simple pooled
      model is adequate) and in favor of the fixed effects
      model.</para>

    <para>The random effects model, on the other hand, decomposes the
      residual variance into two parts, one part specific to the
      cross-sectional unit or <quote>group</quote> and the other
      specific to the particular observation.  (This estimator can be
      computed only if the panel is <quote>wide</quote> enough, that
      is, if the number of cross-sectional units in the data set
      exceeds the number of parameters to be estimated.)  The
      Breusch&ndash;Pagan LM statistic tests the null hypothesis
      (again, that the pooled OLS estimator is adequate) against the
      random effects alternative.</para>

    <para>It is quite possible that the pooled OLS model is rejected
      against both of the alternatives, fixed effects and random
      effects. How, then, to assess the relative merits of the two
      alternative estimators?  The Hausman test (also reported,
      provided the random effects model can be estimated) addresses
      this issue.  Provided the unit- or group-specific error is
      uncorrelated with the independent variables, the random effects
      estimator is more efficient than the fixed effects estimator;
      otherwise the random effects estimator is inconsistent, in which
      case the fixed effects estimator is to be preferred.  The null
      hypothesis for the Hausman test is that the group-specific error
      is not so correlated (and therefore the random effects model is
      preferable).  Thus a low p-value for this tests counts against
      the random effects model and in favor of fixed effects.</para>

    <para>For a rigorous discussion of this topic, see Greene (2000),
      chapter 14.</para>

  </sect1>

  <sect1 id="PWT"><title>Illustration: the Penn World Table</title>

    <para>The Penn World Table (homepage at <ulink
	url="http://pwt.econ.upenn.edu/">pwt.econ.upenn.edu</ulink>)
      is a rich macroeconomic panel dataset, spanning 152 countries
      over the years 1950&ndash;1992.  The data are available in
      <application>gretl</application> format; please see the
      <application>gretl</application> <ulink
	url="http://ricardo.ecn.wfu.edu/gretl/gretl_data.html">data
	site</ulink> (this is a free download, although it is not
      included in the main <application>gretl</application>
      package).</para>  

    <para><xref linkend="examp-pwt"/> below opens
      <filename>pwt56_60_89.gdt</filename>, a subset of the pwt
      containing data on 120 countries, 1960&ndash;89, for 20
      variables, with no missing observations (the full data set,
      which is also supplied in the pwt package for
      <application>gretl</application>, has many missing
      observations). Total growth of real GDP, 1960&ndash;89, is
      calculated for each country and regressed against the 1960 level
      of real GDP, to see if there is evidence for
      <quote>convergence</quote> (i.e. faster growth on the part of
      countries starting from a low base).</para>

    <example id="examp-pwt">
      <title>Use of the Penn World Table</title>
      <programlisting>
	  open pwt56_60_89.gdt 
	  # for 1989 (the last obs), lag 29 gives 1960, the first obs 
	  genr gdp60 = RGDPL(-29) 
	  # find total growth of real GDP over 30 years
	  genr gdpgro = (RGDPL - gdp60)/gdp60
	  # restrict the sample to a 1989 cross-section 
	  smpl --restrict YEAR=1989 
	  # convergence: did countries with a lower base grow faster?  
	  ols gdpgro const gdp60 
	  # result: No! Try an inverse relationship?
	  genr gdp60inv = 1/gdp60 
	  ols gdpgro const gdp60inv 
	  # no again.  Try treating Africa as special? 
	  genr afdum = (CCODE = 1)
	  genr afslope = afdum * gdp60 
	  ols gdpgro const afdum gdp60 afslope 
      </programlisting>
    </example>
  </sect1>

  </chapter>

<!-- Keep this comment at the end of the file
Local variables:
sgml-default-dtd-file:"../manual.ced"
mode: xml
sgml-parent-document:("../manual.xml" "book" "chapter")
End:
-->

