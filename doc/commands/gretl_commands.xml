<?xml version="1.0"?>
<!DOCTYPE commandlist SYSTEM "gretl_commands.dtd">
<commandlist language="english">

<?PSGML NOFILL blurb code altforms altform menu-path other-access?>

  <command name="add" section="Tests">

    <usage>
      <blurb>Add variables to a model and test for their significance</blurb>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
      <examples>
        <example>add 5 7 9</example>
        <example>add xx yy zz</example>
      </examples>
    </usage>

    <description>
      <para>
	Must be invoked after an estimation command.  The variables in
	<repl>varlist</repl> are added to the previous model and the
	new model estimated.  If more than one variable is added, the
	<mathvar>F</mathvar> statistic for the added variables will be
	printed (for the OLS procedure only) along with its p-value.
	A p-value below 0.05 means that the coefficients are jointly
	significant at the 5 percent level. 
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/add variables</menu-path>
    </gui-access>

  </command>

  <command name="addto" section="Tests">

    <usage>
      <arguments>
        <argument>modelID</argument>
	<argument>varlist</argument>
      </arguments>
      <examples>
        <example>addto 2 5 7 9</example>
      </examples>
    </usage>

    <description>
      <para>
	Works like the <cmd>add</cmd> command, except that you specify
	a previous model (using its ID number, which is printed at the
	start of the model output) to take as the base for adding
	variables.  The example above adds variables number 5, 7 and 9
	to Model 2.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/add variables</menu-path>
    </gui-access>

  </command>

  <command name="adf" section="Tests">

    <usage>
      <blurb>Augmented Dickey-Fuller test</blurb>
      <arguments>
        <argument>order</argument>
        <argument>varname</argument>
      </arguments>
      <examples>
        <example>adf 2 x1</example>
      </examples>
    </usage>

    <description>
      <para>
	  Computes statistics for two Dickey&ndash;Fuller tests.  In
	each case the null hypothesis is that the variable in question
	exhibits a unit root. The first is a <mathvar>t</mathvar>-test
	based on the model 
	  <equation status="display"
	  tex="\[(1-L)x_t=m+gx_{t-1}+\epsilon_t\]"
	  ascii="(1 - L)x(t) = m + gx(t-1) + e(t)"
	  graphic="adf1"/> The null hypothesis is that
	<mathvar>g</mathvar> = 0. The second (augmented) test proceeds
	by estimating an unrestricted regression (with regressors a
	constant, a time trend, the first lag of the variable, and
	<repl>order</repl> lags of the first difference) and a
	restricted version (dropping the time trend and the first
	lag).  The test statistic is
	  <equation status="display"
	  tex="\[F_{2,T-k}=\frac{(ESS_r-ESS_u)/2}{ESS_u/(T-k)}\]"
	  ascii="F(2, T-k) = [(ESSr - ESSu)/2] / [ESSu/(T - k)]"
	  graphic="adf2"/> where <mathvar>T</mathvar> is the sample
	size, <mathvar>k</mathvar> the number of parameters in the
	unrestricted model, and the subscripts <mathvar>u</mathvar>
	and <mathvar>r</mathvar> denote the unrestricted and
	restricted models respectively. Note that the critical values
	for these statistics are not the usual ones; a p-value range
	is printed, when it can be determined.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Augmented Dickey-Fuller test</menu-path>
    </gui-access>

  </command>

  <command name="ar" section="Estimation">

    <usage>
      <blurb>Generalized Cochrane-Orcutt (autoregressive) estimation</blurb>
      <arguments>
        <argument>lags</argument>
        <argument separated="true">indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
      <examples>
        <example>ar 1 3 4 ; y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Computes parameter estimates using the generalized
	Cochrane&ndash;Orcutt iterative procedure (see Section 9.5 of
	Ramanathan). Iteration is terminated when successive error
	sums of squares do not differ by more than 0.005 percent or
	after 20 iterations. <repl>lags</repl> is a list of lags in
	the residuals, terminated by a semicolon. In the above
	example, the error term is specified as 
	<equation status="display" 
	  tex="\[u_t = \rho_1u_{t-1} + \rho_3 u_{t-3} +
	    \rho_4 u_{t-4} + e_t\]"
	  ascii="u(t) = rho(1)*u(t-1) + rho(3)+u(t-3) + rho(4)*u(t-4)"
	  graphic="corc"/> where <repl>depvar</repl> is the dependent
	variable and <repl>indepvars</repl> is the list of independent
	variables.  
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Autoregressive estimation</menu-path>
    </gui-access>

  </command>

  <command name="arch" section="Tests">

    <usage>
      <blurb>Test for ARCH (Autoregressive Conditional Heteroskedasticity)</blurb>
      <arguments>
        <argument>order</argument>
        <argument>depvar</argument>
	<argument>indepvars</argument>
      </arguments>
      <examples>
        <example>arch 4 y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Tests the model for ARCH (Autoregressive Conditional
	Heteroskedasticity) of the (integer) lag order specified in
	<repl>order</repl>. If the LM test statistic has p-value below
	0.10, then ARCH estimation is also carried out.  If the
	predicted variance of any observation in the auxiliary
	regression is not positive, then the corresponding squared
	residual is used instead. Weighted least square estimation is
	then performed on the original model.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/ARCH</menu-path>
    </gui-access>

  </command>

  <command name="arma" section="Estimation">

    <usage>
      <blurb>Univariate ARMA model</blurb>
      <arguments>
        <argument>p</argument>
	<argument>q</argument>
	<argument separated="true">depvar</argument>
      </arguments>
      <options>
        <option>
	  <flag>--native</flag>
	  <effect>Use native plugin (default)</effect>
        </option>
        <option>
	  <flag>--x-12-arima</flag>
	  <effect>use X-12-ARIMA for estimation</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>print details of iterations</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
        </option>
      </options>
      <examples>
        <example>arma 1 2 ; y</example>
	<example>arma 2 2 ; y --verbose</example>
      </examples>
    </usage>

    <description>
      <para>
	Estimates a univariate ARMA (Autoregressive, Moving Average)
	model.  The integer values <repl>p</repl> and <repl>q</repl>
	represent the AR and MA orders respectively. 
      </para>

      <para>The default is to use the <quote>native</quote> gretl ARMA
	function; the <lit>--x-12-arima</lit> flag calls for use of
	the <program>X-12-ARIMA</program> program instead (this will
	work only if the <program>X-12-ARIMA</program> package for
	gretl is installed).  
      </para>

      <para>The options given above may be combined, except that the
	covariance matrix is not available when estimation is by
	<program>X-12-ARIMA</program>.</para>

      <para>The native gretl ARMA algorithm is largely due to Riccardo
	<quote>Jack</quote> Lucchetti.  It uses a conditional maximum
	likelihood procedure, implemented via iterated least squares
	estimation of the outer product of the gradient (OPG)
	regression.  See <manref targ="jack-arma"/> for the logic of
	the procedure.  The AR coefficients are initialized using an
	OLS auto-regression, and the MA coefficients are initialized
	at zero.</para>

      <para>The AIC value given in connection with ARMA models is
	calculated according to the definition used in
	<program>X-12-ARIMA</program>, namely
	  <equation status="display" 
	  tex="\[\mbox{AIC}=-2L+2k\]"
	  ascii="AIC = -2L + 2k"
	  graphic="aic"/> where <mathvar>L</mathvar> is the
	log-likelihood and <mathvar>k</mathvar> is the total number of
	parameters estimated. The <quote>frequency</quote> figure
	printed in connection with AR and MA roots is the &lgr; value
	that solves
	  <equation status="display" 
	  tex="\[z=re^{i2\pi\lambda}\]"
	  ascii="z = r * exp(i*2*pi*lambda)"
	  graphic="lambda"/> where <mathvar>z</mathvar> is the root in
	question and <mathvar>r</mathvar> is its modulus.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/ARMA model</menu-path>
      <other-access>Main window pop-up menu (single selection)</other-access>
    </gui-access>

  </command>

  <command name="boxplot" section="Graphs">

    <usage>
      <blurb>Exploratory data analysis</blurb>
      <arguments>
        <argument>varname</argument>
      </arguments>
    </usage>

    <description><para>
	This command is available in the gretl console, but not in the
	command-line program.</para>

      <para>Boxplots (after Tukey and Chambers) display the
	distribution of a variable. The central box encloses the
	middle 50 percent of the data, i.e. it is bounded by the first
	and third quartiles. The <quote>whiskers</quote> extend to the
	minimum and maximum values.  A line is drawn across the box at
	the median.</para>

      <para>See <manref targ="sect-boxplots"/> for further details.</para>
    </description>

    <gui-access>
      <menu-path>/Data/Graph specified vars/Boxplots</menu-path>
    </gui-access>

  </command>

  <command name="chow" section="Tests">

    <usage>
      <blurb>Chow test for structural homogeneity</blurb>
      <arguments>
        <argument>obs</argument>
      </arguments>
      <examples>
        <example>chow 25</example>
        <example>chow 1988:1</example>
      </examples>
    </usage>

    <description>
      <para>
	Must follow an OLS regression.  Creates a dummy variable which
	equals 1 from the split point specified by <repl>obs</repl> to
	the end of the sample, 0 otherwise, and also creates
	interaction terms between this dummy and the original
	independent variables.  An augmented regression is run
	including these terms and an <mathvar>F</mathvar> statistic is
	calculated, taking the augmented regression as the
	unrestricted and the original as restricted.  This statistic
	is appropriate for testing the null hypothesis of no
	structural break at the given split point.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/Chow test</menu-path>
    </gui-access>

  </command>

  <command name="coeffsum" section="Tests">

    <usage>
      <blurb>Test for the sum of specified coefficients</blurb>
      <arguments>
        <argument>indepvars</argument>
      </arguments>
      <examples>
        <example>coeffsum xt xt_1 xr_2</example>
      </examples>
    </usage>

    <description>
      <para>
	Must follow a regression.  Calculates the sum of the
	coefficients on the variables in the <repl>indepvars</repl>
	list.  Prints this sum along with its standard error and the
	p-value for the null hypothesis that the sum is zero.  Note the
	difference between this and <cmdref targ="omit"/>, which tests
	the null hypothesis that the coefficients on a specified
	subset of independent variables are all equal to zero.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/sum of coefficients</menu-path>
    </gui-access>

  </command>

  <command name="coint" section="Tests">

    <usage>
      <blurb>Engle-Granger cointegration test</blurb>
      <arguments>
        <argument>order</argument>
        <argument>depvar</argument>
	<argument>indepvars</argument>
      </arguments>
      <examples>
        <example>coint 2 y x</example>
	<example>coint 4 y x1 x2</example>
      </examples>
    </usage>

    <description>
      <para>
	The Engle&ndash;Granger cointegration test.  Carries out
	Augmented Dickey&ndash;Fuller tests on the null hypothesis
	that each of the variables listed has a unit root, using the
	given lag order.  The cointegrating regression is estimated,
	and an ADF test is run on the residuals from this regression.
	The Durbin&ndash;Watson statistic for the cointegrating
	regression is also given.  Note that none of these test
	statistics can be referred to the usual statistical tables.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Cointegration test/Engle-Granger</menu-path>
    </gui-access>

  </command>

  <command name="coint2" section="Tests">

    <usage>
      <blurb>Johansen cointegration test</blurb>
      <arguments>
        <argument>order</argument>
        <argument>depvar</argument>
	<argument>indepvars</argument>
      </arguments>
      <options>
        <option>
	  <flag>--verbose</flag>
	  <effect>print details of auxiliary regressions</effect>
        </option>
      </options>
      <examples>
        <example>coint2 2 y x</example>
	<example>coint2 4 y x1 x2 --verbose</example>
      </examples>
    </usage>

    <description>
      <para>
	Carries out the Johansen trace test for cointegration among
	the listed variables for the given order. Critical values are
	computed via J. Doornik's gamma approximation (Doornik, 1998).
	For details of this test see Hamilton, <book>Time Series
	Analysis</book> (1994), Chapter 20.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Cointegration test/Johansen</menu-path>
    </gui-access>

  </command>

  <command name="corc" section="Estimation">

    <usage>
      <arguments>
	<blurb>Cochrane-Orcutt estimation</blurb>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
      <examples>
        <example>corc 1 0 2 4 6 7</example>
      </examples>
    </usage>

    <description>
      <para>
	Computes parameter estimates using the Cochrane&ndash;Orcutt
	iterative procedure (see Section 9.4 of Ramanathan) with
	<repl>depvar</repl> as the dependent variable and
	<repl>indepvars</repl> as the list of independent variables.
	Iteration is terminated when successive estimates of the
	autocorrelation coefficient do not differ by more than 0.001
	or after 20 iterations.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Cochrane-Orcutt</menu-path>
    </gui-access>

  </command>

  <command name="corr" section="Statistics">

    <usage>
      <arguments>
        <argument optional="true">varlist</argument>
      </arguments>
      <examples>
        <example>corr y x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Prints the pairwise correlation coefficients for the variables
	in <repl>varlist</repl>, or for all variables in the data set
	if <repl>varlist</repl> is not given.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Correlation matrix</menu-path>
      <other-access>Main window pop-up menu (multiple selection)</other-access>
    </gui-access>

  </command>

  <command name="corrgm" section="Statistics">

    <usage>
      <arguments>
        <argument>variable</argument>
        <argument optional="true">maxlag</argument>
      </arguments>
      <examples>
        <example>corrgm x 12</example>
      </examples>
    </usage>

    <description>
      <para>
	Prints the values of the autocorrelation function for the
	<repl>variable</repl> specified (either by name or number).
	See Ramanathan, Section 11.7.  It is thus
	<equation status="inline" 
	  tex="$\rho(u_t, u_{t-s})$"
	  ascii="rho(u(t), u(t-s))"
	  graphic="autocorr"/> where <mathvar>u<sub>t</sub></mathvar>
	is the <mathvar>t</mathvar>th observation of the variable
	<mathvar>u</mathvar> and <mathvar>s</mathvar> is the number of
	lags.
      </para>

      <para>
	The partial autocorrelations are also shown: these are net of
	the effects of intervening lags.  The command also graphs the
	correlogram and prints the Box&ndash;Pierce
	<mathvar>Q</mathvar> statistic for testing the null hypothesis
	that the series is <quote>white noise</quote>. This is
	asymptotically distributed as chi-square with degrees of
	freedom equal to the number of lags used.
      </para>

      <para>
	If a <repl>maxlag</repl> value is specified the length of the
	correlogram is limited to at most that number of lags,
	otherwise the length is determined automatically.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Correlogram</menu-path>
      <other-access>Main window pop-up menu (single selection)</other-access>
    </gui-access>

  </command>

  <command name="criteria" section="Utilities">

    <usage>
      <arguments>
        <argument>ess</argument>
        <argument>T</argument>
        <argument>k</argument>
      </arguments>
      <examples>
        <example>criteria 23.45 45 8</example>
      </examples>
    </usage>

    <description>
      <para>
	Computes the model selection statistics (see Ramanathan,
	Section 4.3), given <repl>ess</repl> (error sum of squares),
	the number of observations (<mathvar>T</mathvar>), and the
	number of coefficients (<mathvar>k</mathvar>).
	<mathvar>T</mathvar>, <mathvar>k</mathvar>, and
	<repl>ess</repl> may be numerical values or names of
	previously defined variables.
      </para>
    </description>

  </command>

  <command name="critical" section="Utilities">

    <usage>
      <arguments>
        <argument>dist</argument>
        <argument>param1</argument>
	<argument optional="true">param2</argument>
      </arguments>
      <examples>
        <example>critical t 20</example>
        <example>critical X 5</example>
        <example>critical F 3 37</example>
      </examples>
    </usage>

    <description>
      <para>If <repl>dist</repl> is <lit>t</lit>, <lit>X</lit> or
	<lit>F</lit>, prints out the critical values for the student's
	<mathvar>t</mathvar>, chi-square or <mathvar>F</mathvar>
	distribution respectively, for the common significance levels
	and using the specified degrees of freedom, given as
	<repl>param1</repl> for t and chi-square, or
	<repl>param1</repl> and <repl>param2</repl> for
	<mathvar>F</mathvar>. If <repl>dist</repl> is <lit>d</lit>,
	prints the upper and lower values of the Durbin-Watson
	statistic at 5 percent significance, for the given number of
	observations, <repl>param1</repl>, and for the range of 1 to 5
	explanatory variables.
      </para>
    </description>

    <gui-access>
      <menu-path>/Utilities/Statistical tables</menu-path>
    </gui-access>

  </command>

  <command name="cusum" section="Tests">

    <description>
      <para>
	Must follow the estimation of a model via OLS.  Performs the
	CUSUM test for parameter stability.  A series of (scaled)
	one-step ahead forecast errors is obtained by running a series
	of regressions: the first regression uses the first
	<mathvar>k</mathvar> observations and is used to generate a
	prediction of the dependent variable at observation at
	observation <mathvar>k</mathvar> + 1; the second uses the
	first <mathvar>k</mathvar> + 1 observations and generates a
	prediction for observation <mathvar>k</mathvar> + 2, and so on
	(where <mathvar>k</mathvar> is the number of parameters in the
	original model).  The cumulated sum of the scaled forecast
	errors is printed and graphed.  The null hypothesis of
	parameter stability is rejected at the 5 percent significance
	level if the cumulated sum strays outside of the 95 percent
	confidence band.
      </para>

      <para>
	The Harvey&ndash;Collier <mathvar>t</mathvar>-statistic for
	testing the null hypothesis of parameter stability is also
	printed.  See Chapter 7 of Greene's <book>Econometric
	  Analysis</book> for details.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/CUSUM</menu-path>
    </gui-access>

  </command>

  <command name="data" section="Dataset">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>Reads the variables in <repl>varlist</repl> from a
	database (gretl or RATS 4.0), which must have been opened
	previously using the <cmdref targ="open"/> command. In
	addition, a data frequency and sample range must be
	established using the the <cmdref targ="setobs"/> and <cmdref
	  targ="smpl"/> commands
	prior to using this command. Here is a full example:</para>

      <code>
	open macrodat.rat
	setobs 4 1959:1
	smpl ; 1999:4
	data GDP_JP GDP_UK</code>

      <para>These commands open a database named
	<filename>macrodat.rat</filename>, establish a quarterly data
	set starting in the first quarter of 1959 and ending in the
	fourth quarter of 1999, and then import the series named
	<lit>GDP_JP</lit> and <lit>GDP_UK</lit>.</para>

      <para>If the series to be read are of higher frequency than the
	working data set, you must specify a compaction method as
	below:</para>

      <code>
	data (compact=average) 
	LHUR PUNEW</code>

      <para>The four available compaction methods are
	<quote>average</quote> (takes the mean of the high frequency
	observations), <quote>last</quote> (uses the last
	observation), <quote>first</quote> and <quote>sum</quote>.
      </para> 

    </description>

    <gui-access>
      <menu-path>/File/Browse databases</menu-path>
    </gui-access>

  </command>

  <command name="delete" section="Dataset">

    <usage>
      <arguments>
        <argument optional="true">varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>Removes the listed variables (given by name or number)
	from the dataset. <emphasis>Use with caution</emphasis>: no
	confirmation is asked, and any variables with higher ID
	numbers will be re-numbered.</para>

      <para>If no <repl>varlist</repl> is given with this command, it
	deletes the last (highest numbered) variable from the
	dataset.</para>
    </description>

    <gui-access>
      <menu-path>Main window pop-up (single selection)</menu-path>
    </gui-access>

  </command>

  <command name="diff" section="Transformations">

    <usage>
      <blurb>First differences</blurb>
      <arguments>
        <argument>varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>
	The first difference of each variable in <repl>varlist</repl>
	is obtained and the result stored in a new variable with the
	prefix <lit>d_</lit>.  Thus <cmd>diff x y</cmd> creates the
	new variables <lit>d_x = x(t) - x(t-1)</lit> and <lit>d_y =
	  y(t) - y(t-1)</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Add variables/first differences</menu-path>
    </gui-access>

  </command>

  <command name="else" section="Programming">

    <description><para>See <cmdref targ="if"/>.</para>
    </description>

  </command>

  <command name="end" section="Programming">

    <description>
      <para>
	Ends a block of commands of some sort.  For example, <cmd>end
	  system</cmd> terminates an equation <cmdref targ="system"/>.
      </para>
    </description>

  </command>

  <command name="endif" section="Programming">

    <description><para>See <cmdref targ="if"/>.</para>
    </description>

  </command>

  <command name="endloop" section="Programming">

    <description>
      <para>
	Marks the end of a command loop.  See <cmdref targ="loop"/>.
      </para>
    </description>

  </command>

  <command name="eqnprint" section="Printing">

    <usage>
      <arguments>
        <argument optional="true">-f filename</argument>
      </arguments>
      <options>
        <option>
	  <flag>--complete</flag>
	  <effect>Create a complete document</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Must follow the estimation of a model.  Prints the estimated
	model in the form of a &latex; equation.  If a filename is
	specified using the <lit>-f</lit> flag output goes to that
	file, otherwise it goes to a file with a name of the form
	<filename>equation_N.tex</filename>, where <lit>N</lit> is the
	number of models estimated to date in the current session.
	See also <cmdref targ="tabprint"/>.
      </para>

      <para>
	If the <lit>--complete</lit> flag is given, the &latex; file is
	a complete document, ready for processing; otherwise it must
	be included in a document.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /LaTeX</menu-path>
    </gui-access>

  </command>

  <command name="equation" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <examples>
        <example>equation y x1 x2 x3 const</example>
      </examples>
    </usage>

    <description>
      <para>
	Specifies an equation within a system of equations (see 
	<cmdref targ="system"/>).  The syntax for specifying an
	equation is the same as that for, e.g., 
	<cmdref targ="ols"/>.
      </para>
    </description>

  </command>

  <command name="fcast" section="Prediction">

    <usage>
      <arguments>
        <argument optional="true" >startobs endobs</argument>
	<argument>fitvar</argument>
      </arguments>
      <examples>
        <example>fcast 1997:1 2001:4 f1</example>
	<example>fcast fit2</example>
      </examples>
    </usage>

    <description>
      <para>
	Must follow an estimation command.  Forecasts are generated
	for the specified range (or the largest possible range if no
	<repl>startobs</repl> and <repl>endobs</repl> are given) and
	the values saved as <repl>fitvar</repl>, which can be
	printed, graphed, or plotted. The right-hand side variables
	are those in the original model.  There is no provision to
	substitute other variables.  If an autoregressive error
	process is specified (for <cmd>hilu</cmd>, <cmd>corc</cmd>,
	and <cmd>ar</cmd>) the forecast is conditional one step ahead
	and incorporates the error process.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Model data/Forecasts</menu-path>
    </gui-access>

  </command>

  <command name="fcasterr" section="Prediction">

    <usage>
      <blurb>Forecasts with confidence intervals</blurb>
      <arguments>
        <argument>startobs</argument>
        <argument>endobs</argument>
      </arguments>
      <options>
        <option>
	  <flag>--plot</flag>
	  <effect>display graph</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	After estimating an OLS model which includes a constant and at
	least one independent variable (these restrictions may be
	relaxed at some point) you can use this command to print out
	fitted values over the specified observation range, along with
	the estimated standard errors of those predictions and 95
	percent confidence intervals.  The augmented regression method
	of Salkever (1976) is used to generate the forecast standard
	errors.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Model data/Forecasts</menu-path>
    </gui-access>

  </command>

  <command name="fit" section="Prediction">

    <description>
      <para>
	A shortcut to <cmd>fcast</cmd>. Must follow an estimation
	command.  Generates fitted values, in a series called
	<lit>autofit</lit>, for the current sample, based on the last
	regression.  In the case of time-series models, also pops up a
	graph of fitted and actual values of the dependent variable
	against time.
      </para>
    </description>

  </command>

  <command name="freq" section="Statistics">

    <usage>
      <arguments>
        <argument>var</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Prints the frequency distribution for <repl>var</repl> (given
	by name or number); also shows the results of the
	Doornik&ndash;Hansen chi-square test for normality. In
	interactive mode a graph of the distribution is displayed.  
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Frequency distribution</menu-path>
    </gui-access>

  </command>

  <command name="genr" section="Dataset">

    <usage>
      <blurb>Generate a new variable</blurb>
      <arguments>
        <argument>newvar</argument>
        <argument>= formula</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Creates new variables, usually through transformations of
	existing variables. See also <cmdref targ="diff"/>, <cmdref targ="logs"/>,
	<cmdref targ="lags"/>, <cmdref targ="ldiff"/>, <cmdref targ="multiply"/> and
	<cmdref targ="square"/> for shortcuts.
      </para>

      <para>
	Supported <emphasis>arithmetical operators</emphasis> are, in
	order of precedence: <lit>^</lit> (exponentiation);
	<lit>*</lit>, <lit>/</lit> and <lit>%</lit> (modulus or
	remainder); <lit>+</lit> and <lit>-</lit>. 
      </para>

      <para>
	The available <emphasis>Boolean operators</emphasis> are
	(again, in order of precedence): <lit>!</lit> (negation),
	<lit>&amp;</lit> (logical AND), <lit>|</lit> (logical OR),
	<lit>&gt;</lit>, <lit>&lt;</lit>, <lit>=</lit>,
	<lit>&gt;=</lit> (greater than or equal), <lit>&lt;=</lit>
	(less than or equal) and <lit>!=</lit> (not equal).  The
	Boolean operators can be used in constructing dummy variables:
	for instance <lit>(x > 10)</lit> returns 1 if <lit>x</lit>
	&gt; 10, 0 otherwise.</para>

      <para>Supported <emphasis>functions</emphasis> fall into these
	groups:
      </para>

      <ilist>
	<li><para>Standard math functions: <func>abs</func>,
	    <func>cos</func>, <func>exp</func>, <func>int</func>
	    (integer part), <func>ln</func> (natural log:
	    <func>log</func> is a synonym), <func>sin</func>,
	    <func>sqrt</func>.</para>
	</li>
	<li><para>Statistical functions: <func>max</func> (maximum
	    value in a series), <func>min</func> (minimum),
	    <func>mean</func> (arithmetic mean), <func>median</func>,
	    <func>var</func> (variance) <func>sd</func> (standard
	    deviation), <func>sst</func> (sum of squared deviations
	    from the mean), <func>sum</func>, <func>cov</func>
	    (covariance), <func>corr</func> (correlation coefficient),
	    <func>pvalue</func>, <func>sort</func>, <func>cum</func>
	    (cumulate, or running sum).</para>
	</li>
	<li><para>Time-series functions: <func>diff</func> (first
	    difference), <func>ldiff</func> (log-difference, or first
	    difference of natural logs).  To generate lags of a
	    variable <lit>x</lit>, use the syntax <cmd>x(-N)</cmd>,
	    where <lit>N</lit> represents the desired lag length; to
	    generate leads, use <cmd>x(+N)</cmd>.</para>
	</li>
	<li><para>Dataset functions: <func>misszero</func> (replace
	    the missing observation code in a given series with
	    zeros), <func>zeromiss</func> (the inverse operation to
	    <func>misszero</func>), <func>nobs</func> (return the
	    number of valid observations in a given data series),
	    <func>missing</func> (at each observation, 1 if the
	    argument has a missing value, 0 otherwise).</para>
	</li>
	<li><para>Pseudo-random numbers: <func>uniform</func>,
	    <func>normal</func>.</para>
	</li>
      </ilist> 

      <para>
	All of the above functions with the exception of
	<func>cov</func>, <func>corr</func>, <func>pvalue</func>,
	<func>uniform</func> and <func>normal</func> take as their
	single argument either the name of a variable (note that you
	can't refer to variables by their ID numbers in a
	<cmd>genr</cmd> formula) or an expression that evaluates to a
	variable (e.g. <lit>ln((x1+x2)/2)</lit>). <func>cov</func> and
	<func>corr</func> both require two arguments, and return
	respectively the covariance and the correlation coefficient
	between the arguments. The <func>pvalue</func> function takes
	the same arguments as the <cmdref targ="pvalue"/> command, but
	in this context commas should be placed between the arguments.
	<func>uniform()</func> and <func>normal()</func>, which do not
	take arguments, return pseudo-random series drawn from the
	uniform (0&ndash;1) and standard normal distributions
	respectively (see also the
	<cmdref targ="set"/> command, <lit>seed</lit> option).
	Uniform series are generated using the Mersenne
	Twister;<footnote><para>See Matsumoto and
	    Nishimura (1998).  The implementation is provided by
	    <program>glib</program>, if available, or by the C code
	    written by Nishimura and Matsumoto.</para></footnote> for
	normal series the method of Box and Muller (1958) is used,
	taking input from the Mersenne Twister.</para>

      <para>Besides the operators and functions just noted there are
	some special uses of <cmd>genr</cmd>:
      </para>

      <ilist>
	<li><para><cmd>genr time</cmd> creates a time trend variable
	    (1,2,3,&hellip;) called <cmd>time</cmd>. <cmd>genr
	      index</cmd> does the same thing except that the variable
	    is called <lit>index</lit>.</para>
	</li>
	<li><para><cmd>genr dummy</cmd> creates dummy variables up to
	    the periodicity of the data.  E.g. in the case of
	    quarterly data (periodicity 4), the program creates
	    <lit>dummy_1</lit> = 1 for first quarter and 0 in other
	    quarters, <lit>dummy_2</lit> = 1 for the second quarter
	    and 0 in other quarters, and so on.</para>
	</li>
	<li><para><cmd>genr paneldum</cmd> creates a set of special
	    dummy variables for use with a panel data set &mdash; see
	    <cmdref targ="panel"/>.</para>
	</li>
	<li><para>Various internal variables defined in the course of
	    running a regression can be retrieved using
	    <cmd>genr</cmd>, as follows:</para>

	  <table lwidth="100pt" rwidth="300pt">
	    <row> 
	      <cell><lit>$ess</lit></cell>
	      <cell>error sum of squares</cell> 
	    </row> 
	    <row>
	      <cell><lit>$rsq</lit></cell> 
	      <cell>unadjusted <emphasis>R</emphasis>-squared</cell> 
	    </row> 
	    <row>
	      <cell><lit>$T</lit></cell> 
	      <cell>number of observations used</cell> 
	    </row> 
	    <row> 
	      <cell><lit>$df</lit></cell>
	      <cell>degrees of freedom</cell> 
	    </row> 
	    <row>
	      <cell><lit>$trsq</lit></cell>
	      <cell><emphasis>TR</emphasis>-squared (sample size times
		<emphasis>R</emphasis>-squared)</cell> 
	    </row> 
	    <row>
	      <cell><lit>$sigma</lit></cell> 
	      <cell>standard error of residuals</cell> 
	    </row> 
	    <row>
	      <cell><lit>$aic</lit></cell> 
	      <cell>Akaike Information Criterion</cell> 
	    </row> 
	    <row>
	      <cell><lit>$lnl</lit></cell> 
	      <cell>log-likelihood (where applicable)</cell> 
	    </row> 
	    <row>
	      <cell><lit>$sigma</lit></cell> 
	      <cell>standard error of residuals</cell> 
	    </row> 
	    <row>
	      <cell>coeff(<repl>var</repl>)</cell> 
	      <cell>estimated coefficient for variable
		<repl>var</repl></cell> 
	    </row> 
	    <row>
	      <cell>stderr(<repl>var</repl>)</cell> 
	      <cell>estimated standard error for variable
		<repl>var</repl> 
	      </cell> 
	    </row> 
	    <row>
	      <cell>rho(<repl>i</repl>)</cell>
	      <cell><repl>i</repl>th order autoregressive coefficient
		for residuals</cell> 
	    </row> 
	    <row>
	      <cell>vcv(<repl>x1</repl>,<repl>x2</repl>)</cell>
	      <cell>covariance between coefficients for named
		variables <repl>x1</repl> and <repl>x2</repl> 
	      </cell> 
	    </row>
	  </table>

	</li>
      </ilist> 

      <para>
	<emphasis>Note</emphasis>: In the command-line program,
	<cmd>genr</cmd> commands that retrieve model-related data
	always reference the model that was estimated most recently.
	This is also true in the GUI program, if one uses
	<cmd>genr</cmd> in the <quote>gretl console</quote> or enters
	a formula using the <quote>Define new variable</quote> option
	under the Variable menu in the main window.  With the GUI,
	however, you have the option of retrieving data from any model
	currently displayed in a window (whether or not it's the most
	recent model).  You do this under the <quote>Model
	  data</quote> menu in the model's window.</para>

      <para>The internal series <lit>uhat</lit> and <lit>yhat</lit>
	hold, respectively, the residuals and fitted values from the
	last regression.</para>

      <para>
	Two <quote>internal</quote> dataset variables are available:
	<lit>$nobs</lit> holds the number of observations in the
	current sample range (which may or may not equal the value of
	<lit>$T</lit>, the number of observations used in estimating
	the last model), and <lit>$pd</lit> holds the frequency or
	periodicity of the data (e.g. 4 for quarterly data).</para>

      <para>The variable <lit>t</lit> serves as an index of the
	observations. For instance <lit>genr dum = (t=15)</lit>
	will generate a dummy variable that has value 1 for
	observation 15, 0 otherwise.  The variable <lit>obs</lit> is
	similar but more flexible: you can use this to pick out
	particular observations by date or name.  For example,
	<lit>genr d = (obs&gt;1986:4)</lit> or <lit>genr d =
	  (obs="CA")</lit>. The last form presumes that the
	observations are labeled; the label must be put in double
	quotes.</para>

      <para>Scalar values can be pulled from a series in the context
	of a <lit>genr</lit> formula, using the syntax
	<repl>varname</repl><lit>[</lit><repl>obs</repl><lit>]</lit>.
	The <repl>obs</repl> value can be given by number or date.
	Examples: <lit>x[5]</lit>, <lit>CPI[1996:01]</lit>.  For daily
	data, the form <repl>YYYY:MM:DD</repl> must be used, e.g.
	<lit>ibm[1970:01:23]</lit>.
      </para>

      <para>
	<tabref targ="tab-genr"/> gives several examples of uses of
	<cmd>genr</cmd> with explanatory notes; here are a
	couple of tips on dummy variables:
      </para>

      <ilist>
	<li><para>Suppose <lit>x</lit> is coded with values 1, 2, or 3
	    and you want three dummy variables, <lit>d1</lit> = 1 if
	    <lit>x</lit> = 1, 0 otherwise, <lit>d2</lit> = 1 if
	    <lit>x</lit> = 2, and so on.  To create these, use the
	    commands:</para>

	  <code>
	    genr d1 = (x=1)
	    genr d2 = (x=2)
	    genr d3 = (x=3)</code>
	</li>

	<li><para>To create <lit>z</lit> = <lit>max(x,y)</lit>
	    do</para>

	  <code>
	    genr d = x&gt;y
	    genr z = (x*d)+(y*(1-d))</code>
	</li>
      </ilist>

      <table id="tab-genr" title="Examples of use of genr command"
	lhead="Command" rhead="Comment">
	<row>
	  <cell><lit>genr y = x1^3</lit></cell>
	  <cell><lit>x1</lit> cubed</cell>
	</row>          
	<row>
	  <cell><lit>genr y = ln((x1+x2)/x3)</lit></cell>
	  <cell></cell>
	</row>
	<row>
	  <cell><lit>genr z = x&gt;y</lit></cell>
	  <cell><lit>z(t)</lit> = 1 if <lit>x(t) &gt; y(t)</lit>,
	    otherwise 0</cell>
	</row> 
	<row>
	  <cell><lit>genr y = x(-2)</lit></cell>
	  <cell><lit>x</lit> lagged 2 periods</cell>
	</row>     
	<row>
	  <cell><lit>genr y = x(2)</lit></cell>
	  <cell><lit>x</lit> led 2 periods</cell>
	</row>
	<row>
	  <cell><lit>genr y = diff(x)</lit></cell>
	  <cell><lit>y(t) = x(t) - x(t-1)</lit></cell>
	</row>
	<row>
	  <cell><lit>genr y = ldiff(x)</lit></cell>
	  <cell><lit>y(t) = log x(t) - log x(t-1)</lit>, the
	    instantaneous rate of growth of <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>genr y = sort(x)</lit></cell>
	  <cell>sorts <lit>x</lit> in increasing order and stores in
	    <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>genr y = -sort(-x)</lit></cell>
	  <cell>sort <lit>x</lit> in decreasing order</cell>
	</row>
	<row>
	  <cell><lit>genr y = int(x)</lit></cell>
	  <cell>truncate <lit>x</lit> and store its integer value as
	    <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>genr y = abs(x)</lit></cell>
	  <cell>store the absolute values of <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>genr y = sum(x)</lit></cell>
	  <cell>sum <lit>x</lit> values excluding missing &minus;999
	    entries</cell>
	</row>
	<row>
	  <cell><lit>genr y = cum(x)</lit></cell>
	  <cell>cumulation: 
		<equation status="inline"
		  tex="$y_t = \sum_{\tau=1}^t x_{\tau}$"
		  ascii="y(t) = the sum from s=1 to s=t of x(s)"
		  graphic="cumulate"/>
	  </cell>
	</row>
	<row>
	  <cell><lit>genr aa = $ess</lit></cell>
	  <cell>set <lit>aa</lit> equal to the Error Sum of Squares
	    from last regression</cell>
	</row>
	<row>
	  <cell><lit>genr x = coeff(sqft)</lit></cell>
	  <cell>grab the estimated coefficient on the variable
	    <lit>sqft</lit> from the last regression</cell>
	</row>
	<row>
	  <cell><lit>genr rho4 = rho(4)</lit></cell>
	  <cell>grab the 4th-order autoregressive coefficient from the
	    last model (presumes an <lit>ar</lit> model)</cell>
	</row>
	<row>
	  <cell><lit>genr cvx1x2 = vcv(x1, x2)</lit></cell>
	  <cell>grab the estimated coefficient covariance of vars
	    <lit>x1</lit> and <lit>x2</lit> from the last model</cell>
	</row>
	<row>
	  <cell><lit>genr foo = uniform()</lit></cell>
	  <cell>uniform pseudo-random variable in range
	    0&ndash;1</cell>
	</row>
	<row>
	  <cell><lit>genr bar = 3 * normal()</lit></cell>
	  <cell>normal pseudo-random variable, &mu; = 0, &sigma; =
	    3</cell>
	</row>
	<row>
	  <cell><lit>genr samp = !missing(x)</lit></cell>
	  <cell>= 1 for observations where <lit>x</lit> is not
	    missing.</cell>
	</row>
      </table>

    </description>

    <gui-access>
      <menu-path>/Variable/Define new variable</menu-path>
      <other-access>Main window pop-up menu</other-access>
    </gui-access>

  </command>

  <command name="gnuplot" section="Graphs">

    <usage>
      <arguments>
        <argument>yvars</argument>
        <argument>xvar</argument>
	<argument optional="true">dumvar</argument>
      </arguments>
      <options>
        <option>
	  <flag>--with-lines</flag>
	  <effect>use lines, not points</effect>
        </option>
        <option>
	  <flag>--with-impulses</flag>
	  <effect>use vertical lines</effect>
        </option>
        <option>
	  <flag>--suppress-fitted</flag>
	  <effect>don't show least squares fit</effect>
        </option>
        <option>
	  <flag>--dummy</flag>
	  <effect>see below</effect>
        </option>
      </options>
      <examples>
        <example>gnuplot y1 y2 x</example>
        <example>gnuplot x time --with-lines</example>
	<example>gnuplot wages educ gender --dummy</example>
      </examples>
    </usage>

    <description>
      <para>Without the <lit>--dummy</lit> option, the
	<repl>yvars</repl> are graphed against <repl>xvar</repl>. With
	<lit>--dummy</lit>, <repl>yvar</repl> is graphed against
	<repl>xvar</repl> with the points shown in different colors
	depending on whether the value of <repl>dumvar</repl> is 1 or
	0.</para>

      <para>
	The <lit>time</lit> variable behaves specially: if it does not
	already exist then it will be generated automatically.
      </para>

      <para>
	In interactive mode the result is displayed immediately. In
	batch mode a gnuplot command file is written, with a name on
	the pattern <filename>gpttmpN.plt</filename>, starting with N
	= <lit>01</lit>. The actual plots may be generated later using
	<program>gnuplot</program> (under MS Windows,
	<program>wgnuplot</program>).
      </para>

      <para>A further option to this command is available: following
	the specification of the variables to be plotted and the
	option flag (if any), you may add literal gnuplot commands to
	control the appearance of the plot (for example, setting the
	plot title and/or the axis ranges).  These commands should be
	enclosed in braces, and each gnuplot command must be
	terminated with a semi-colon.  A backslash may be used to
	continue a set of gnuplot commands over more than one line.
	Here is an example of the syntax:
      </para>

      <para>
	<lit>{ set title 'My Title'; set yrange [0:1000]; }</lit>
      </para>

    </description>

    <gui-access>
      <menu-path>/Data/Graph specified vars</menu-path>
      <other-access>Main window pop-up menu, graph button on toolbar</other-access>
    </gui-access>

  </command>

  <command name="graph" section="Graphs">

    <usage>
      <arguments>
        <argument>yvars</argument>
        <argument>xvar</argument>
      </arguments>
      <options>
        <option>
	  <flag>--tall</flag>
	  <effect>use 40 rows</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	ASCII graphics.  The <repl>yvars</repl> (which may be given by
	name or number) are  graphed against <repl>xvar</repl> using
	ASCII symbols. The <lit>--tall</lit> flag will produce a graph
	with 40 rows and 60 columns. Without it, the graph will be 20
	by 60 (for screen output).  See also <cmdref targ="gnuplot"/>.
      </para>
    </description>

  </command>

  <command name="hausman" section="Tests">

    <description>
      <para>
	This test is available only after estimating a model using the
	<cmdref targ="pooled"/> command (see also <cmd>panel</cmd> and
	<cmd>setobs</cmd>).  It tests the simple pooled model against
	the principal alternatives, the fixed effects and random
	effects models.</para>

      <para>
	The fixed effects model adds a dummy variable for all but one
	of the cross-sectional units, allowing the intercept of the
	regression to vary across the units.  An
	<mathvar>F</mathvar>-test for the joint significance of these
	dummies is presented.  The random effects model decomposes the
	residual variance into two parts, one part specific to the
	cross-sectional unit and the other specific to the particular
	observation.  (This estimator can be computed only if the
	number of cross-sectional units in the data set exceeds the
	number of parameters to be estimated.) The Breusch&ndash;Pagan
	LM statistic tests the null hypothesis (that the pooled OLS
	estimator is adequate) against the random effects
	alternative.</para>

      <para>
	The pooled OLS model may be rejected against both of the
	alternatives, fixed effects and random effects. Provided the
	unit- or group-specific error is uncorrelated with the
	independent variables, the random effects estimator is more
	efficient than the fixed effects estimator; otherwise the
	random effects estimator is inconsistent and the fixed effects
	estimator is to be preferred. The null hypothesis for the
	Hausman test is that the group-specific error is not so
	correlated (and therefore the random effects model is
	preferable).  A low p-value for this test counts against the
	random effects model and in favor of fixed effects.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/panel diagnostics</menu-path>
    </gui-access>

  </command>

  <command name="hccm" section="Estimation">

    <usage>
      <blurb>Heteroskedasticity Consistent Covariance Matrix</blurb>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Presents OLS estimates with the heteroskedasticity consistent
	covariance matrix estimates for the standard errors of
	regression coefficients using MacKinnon and White (1985)
	<quote>jackknife</quote> estimates (see Ramanathan, Section
	8.3).
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/HCCM</menu-path>
    </gui-access>

  </command>

  <command name="help" section="Utilities">

    <description>
      <para>
	Gives a list of available commands. <cmd>help</cmd>
	<repl>command</repl> describes <repl>command</repl> (e.g.
	<cmd>help smpl</cmd>).  You can type <cmd>man</cmd> instead of
	<cmd>help</cmd> if you like. 
      </para> 
    </description>

    <gui-access>
      <menu-path>/Help</menu-path>
    </gui-access>

  </command>

  <command name="hilu" section="Estimation">

    <usage>
      <blurb>Hildreth-Lu estimation</blurb>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>Computes parameter estimates using the Hildreth&ndash;Lu
	search procedure (fine-tuned by the CORC procedure) with
	<repl>depvar</repl> as the dependent variable and
	<repl>indepvars</repl> as the list of independent variables.
	This procedure is designed to correct for serial correlation
	of the error term.  The error sum of squares of the
	transformed model is graphed against the value of rho from
	&minus;0.99 to 0.99.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Hildreth-Lu</menu-path>
    </gui-access>

  </command>

  <command name="hsk" section="Estimation">

    <usage>
      <arguments>
	<blurb>Heteroskedasticity-corrected estimates</blurb>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Prints heteroskedasticity-corrected estimates (see Ramanathan,
	ch. 8) and associated statistics.  The auxiliary regression
	predicts the log of the square of residuals (using squares of
	independent variables but not their cross products) from which
	weighted least squares estimates are obtained.  
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Heteroskedasticity corrected</menu-path>
    </gui-access>

  </command>

  <command name="if" section="Programming">

    <description>
      <para>Flow control for command execution.  The syntax is:</para>

      <table lwidth="25pt" rwidth="100pt">
	<row><cell><lit>if</lit></cell>
	  <cell><repl>condition</repl></cell>
	</row>
	<row><cell></cell><cell><repl>commands1</repl></cell>
	</row>
	<row><cell><lit>else</lit></cell><cell></cell>
	</row>
	<row><cell></cell><cell><repl>commands2</repl></cell>
	</row>
	<row><cell><lit>endif</lit></cell><cell></cell>
	</row>
      </table>

      <para><repl>condition</repl> must be a Boolean expression, for
	the syntax of which see <cmdref targ="genr"/>.  The
	<cmd>else</cmd> block is optional; <lit>if</lit> &hellip;
	<lit>endif</lit> blocks may be nested.</para>
    </description>

  </command>

  <command name="import" section="Dataset">

    <usage>
      <arguments>
        <argument>filename</argument>
      </arguments>
      <options>
        <option>
	  <flag>--box1</flag>
	  <effect>BOX1 data</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Brings in data from a comma-separated values (CSV) format
	file, such as can easily be written from a spreadsheet
	program.  The file should have variable names on the first
	line and a rectangular data matrix on the remaining lines.
	Variables should be arranged <quote>by observation</quote>
	(one column per variable; each row represents an observation).
	See <manref targ="datafiles"/> for details.
      </para>

      <para>
	With the <lit>--box1</lit> flag, reads a data file in BOX1
	format, as can be obtained using the Data Extraction Service
	of the US Bureau of the Census.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Open data/import</menu-path>
    </gui-access>

  </command>

  <command name="info" section="Dataset">

    <description>
      <para>
	Prints out any supplementary information stored with the
	current datafile.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Read info</menu-path>
      <other-access>Data browser windows</other-access>
    </gui-access>

  </command>

  <command name="label" section="Dataset">

    <usage>
      <arguments>
        <argument>varname</argument>
        <argument flag="-d ">description</argument>
        <argument flag="-n ">displayname</argument>
      </arguments>
      <examples>
        <example>label x1 -d "Description of x1" -n "Graph name"</example>
      </examples>
    </usage>

    <description>
      <para>Sets the descriptive label for the given variable (if the
	<lit>-d</lit> flag is given, followed by a string in double
	quotes) and/or the <quote>display name</quote> for the
	variable (if the <lit>-n</lit> flag is given, followed by a
	quoted string).  If a variable has a display name, this is
	used when generating graphs.</para>
    </description>

    <gui-access>
      <menu-path>/Variable/Edit attributes</menu-path>
      <other-access>Main window pop-up menu</other-access>
    </gui-access>

  </command>

  <command name="labels" section="Dataset">

    <description>
      <para>
	Prints out the informative labels for any variables that have
	been generated using <cmd>genr</cmd>, and any labels added to
	the data set via the GUI.
      </para>
    </description>

  </command>

  <command name="lad" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Calculates a regression that minimizes the sum of the absolute
	deviations of the observed from the fitted values of the
	dependent variable.  Coefficient estimates are derived using
	the Barrodale&ndash;Roberts simplex algorithm; a warning is
	printed if the solution is not unique. Standard errors are
	derived using the bootstrap procedure with 500 drawings.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Least Absolute Deviation</menu-path>
    </gui-access>

  </command>

  <command name="lags" section="Transformations">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Creates new variables which are lagged values of each of the
	variables in <repl>varlist</repl>.  The number of lagged
	variables equals the periodicity. For example, if the
	periodicity is 4 (quarterly), the command <cmd>lags x y</cmd>
	creates <lit>x_1</lit> = <lit>x(t-1)</lit>, <lit>x_2</lit> =
	<lit>x(t-2)</lit>, <lit>x_3</lit> = <lit>x(t-3)</lit> and
	<lit>x_4</lit> <lit>x(t-4)</lit>. Similarly for <lit>y</lit>.
	These variables must be referred to in the exact form, that
	is, with the underscore.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Add variables/lags of selected variables</menu-path>
    </gui-access>

  </command>

  <command name="ldiff" section="Transformations">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>
	The first difference of the natural log of each variable in
	<repl>varlist</repl> is obtained and the result stored in a
	new variable with the prefix <lit>ld_</lit>.  Thus <cmd>ldiff
	  x y</cmd> creates the new variables <lit>ld_x</lit> =
	  <equation status="inline" 
	  tex="$\ln(x_t) - \ln(x_{t-1})$"
	  ascii="ln[x(t)] - ln[x(t-1)]"
	  graphic="ldx"/> and <lit>ld_y</lit> =
	  <equation status="inline" 
	  tex="$\ln(y_t) - \ln(y_{t-1})$"
	  ascii="ln[y(t)] - ln[y(t-1)]"
	  graphic="ldy"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Add variables/log differences</menu-path>
    </gui-access>

  </command>

  <command name="leverage" section="Tests">

    <usage>
      <options>
        <option>
	  <flag>--save</flag>
	  <effect>save variables</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Must immediately follow an <cmd>ols</cmd> command. Calculates
	the leverage (<mathvar>h</mathvar>, which must lie in the
	range 0 to 1) for each data point in the sample on which the
	previous model was estimated.  Displays the residual
	(<mathvar>u</mathvar>) for each observation along with its
	leverage and a measure of its influence on the estimates, 
	  <equation status="inline" 
	  tex="$uh/(1 - h)$"
	  ascii="u*h/(1-h)"
	  graphic="influence"/>. <quote>Leverage points</quote> for
	which the value of <mathvar>h</mathvar> exceeds
	2<mathvar>k</mathvar>/<mathvar>n</mathvar> (where
	<mathvar>k</mathvar> is the number of parameters being
	estmated and <mathvar>n</mathvar> is the sample size) are
	flagged with an asterisk.  For details on the concepts of
	leverage and influence see Davidson and MacKinnon (1993,
	Chapter 2).
      </para>

      <para>
	DFFITS values are also shown: these are <quote>studentized
	  residuals</quote> (predicted residuals divided by their
	standard errors) multiplied by 
	  <equation status="inline" 
	  tex="$\sqrt{h/(1 - h)}$"
	  ascii="sqrt[h/(1 - h)]"
	  graphic="dffit"/>. For a discussion of studentized residuals
	and DFFITS see G. S. Maddala, <book>Introduction to
	  Econometrics</book>, chapter 12; also Belsley, Kuh and
	Welsch (1980).  Briefly, a <quote>predicted residual</quote>
	is the difference between the observed value of the dependent
	variable at observation <mathvar>t</mathvar>, and the fitted
	value for observation <mathvar>t</mathvar> obtained from a
	regression in which that observation is omitted (or a dummy
	variable with value 1 for observation <mathvar>t</mathvar>
	alone has been added); the studentized residual is obtained by
	dividing the predicted residual by its standard error.</para>

      <para>If the <lit>--save</lit> flag is given with this command,
	then the leverage, influence and DFFITS values are added to
	the current data set.</para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/influential observations</menu-path>
    </gui-access>

  </command>

  <command name="lmtest" section="Tests">

    <usage>
      <options>
        <option>
	  <flag>--logs</flag>
	  <effect>non-linearity, logs</effect>
        </option>
        <option>
	  <flag>--autocorr</flag>
	  <effect>serial correlation</effect>
        </option>
        <option>
	  <flag>--squares</flag>
	  <effect>non-linearity, squares</effect>
        </option>
        <option>
	  <flag>--white</flag>
	  <effect>heteroskedasticity (White's test)</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Must immediately follow an <cmd>ols</cmd> command. Carries out
	some combination of the following: Lagrange Multiplier tests
	for nonlinearity (logs and squares), White's test for
	heteroskedasticity, and the LMF test for serial correlation up
	to the periodicity (see Kiviet, 1986).  The corresponding
	auxiliary regression coefficients are also printed out.  See
	Ramanathan, Chapters 7, 8, and 9 for details. In the case of
	White's test, only the squared independent variables are used
	and not their cross products.  In the case of the
	autocorrelation test, if the p-value of the LMF statistic is
	less than 0.05 (and the model was not originally estimated
	with robust standard errors) then serial correlation-robust
	standard errors are calculated and displayed.  For details on
	the calculation of these standard errors see Wooldridge (2002,
	Chapter 12).
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests</menu-path>
    </gui-access>

  </command>

  <command name="logistic" section="Estimation">

    <usage>
      <blurb>Logistic regression</blurb>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
	<argument optional="true" flag="ymax=">value</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
      <examples>
        <example>logistic y const x</example>
        <example>logistic y const x ymax=50</example>
      </examples>
    </usage>

    <description>
      <para>
	Logistic regression: carries out an OLS regression using the
	logistic transformation of the dependent variable,
	<equation status="display" 
	  tex="\[\log\left(\frac{y}{y^*-y}\right)\]"
	  ascii="log(y/(ymax - y))"
	  graphic="logistic1"/>
      </para>

      <para>The dependent variable must be strictly positive.  If it
	is a decimal fraction, between 0 and 1, the default is to use
	a <mathvar>y<super>*</super></mathvar> value (the asymptotic
	maximum of the dependent variable) of 1. If the dependent
	variable is a percentage, between 0 and 100, the default
	<mathvar>y<super>*</super></mathvar> is 100.  If you wish to
	set a different maximum, use the optional
	<lit>ymax=</lit><repl>value</repl> syntax following the list
	of regressors.  The supplied value must be greater than all of
	the observed values of the dependent variable.</para>

      <para>The fitted values and residuals from the regression are
	automatically transformed using 	  
	<equation status="display" 
	  tex="\[y=\frac{y^*}{1+e^{-x}}\]"
	  ascii="y = ymax / (1 + exp(-x))"
	  graphic="logistic2"/> where <mathvar>x</mathvar> represents
	either a fitted value or a residual from the OLS regression
	using the transformed dependent variable.  The reported values
	are therefore comparable with the original dependent
	variable.</para>

      <para>Note that if the dependent variable is binary, you should
	use the <cmd>logit</cmd> command instead.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Logistic</menu-path>
    </gui-access>

  </command>

  <command name="logit" section="Estimation">

    <usage>
      <blurb>Logit regression</blurb>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Binomial logit regression. The dependent variable should be a
	binary variable.  Maximum likelihood estimates of the
	coefficients on <repl>indepvars</repl> are obtained via the EM
	or Expectation&ndash;Maximization method (see Ruud, 2000,
	Chapter 27).  As the model is nonlinear the slopes depend on
	the values of the independent variables: the reported slopes
	are evaluated at the means of those variables. The chi-square
	statistic tests the null hypothesis that all coefficients are
	zero apart from the constant.
      </para>

      <para>
	If you want to use logit for analysis of proportions (where
	the dependent variable is the proportion of cases having a
	certain characteristic, at each observation, rather than a 1
	or 0 variable indicating whether the characteristic is present
	or not) you should not use the <cmd>logit</cmd> command, but
	rather construct the logit variable (e.g. <cmd>genr lgt_p =
	  log(p/(1 - p))</cmd>) and use this as the dependent variable
	in an OLS regression.  See Ramanathan, Chapter 12.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Logit</menu-path>
    </gui-access>

  </command>

  <command name="logs" section="Transformations">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>
	The natural log of each of the variables in
	<repl>varlist</repl> is obtained and the result stored in a
	new variable with the prefix <lit>l_</lit> which is
	<quote>el</quote> underscore.  <cmd>logs x y</cmd> creates the
	new variables <lit>l_x</lit> = ln(<lit>x</lit>) and
	<lit>l_y</lit> = ln(<lit>y</lit>).
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Add variables/logs of selected variables</menu-path>
    </gui-access>

  </command>

  <command name="loop" section="Programming">

    <usage>
      <arguments>
        <argument>control</argument>
      </arguments>
      <examples>
        <example>loop 1000</example>
        <example>loop while essdiff > .00001</example>
        <example>loop for i=1991..2000</example>
      </examples>
    </usage>

    <description>
      <para>The parameter <repl>control</repl> must take one of three
	forms, as shown in the examples: an integer number of times to
	repeat the commands within the loop;
	<quote><lit>while</lit></quote> plus a numerical condition; or
	<quote><lit>for</lit></quote> plus a range of values for the
	internal index variable <lit>i</lit>.
      </para>

      <para>This command opens a special mode in which the program
	accepts commands to be executed repeatedly.  Within a loop,
	only certain commands can be used: <cmd>genr</cmd>,
	<cmd>ols</cmd>, <cmd>print</cmd>, <cmd>sim</cmd>,
	<cmd>smpl</cmd>, <cmd>store</cmd> and <cmd>summary</cmd>
	(store can't be used in a <quote>while</quote> loop).  You
	exit the mode of entering loop commands with
	<cmd>endloop</cmd>: at this point the stacked commands are
	executed.  Loops cannot be nested.
      </para>

      <para>See <manref targ="looping"/> for further details and
	examples.</para>
    </description>

  </command>

  <command name="meantest" section="Tests">

    <usage>
      <arguments>
        <argument>var1</argument>
        <argument>var2</argument>
      </arguments>
      <options>
        <option>
	  <flag>--unequal-vars</flag>
	  <effect>assume variances are unequal</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Calculates the <mathvar>t</mathvar> statistic for the null
	hypothesis that the population means are equal for the
	variables <repl>var1</repl> and <repl>var2</repl>, and shows
	its p-value. By default the statistic is computed on the
	assumption that the variances are equal for the two variables;
	with the <lit>--unequal-vars</lit> flag the variances are
	assumed to be unequal. (The flag will make a difference only
	if there are different numbers of non-missing observations for
	the two variables.)
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Difference of means</menu-path>
    </gui-access>

  </command>

  <command name="modeltab" section="Utilities">

    <usage>
      <arguments>
        <argument>add</argument>
        <argument alternate="true">show</argument>
        <argument alternate="true">free</argument>
      </arguments>
    </usage>

    <description>
      <para>Manipulates the gretl <quote>model table</quote>. See
	<manref targ="modes"/> for details. The sub-commands have
	the following effects: <cmd>add</cmd> adds the last model
	estimated to the model table, if possible; <cmd>show</cmd>
	displays the model table in a window; and <cmd>free</cmd>
	clears the table.</para>
    </description>

    <gui-access>
      <menu-path>Session window, Model table icon</menu-path>
    </gui-access>

  </command>

  <command name="mpols" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Computes OLS estimates with <repl>depvar</repl> as the
	dependent variable and <repl>indepvars</repl> as the list of
	independent variables, using multiple precision floating-point
	arithmetic. The variables may be specified by name or number;
	use the number zero for a constant term. This command is
	available only if <program>gretl</program> is compiled with
	support for the Gnu Multiple Precision library (GMP).
      </para>

      <para>
	To estimate a polynomial fit, using multiple precision
	arithmetic to generate the required powers of the independent
	variable, use the form, e.g. <cmd>mpols y 0 x ; 2 3 4</cmd>
	This does a regression of <lit>y</lit> on <lit>x</lit>,
	<lit>x</lit> squared, <lit>x</lit> cubed and <lit>x</lit> to
	the fourth power.  That is, the numbers (which must be
	positive integers) to the right of the semicolon specify the
	powers of <lit>x</lit> to be used.  If more than one
	independent variable is specified, the last variable before
	the semicolon is taken to be the one that should be raised to
	various powers.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/High precision OLS</menu-path>
    </gui-access>

  </command>

  <command name="multiply" section="Transformations">

    <usage>
      <arguments>
        <argument>x</argument>
        <argument>suffix</argument>
        <argument>varlist</argument>
      </arguments>
      <examples>
        <example>multiply invpop pc 3 4 5 6</example>
        <example>multiply 1000 big x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	The variables in <repl>varlist</repl> (referenced by name or
	number) are multiplied by <repl>x</repl>, which may be either
	a numerical value or the name of a variable already defined.
	The products are named with the specified <repl>suffix</repl>
	(maximum 3 characters). The original variable names are
	truncated first if need be. For instance, suppose you want to
	create per capita versions of certain variables, and you have
	the variable <lit>pop</lit> (population).  A suitable set of
	commands is then:</para>
      
      <code>
	genr invpop = 1/pop
	multiply invpop pc income</code>

      <para>which will create <lit>incomepc</lit> as the product of
	<lit>income</lit> and <lit>invpop</lit>, and
	<lit>expendpc</lit> as <lit>expend</lit> times
	<lit>invpop</lit>.
      </para>
    </description>

  </command>

  <command name="nls" section="Estimation">

    <usage>
      <arguments>
        <argument>function</argument>
        <argument>derivatives</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Performs Nonlinear Least Squares (NLS) estimation using a
	modified version of the Levenberg&ndash;Marquandt algorithm.
	The user must supply a function specification.  The parameters
	of this function must be declared and given starting values
	(using the <cmd>genr</cmd> command) prior to estimation.
	Optionally, the user may specify the derivatives of the
	regression function with respect to each of the parameters; if
	analytical derivatives are not supplied, a numerical
	approximation to the Jacobian is computed.</para>

      <para>
	It is easiest to show what is required by example.  The
	following is a complete script to estimate the nonlinear
	consumption function set out in William Greene's
	<book>Econometric Analysis</book> (Chapter 11 of the 4th
	edition, or Chapter 9 of the 5th).  The numbers to the left of
	the lines are for reference and are not part of the
	commands.  Note that the <lit>--vcv</lit> option, for printing
	the covariance matrix of the parameter estimates, attaches to
	the final command, <lit>end nls</lit>.</para>

      <code>
	1   open greene11_3.gdt
	2   ols C 0 Y
	3   genr alpha = coeff(0)
	4   genr beta = coeff(Y)
	5   genr gamma = 1.0
	6   nls C = alpha + beta * Y^gamma
	7   deriv alpha = 1
	8   deriv beta = Y^gamma
	9   deriv gamma = beta * Y^gamma * log(Y)
	10  end nls --vcv
      </code>

      <para>
	It is often convenient to initialize the parameters by
	reference to a related linear model; that is accomplished here
	on lines 2 to 5.  The parameters alpha, beta and gamma could
	be set to any initial values (not necessarily based on a model
	estimated with OLS), although convergence of the NLS procedure
	is not guaranteed for an arbitrary starting point.</para>

      <para>
	The actual NLS commands occupy lines 6 to 10. On line 6 the
	<cmd>nls</cmd> command is given: a dependent variable is
	specified, followed by an equals sign, followed by a function
	specification.  The syntax for the expression on the right is
	the same as that for the <cmd>genr</cmd> command.  The next
	three lines specify the derivatives of the regression function
	with respect to each of the parameters in turn.  Each line
	begins with the keyword <cmd>deriv</cmd>, gives the name of a
	parameter, an equals sign, and an expression whereby the
	derivative can be calculated (again, the syntax here is the
	same as for <cmd>genr</cmd>). These <cmd>deriv</cmd> lines are
	optional, but it is recommended that you supply them if
	possible. Line 10, <cmd>end nls</cmd>, completes the command
	and calls for estimation.</para>

      <para>For further details on NLS estimation please see
	<manref targ="nlschap"/>.</para>
    </description>

    <gui-access>
      <menu-path>/Model/Nonlinear Least Squares</menu-path>
    </gui-access>

  </command>

  <command name="noecho" section="Printing">
    <description>
      <para>Obsolete command.  See <cmdref targ="set"/>.
      </para>
    </description>
  </command>

  <command name="nulldata" section="Dataset">

    <usage>
      <arguments>
        <argument>series_length</argument>
      </arguments>
      <examples>
        <example>nulldata 500</example>
      </examples>
    </usage>

    <description>
      <para>
	Establishes a <quote>blank</quote> data set, containing only a
	constant and an index variable, with periodicity 1 and the
	specified number of observations. This may be used for
	simulation purposes: some of the <cmd>genr</cmd> commands
	(e.g. <cmd>genr uniform()</cmd>, <cmd>genr normal()</cmd>)
	will generate dummy data from scratch to fill out the data
	set. This command may be useful in conjunction with
	<cmd>loop</cmd>.  See also the <quote>seed</quote> option to
	the <cmdref targ="set"/> command.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Create data set</menu-path>
    </gui-access>

  </command>

  <command name="ols" section="Estimation">

    <usage>
      <blurb>Ordinary Least Squares estimation</blurb>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>robust standard errors</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>suppress printing of results</effect>
        </option>
      </options>
      <examples>
        <example>ols 1 0 2 4 6 7</example>
	<example>ols y 0 x1 x2 x3 --vcv</example>
	<example>ols y 0 x1 x2 x3 --quiet</example>
      </examples>
    </usage>

    <description>
      <para>
        Computes ordinary least squares (OLS) estimates with
	<repl>depvar</repl> as the dependent variable and
	<repl>indepvars</repl> as the list of independent variables.
      </para>

      <para>Variables may be specified by name or number; use the
	number zero for a constant term. The program also prints the
	p-values for <mathvar>t</mathvar> (two-tailed) and
	<mathvar>F</mathvar>-statistics.  A p-value below 0.01
	indicates significance at the 1 percent level and is denoted
	by <lit>***</lit>. <lit>**</lit> indicates significance
	between 1 and 5 percent and <lit>*</lit> indicates
	significance between 5 and 10 percent levels. Model selection
	statistics (described in Ramanathan, Section 4.3) are also
	printed. Various internal variables may be retrieved using the
	<cmdref targ="genr"/> command, provided <cmd>genr</cmd> is
	invoked immediately after this command.
      </para>

      <para>The specific formula used for generating robust standard
	errors (when the <lit>--robust</lit> option is given) can be
	adjusted via the <cmdref targ="set"/> command.</para>
    </description>

    <gui-access>
      <menu-path>/Model/Ordinary Least Squares</menu-path>
      <other-access>Beta-hat button on toolbar</other-access>
    </gui-access>

  </command>

  <command name="omit" section="Tests">

    <usage>
      <blurb>Omit variables from a model and test for joint significance</blurb>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
      <examples>
        <example>omit 5 7 9</example>
      </examples>
    </usage>

    <description>
      <para>
	This command must follow an estimation command. The variables
	in <repl>varlist</repl> are omitted from the previous model
	and the new model estimated. If more than one variable is
	omitted, the Wald <mathvar>F</mathvar>-statistic for the
	omitted variables will be printed along with its p-value (for
	the OLS procedure only).  A p-value below 0.05 means that the
	coefficients are jointly significant at the 5 percent level.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/omit variables</menu-path>
    </gui-access>

  </command>

  <command name="omitfrom" section="Tests">

    <usage>
      <arguments>
        <argument>modelID</argument>
        <argument>varlist</argument>
      </arguments>
      <examples>
        <example>omitfrom 2 5 7 9</example>
      </examples>
    </usage>

    <description>
      <para>Works like <cmdref targ="omit"/>, except that you specify
	a previous model (using its ID number, which is printed at the
	start of the model output) to take as the base for omitting
	variables.  The example above omits variables number 5, 7 and
	9 from Model 2.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/omit variables</menu-path>
    </gui-access>

  </command>

  <command name="open" section="Dataset">

    <usage>
      <arguments>
        <argument>datafile</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Opens a data file.  If a data file is already open, it is
	replaced by the newly opened one.  The program will try to
	detect the format of the data file (native, pain text, CSV or
	BOX1).
      </para>

      <para>
	This command can also be used to open a database (gretl or
	RATS 4.0) for reading.  In that case it should be followed by
	the <cmdref targ="data"/> command to extract particular series
	from the database.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Open data</menu-path>
      <other-access>Drag a data file into gretl (MS Windows or Gnome)</other-access>
    </gui-access>

  </command>

  <command name="outfile" section="Printing">

    <usage>
      <arguments>
        <argument>filename</argument>
        <argument>option</argument>
      </arguments>
      <options>
        <option>
	  <flag>--append</flag>
	  <effect>append to file</effect>
        </option>
        <option>
	  <flag>--close</flag>
	  <effect>close file</effect>
        </option>
        <option>
	  <flag>--write</flag>
	  <effect>overwrite file</effect>
        </option>
      </options>
      <examples>
        <example>outfile --write regress.txt</example>
        <example>outfile --close</example>
      </examples>
    </usage>

    <description>
      <para>Diverts output to <repl>filename</repl>, until further
	notice.  Use the flag <lit>--append</lit> to append output to
	an existing file or <lit>--write</lit> to start a new file
	(or overwrite an existing one).  Only one file can be opened
	in this way at any given time.</para>

      <para>The <lit>--close</lit> flag is used to close an output
	file that was previously opened as above.  Output will then
	revert to the default stream.</para>

      <para>In the first example command above, the file
	<filename>regress.txt</filename> is opened for writing, and in
	the second it is closed.  This would make sense as a sequence
	only if some commands were issued before the
	<lit>--close</lit>.  For example if an <cmd>ols</cmd> command
	intervened, its output would go to
	<filename>regress.txt</filename> rather than the
	screen.</para>
    </description>

  </command>

  <command name="panel" section="Dataset">

    <usage>
      <blurb>Register panel data structure</blurb>
      <options>
        <option>
	  <flag>--cross-section</flag>
	  <effect>stacked cross sections</effect>
        </option>
        <option>
	  <flag>--time-series</flag>
	  <effect>stacked time series</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>Request that the current data set be interpreted as a
	panel (pooled cross section and time series).  By default, or
	with the <lit>--time-series</lit> flag, the data set is taken
	to be in the form of stacked time series (successive blocks of
	data contain time series for each cross-sectional unit).  With
	the <lit>--cross-section</lit> flag, the data set is read as
	stacked cross-sections (successive blocks contain cross
	sections for each time period).  See also
	<cmdref targ="setobs"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Sample/interpret as panel</menu-path>
    </gui-access>

  </command>

  <command name="pca" section="Statistics">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
        <option>
	  <flag>--save-all</flag>
	  <effect>Save all components</effect>
        </option>
        <option>
	  <flag>--save</flag>
	  <effect>Save major components</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>Principal Components Analysis.  Prints the eigenvalues of
	the correlation matrix for the variables in
	<repl>varlist</repl> along with the proportion of the joint
	variance accounted for by each component.  Also prints the
	corresponding eigenvectors (or <quote>component
	  loadings</quote>).</para>  

      <para>If the <lit>--save</lit> flag is given, components with
	eigenvalues greater than 1.0 are saved to the dataset as
	variables, with names <lit>PC1</lit>, <lit>PC2</lit> and so
	on.  These artificial variables are formed as the sum of
	(component loading) times (standardized <lit>Xi</lit>), where
	<lit>Xi</lit> denotes the <mathvar>i</mathvar>th variable in
	<repl>varlist</repl>.</para>

      <para>If the <lit>--save-all</lit> flag is given, all of the
	components are saved as described above.</para> 
    </description>

    <gui-access>
      <menu-path>Main window pop-up (multiple selection)</menu-path>
    </gui-access>

  </command>

  <command name="pergm" section="Statistics">

    <usage>
      <arguments>
        <argument>varname</argument>
      </arguments>
      <options>
        <option>
	  <flag>--bartlett</flag>
	  <effect>use Bartlett lag window</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Computes and displays (and if not in batch mode, graphs) the
	spectrum of the specified variable.  Without the
	<lit>--bartlett</lit> flag the sample periodogram is given;
	with the flag a Bartlett lag window of length
	<equation status="inline"
	  tex="$2\sqrt{T}$"
	  ascii="2*sqrt(T)"
	  graphic="tworootT"/> (where <mathvar>T</mathvar> is the
	sample size) is used in estimating the spectrum (see Chapter
	18 of Greene's <book>Econometric Analysis</book>). When the
	sample periodogram is printed, a <mathvar>t</mathvar>-test for
	fractional integration of the series (<quote>long
	  memory</quote>) is also given: the null hypothesis is that
	the integration order is zero.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/spectrum</menu-path>
      <other-access>Main window pop-up menu (single selection)</other-access>
    </gui-access>

  </command>

  <command name="plot" section="Graphs">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
        <option>
	  <flag>--one-scale</flag>
	  <effect>force a single scale</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Plots the values for specified variables, for the range of
	observations currently in effect, using ASCII symbols.  Each
	line stands for an observation and the values are plotted
	horizontally.  By default the variables are scaled
	appropriately.  See also <cmdref targ="gnuplot"/>.
      </para>
    </description>

  </command>

  <command name="pooled" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>Estimates a model via OLS (see <cmdref targ="ols"/> for
	details on syntax), and flags it as a pooled or panel model,
	so that the <cmdref targ="hausman"/> test item becomes
	available.</para>
    </description>

    <gui-access>
      <menu-path>/Model/Pooled OLS</menu-path>
    </gui-access>

  </command>

  <command name="print" section="Printing">

    <usage>
      <arguments>
	<argument>varlist</argument>
	<argument alternate="true">string_literal</argument>
      </arguments>
      <options>
	<option>
	  <flag>--byobs</flag>
	  <effect>by observations</effect>
	</option>
	<option>
	  <flag>--ten</flag>
	  <effect>use 10 significant digits</effect>
	</option>
      </options>
      <examples>
	<example>print x1 x2 --byobs</example>
	<example>print "This is a string"</example>
      </examples>
    </usage>

    <description>
      <para>
	If <repl>varlist</repl> is given, prints the values of the
	specified variables; if no list is given, prints the values of
	all variables in the current data file. If the
	<lit>--byobs</lit> flag is given the data are printed by
	observation, otherwise they are printed by variable.  If the
	<lit>--ten</lit> flag is given the data are printed by
	variable to 10 significant digits.
      </para>

      <para>
	If the argument to <cmd>print</cmd> is a literal string (which
	must start with a double-quote, <lit>"</lit>), the string is
	printed as is.  See also <cmdref
	  targ="printf"/>.</para>
    </description>

    <gui-access>
      <menu-path>/Data/Display values</menu-path>
    </gui-access>

  </command>

  <command name="printf" section="Printing">

    <usage>
      <arguments>
        <argument>format</argument>
        <argument>args</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Prints scalar values under the control of a format string
	(providing a small subset of the <lit>printf()</lit> statement
	in the C programming language). Recognized formats are
	<lit>%g</lit> and <lit>%f</lit>, in each case with the various
	modifiers available in C.  Examples: the format
	<lit>%.10g</lit> prints a value to 10 significant figures;
	<lit>%12.6f</lit> prints a value to 6 decimal places, with a
	width of 12 characters.</para>  

      <para>The format string itself must be enclosed in double
	quotes.  The values to be printed must follow the format
	string, separated by commas.  These values should take the
	form of either (a) the names of variables in the dataset, or
	(b) expressions that are valid for the <cmd>genr</cmd>
	command.  The following example prints the values of two
	variables plus that of a calculated expression:</para>

      <code>
	ols 1 0 2 3
	genr b = coeff(2)
	genr se_b = stderr(2)
	printf "b = %.8g, standard error %.8g, t = %.4f\n", b, se_b, b/se_b
      </code>

      <para>
	The maximum length of a format string is 127 characters.  The
	escape sequences <lit>\n</lit> (newline), <lit>\t</lit> (tab),
	<lit>\v</lit> (vertical tab) and <lit>\\</lit> (literal
	backslash) are recognized.  To print a literal percent sign,
	use <lit>%%</lit>.</para>
    </description>

  </command>

  <command name="probit" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Probit regression. The dependent variable should be a binary
	variable. Maximum likelihood estimates of the coefficients on
	<repl>indepvars</repl> are obtained via iterated least squares
	(the EM or Expectation&ndash;Maximization method).  As the
	model is nonlinear the slopes depend on the values of the
	independent variables: the reported slopes are evaluated at
	the means of those variables.  The chi-square statistic tests
	the null hypothesis that all coefficients are zero apart from
	the constant.
      </para>

      <para>
	Probit for analysis of proportions is not implemented in
	<program>gretl</program> at this point.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Probit</menu-path>
    </gui-access>

  </command>

  <command name="pvalue" section="Utilities">

    <usage>
      <arguments>
        <argument>dist</argument>
        <argument optional="true">params</argument>
	<argument>xval</argument>
      </arguments>
      <examples>
        <example>pvalue z zscore</example>
	<example>pvalue t 25 3.0</example>
	<example>pvalue X 3 5.6</example>
	<example>pvalue F 4 58 fval</example>
	<example>pvalue G xbar varx x</example>
      </examples>
    </usage>

    <description>
      <para>
	Computes the area to the right of <repl>xval</repl> in the
	specified distribution (<lit>z</lit> for Gaussian,
	<lit>t</lit> for Student's <mathvar>t</mathvar>, <lit>X</lit>
	for chi-square, <lit>F</lit> for <mathvar>F</mathvar> and
	<lit>G</lit> for gamma).  For the <mathvar>t</mathvar> and
	chi-square distributions the degrees of freedom must be given;
	for <mathvar>F</mathvar> numerator and denominator degrees of
	freedom are required; and for gamma the mean and variance are
	needed.
      </para>
    </description>

    <gui-access>
      <menu-path>/Utilities/p-value finder</menu-path>
    </gui-access>

  </command>

  <command name="quit" section="Utilities">

    <description>
      <para>
	Exits from the program, giving you the option of saving the
	output from the session on the way out.  
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Exit</menu-path>
    </gui-access>

  </command>

  <command name="rename" section="Dataset">

    <usage>
      <arguments>
        <argument>varnumber</argument>
        <argument>newname</argument>
      </arguments>
    </usage>

    <description>
      <para>Changes the name of the variable with identification
	number <repl>varnumber</repl> to <repl>newname</repl>.  The
	<repl>varnumber</repl> must be between 1 and the number of
	variables in the dataset.  The new name must be of 8
	characters maximum, must start with a letter, and must be
	composed of only letters, digits, and the underscore
	character.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Edit attributes</menu-path>
      <other-access>Main window pop-up menu (single selection)</other-access>
    </gui-access>

  </command>

  <command name="reset" section="Tests">

    <description>
      <para>
	Must follow the estimation of a model via OLS. Carries out
	Ramsey's RESET test for model specification (non-linearity) by
	adding the square and the cube of the fitted values to the
	regression and calculating the <mathvar>F</mathvar> statistic
	for the null hypothesis that the parameters on the two added
	terms are zero.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/Ramsey's RESET</menu-path>
    </gui-access>

  </command>

  <command name="rhodiff" section="Transformations">

    <usage>
      <arguments>
        <argument>rholist</argument>
        <argument separated="true">varlist</argument>
      </arguments>
      <examples>
        <example>rhodiff .65 ; 2 3 4</example>
        <example>rhodiff r1 r2 ; x1 x2 x3</example>	
      </examples>
    </usage>

    <description>
      <para>
	Creates rho-differenced counterparts of the variables (given
	by number or by name) in <repl>varlist</repl> and adds them to
	the data set, using the suffix <lit>#</lit> for the new
	variables. Given variable <lit>v1</lit> in
	<repl>varlist</repl>, and entries <lit>r1</lit> and
	<lit>r2</lit> in <repl>rholist</repl>, <lit>v1# = v1(t) -
	  r1*v1(t-1) - r2*v1(t-2)</lit> is created. The
	<repl>rholist</repl> entries can be given as numerical values
	or as the names of variables previously defined.
      </para>
    </description>

  </command>

  <command name="rmplot" section="Graphs">

    <usage>
      <arguments>
        <argument>varname</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Range&ndash;mean plot: this command creates a simple graph to
	help in deciding whether a time series,
	<mathvar>y</mathvar>(t), has constant variance or not.  We
	take the full sample t=1,...,T and divide it into small
	subsamples of arbitrary size <mathvar>k</mathvar>. The first
	subsample is formed by
	<mathvar>y</mathvar>(1),...,<mathvar>y</mathvar>(k), the
	second is <mathvar>y</mathvar>(k+1), ...,
	<mathvar>y</mathvar>(2k), and so on.  For each subsample we
	calculate the sample mean and range (= maximum minus minimum),
	and we construct a graph with the means on the horizontal axis
	and the ranges on the vertical. So each subsample is
	represented by a point in this plane.  If the variance of the
	series is constant we would expect the subsample range to be
	independent of the subsample mean; if we see the points
	approximate an upward-sloping line this suggests the variance
	of the series is increasing in its mean; and if the points
	approximate a downward sloping line this suggests the variance
	is decreasing in the mean.</para>

      <para>Besides the graph, gretl displays the means and ranges for
	each subsample, along with the slope coefficient for an OLS
	regression of the range on the mean and the p-value for the
	null hypothesis that this slope is zero.  If the slope
	coefficient is significant at the 10 percent significance
	level then the fitted line from the regression of range on
	mean is shown on the graph.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Range-mean graph</menu-path>
    </gui-access>

  </command>

  <command name="run" section="Programming">

    <usage>
      <arguments>
        <argument>inputfile</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Execute the commands in <repl>inputfile</repl> then return
	control to the interactive prompt.
      </para>
    </description>

    <gui-access>
      <menu-path>Run icon in script window</menu-path>
    </gui-access>

  </command>

  <command name="runs" section="Tests">

    <usage>
      <arguments>
        <argument>varname</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Carries out the nonparametric <quote>runs</quote> test for
	randomness of the specified variable.  If you want to test for
	randomness of deviations from the median, for a variable named
	<lit>x1</lit> with a non-zero median, you can do the
	following:</para>

      <code>
	genr signx1 = x1 - median(x1)
	runs signx1
      </code>
    </description>

    <gui-access>
      <menu-path>/Variable/Runs test</menu-path>
    </gui-access>

  </command>

  <command name="scatters" section="Graphs">

    <usage>
      <arguments>
        <argument>yvar</argument>
        <argument separated="true">xvarlist</argument>
	<argument alternate="true">yvarlist ; xvar</argument>
      </arguments>
      <examples>
        <example>scatters 1 ; 2 3 4 5</example>
        <example>scatters 1 2 3 4 5 6 ; 7</example>
      </examples>
    </usage>

    <description>
      <para>
	Plots pairwise scatters of <repl>yvar</repl> against all the
	variables in <repl>xvarlist</repl>, or of all the variables in
	<repl>yvarlist</repl> against <repl>xvar</repl>.  The first
	example above puts variable 1 on the <mathvar>y</mathvar>-axis
	and draws four graphs, the first having variable 2 on the
	<mathvar>x</mathvar>-axis, the second variable 3 on the
	<mathvar>x</mathvar>-axis, and so on.  The second example
	plots each of variables 1 through 6 against variable 7 on the
	<mathvar>x</mathvar>-axis. Scanning a set of such plots can be
	a useful step in exploratory data analysis.  The maximum
	number of plots is six; any extra variable in the list will be
	ignored.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Multiple scatterplots</menu-path>
    </gui-access>

  </command>

  <command name="seed" section="Programming">
    <description>
      <para>Obsolete command.  See <cmdref targ="set"/>.
      </para>
    </description>
  </command>

  <command name="set" section="Programming">

    <usage>
      <arguments>
        <argument>variable</argument>
        <argument>value</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Set the values of various program parameters.  The given value
	remains in force for the duration of the gretl session unless
	it is changed by a further call to <cmd>set</cmd>.  The
	parameters that can be set in this way are enumerated below.
	Note that the settings of <lit>hac_lag</lit> and
	<lit>hc_version</lit> are used when the <lit>--robust</lit>
	option is given to the <cmd>ols</cmd> command. 
      </para>

      <table lwidth="80pt" rwidth="320pt">
	<row>
	  <cell><lit>echo</lit></cell>
	  <cell>values: <lit>off</lit> or <lit>on</lit> (the default).
	    Suppress or resume the echoing of commands in gretl's
	    output.</cell>
	</row>
	<row>
	  <cell><lit>qr</lit></cell>
	  <cell>values: <lit>on</lit> or <lit>off</lit> (the default).
	    Use QR rather than Cholesky decomposition in calculating
	    OLS estimates.</cell>
	</row>
	<row>
	  <cell><lit>hac_lag</lit></cell>
	  <cell>values: <lit>nw1</lit> (the default) or
	    <lit>nw2</lit>, or an integer.  Sets the maximum lag
	    value, <mathvar>p</mathvar>, used when calculating HAC
	    (Heteroskedasticity and Autocorrelation Consistent)
	    standard errors using the Newey-West approach, for time
	    series data. <lit>nw1</lit> and <lit>nw2</lit> represent
	    two variant automatic calculations based on the sample
	    size, <mathvar>T</mathvar>: for nw1, 
	  <equation status="inline"
	    tex="$p = 0.75 \times T^{1/3}$"
	    ascii="p = 0.75 * T^(1/3)"
	    graphic="nw1"/>,
	    and for nw2, 
	  <equation status="inline"
	    tex="$p = 4 \times (T/100)^{2/9}$"
	    ascii="p = 4 * (T/100)^(2/9)"
	    graphic="nw2"/>.	  
	  </cell>
	</row>
	<row>
	  <cell><lit>hc_version</lit></cell>
	  <cell>values: 0 (the default), 1, 2 or 3. Sets the variant
	    used when calculating Heteroskedasticity Consistent
	    standard errors with cross-sectional data.  The options
	    correspond to the HC0, HC1, HC2 and HC3 discussed by
	    Davidson and MacKinnon in <book>Econometric Theory and
	      Methods</book>, chapter 5.  HC0 produces what are
	    usually called <quote>White's standard
	      errors</quote>.</cell>
	</row>
      </table>

    </description>
  </command>

  <command name="setobs" section="Dataset">

    <usage>
      <arguments>
        <argument>periodicity</argument>
        <argument>startobs</argument>
      </arguments>
      <examples>
        <example>setobs 4 1990:1</example>
        <example>ssetobs 12 1978:03</example>
        <example>setobs 20 1:01</example>
      </examples>
    </usage>

    <description>
      <para>
	Force the program to interpret the current data set as time
	series or panel, when the data have been read in as simple
	undated series.  <repl>periodicity</repl> must be an integer;
	<repl>startobs</repl> is a string representing the date or
	panel ID of the first observation. See also <cmdref
	  targ="panel"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Sample/Set frequency, startobs</menu-path>
    </gui-access>

  </command>

  <command name="setmiss" section="Dataset">

    <usage>
      <arguments>
        <argument>value</argument>
        <argument optional="true">varlist</argument>
      </arguments>
      <examples>
        <example>setmiss -1</example>
        <example>setmiss 100 x2</example>
      </examples>
    </usage>

    <description>
      <para>
	Get the program to interpret some specific numerical data
	value (the first parameter to the command) as a code for
	<quote>missing</quote>, in the case of imported data.  If this
	value is the only parameter, as in the first example above,
	the interpretation will be applied to all series in the data
	set.  If <repl>value</repl> is followed by a list of
	variables, by name or number, the interpretation is confined
	to the specified variable(s). Thus in the second example the
	data value 100 is interpreted as a code for
	<quote>missing</quote>, but only for the variable
	<lit>x2</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Sample/Set missing value code</menu-path>
    </gui-access>

  </command>

  <command name="shell" section="Utilities">

    <usage>
      <arguments>
        <argument>shellcommand</argument>
      </arguments>
      <examples>
        <example>! ls -al</example>
	<example>! notepad</example>
      </examples>
    </usage>

    <description>
      <para>
	A <cmd>!</cmd> at the beginning of a command line is
	interpreted as an escape to the user's shell.  Thus arbitrary
	shell commands can be executed from within <program>gretl</program>.
      </para>
    </description>

  </command>

  <command name="sim" section="Dataset">

    <usage>
      <arguments>
        <argument optional="true">startobs endobs</argument>
	<argument>varname</argument>
	<argument>a0 a1 a2 &hellip;</argument>
      </arguments>
      <examples>
        <example>sim 1979.2 1983.1 y 0 0.9</example>
	<example>sim 15 25 y 10 0.8 x</example>
      </examples>
    </usage>

    <description>
      <para>
	Simulates values for <repl>varname</repl> for the current
	sample range, or for the range <repl>startobs</repl> through
	<repl>endobs</repl> if these optional arguments are given. The
	variable <repl>y</repl> must have been defined earlier with
	appropriate initial values. The formula used is 
	<equation status="display"
	  tex="\[y_t=a_{0t} + a_{1t}y_{t-1} + a_{2t}y_{t-2} + \dots\]"
	  ascii="y(t) = a0(t) + a1(t)*y(t-1) + a2(t)*y(t-2) + ..."
	  graphic="simformula"/> 
	The <lit>ai(t)</lit> terms may be
	either numerical constants or variable names previously
	defined; these terms may be prefixed with a minus sign.
      </para>

      <para>This command is deprecated.  You should use <cmdref
	  targ="genr"/> instead.</para>
    </description>

  </command>

  <command name="smpl" section="Dataset">

    <!-- don't break the lines below or the text version will get messed
    up -->

    <usage>
      <altforms>
	<altform><lit>smpl</lit> <repl>startobs endobs</repl></altform>
	<altform><lit>smpl</lit> <repl>+i -j</repl></altform>
	<altform><lit>smpl</lit> <repl>dumvar</repl> <lit>--dummy</lit></altform>
	<altform><lit>smpl</lit> <repl>condition</repl> <lit>--restrict</lit></altform>
	<altform><lit>smpl</lit> <lit>--no-missing [</lit> <repl>varlist</repl> <lit>]</lit></altform>
	<altform><lit>smpl full</lit></altform>
      </altforms>
      <examples>
        <example>smpl 3 10</example>
	<example>smpl 1960:2 1982:4</example>
	<example>smpl +1 -1</example>
	<example>smpl x > 3000 --restrict</example>
      </examples>
    </usage>

    <description>
      <para>
	Resets the sample range.  The new range can be defined in
	several ways.  In the first alternate form (and the first two
	examples) above, <repl>startobs</repl> and <repl>endobs</repl>
	must be consistent with the periodicity of the data.  Either
	one may be replaced by a semicolon to leave the value
	unchanged.  In the second form, the integers <repl>i</repl>
	and <repl>j</repl> (which may be positive or negative, and
	should be signed) are taken as offsets relative to the
	existing sample range. In the third form <repl>dummyvar</repl>
	must be an indicator variable with values 0 or 1 at each
	observation; the sample will be restricted to observations
	where the value is 1. The fourth form, using
	<lit>--restrict</lit>, restricts the sample to observations
	that satisfy the given Boolean condition (which is specified
	according to the syntax of the <cmdref targ="genr"/>
	command).</para>

      <para>With the <lit>--no-missing</lit> form, if
	<repl>varlist</repl> is specified an observation is dropped if
	and only if at least one of the variables in
	<repl>varlist</repl> has a missing value at that observation;
	otherwise observations are dropped if <emphasis>any</emphasis>
	variable has a missing value.</para>

      <para>The final form, <lit>smpl full</lit>, restores the full
	data range.
      </para>

      <para>The internal variable <lit>obs</lit> may be used with the
	<lit>--restrict</lit> form of <lit>smpl</lit> to exclude
	particular observations from the sample.  For example,
	<lit>smpl obs!=4 --restrict</lit> will drop just the fourth
	observation. If the data points are identified by labels,
	<lit>smpl obs!="USA" --restrict</lit> will drop the
	observation with label <quote>USA</quote>.</para>

      <para>
	One point should be noted about the <lit>--dummy</lit>,
	<lit>--restrict</lit> and <lit>--no-missing</lit> forms of
	<lit>smpl</lit>: Any <quote>structural</quote> information in
	the data file (regarding the time series or panel nature of
	the data) is lost when this command is issued.  You may
	reimpose structure with the <cmdref targ="setobs"/> command.
      </para>
    </description>

    <gui-access>
      <menu-path>/Sample</menu-path>
    </gui-access>

  </command>

  <command name="spearman" section="Statistics">

    <usage>
      <arguments>
        <argument>x</argument>
        <argument>y</argument>
      </arguments>
      <options>
        <option>
	  <flag>--verbose</flag>
	  <effect>print ranked data</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Prints Spearman's rank correlation coefficient for the two
	variables <mathvar>x</mathvar> and <mathvar>y</mathvar>. The
	variables do not have to be ranked manually in advance; the
	function takes care of this.
      </para>

      <para>
	The automatic ranking is from largest to smallest (i.e. the
	largest data value gets rank 1).  If you need to invert this
	ranking, create a new variable which is the negative of the
	original first.  For example:
      </para>

      <code>
	genr altx = -x
	spearman altx y</code>
    </description>

    <gui-access>
      <menu-path>/Model/Rank correlation</menu-path>
    </gui-access>

  </command>

  <command name="square" section="Transformations">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
        <option>
	  <flag>--cross</flag>
	  <effect>generate cross-products as well as squares</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Generates new variables which are squares of the variables in
	<repl>varlist</repl> (plus cross-products if the
	<lit>--cross</lit> option is given).  For example, <cmd>square
	  x y</cmd> will generate <lit>sq_x</lit> = <lit>x</lit>
	squared, <lit>sq_y</lit> = <lit>y</lit> squared and
	(optionally) <lit>x_y</lit> = <lit>x</lit> times <lit>y</lit>.
	If a particular variable is a dummy variable it is not squared
	because we will get the same variable.  
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Add variables/squares of variables</menu-path>
    </gui-access>

  </command>

  <command name="store" section="Dataset">

    <usage>
      <arguments>
        <argument>datafile</argument>
        <argument optional="true">varlist</argument>
      </arguments>
      <options>
        <option>
	  <flag>--csv</flag>
	  <effect>use CSV format</effect>
        </option>
        <option>
	  <flag>--gnu-octave</flag>
	  <effect>use GNU Octave format</effect>
        </option>
        <option>
	  <flag>--gnu-R</flag>
	  <effect>use GNU R format</effect>
        </option>
        <option>
	  <flag>--traditional</flag>
	  <effect>use traditional ESL format</effect>
        </option>
        <option>
	  <flag>--gzipped</flag>
	  <effect>apply gzip compression</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Saves either the entire dataset or, if a <repl>varlist</repl>
	is supplied, a specified subset of the variables in the
	current dataset, to the file given by
	<repl>datafile</repl>.</para>

      <para>
	By default the data are saved in <quote>native</quote> gretl
	format, but the option flags permit saving in several
	alternative formats.  CSV (Comma-Separated Values) data may be
	read into spreadsheet programs, and can also be manipulated
	using a text editor.  The formats of <program>Octave</program>
	and <program>R</program> are designed for use with the
	respective programs.  Gzip compression may be useful for large
	datasets.  See <manref targ="datafiles"/> for details on the
	various formats.</para>

      <para>
	Note that any scalar variables will not be saved
	automatically: if you wish to save scalars you must explicitly
	list them in <repl>varlist</repl>.
      </para>  
	
    </description>

    <gui-access>
      <menu-path>/File/Save data; /File/Export data</menu-path>
    </gui-access>

  </command>

  <command name="summary" section="Statistics">

    <usage>
      <arguments>
        <argument optional="true">varlist</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Print summary statistics for the variables in
	<repl>varlist</repl>, or for all the variables in the data set
	if <repl>varlist</repl> is omitted. Output consists of the
	mean, standard deviation (sd), coefficient of variation (=
	sd/mean), median, minimum, maximum, skewness coefficient, and
	excess kurtosis.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Summary statistics</menu-path>
      <other-access>Main window pop-up menu</other-access>
    </gui-access>

  </command>

  <command name="system" section="Estimation">

    <usage>
      <arguments>
        <argument>type</argument>
        <argument>savevars</argument>
      </arguments>
      <examples>
        <example>system type=sur</example>
	<example>system type=sur save=resids</example>
	<example>system type=sur save=resids,fitted</example>
      </examples>
    </usage>

    <description>
      <para>
	Starts a system of equations.  At present the only type of
	system supported is <cmd>sur</cmd> (Seemingly Unrelated
	Regressions).  In the optional <cmd>save=</cmd> field of the
	command you can specify whether to save the residuals
	(<cmd>resids</cmd>) and/or the fitted values
	(<cmd>fitted</cmd>).  The system must contain at least two
	equations specified using the <cmd>equation</cmd> command, and
	it must be terminated with the line <cmd>end system</cmd>.
      </para>
    </description>

  </command>

  <command name="tabprint" section="Printing">

    <usage>
      <arguments>
        <argument optional="true">-f filename</argument>
      </arguments>
      <options>
        <option>
	  <flag>--complete</flag>
	  <effect>Create a complete document</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Must follow the estimation of a model.  Prints the estimated
	model in the form of a &latex; table.  If a filename is
	specified using the <lit>-f</lit> flag output goes to that
	file, otherwise it goes to a file with a name of the form
	<filename>model_N.tex</filename>, where <lit>N</lit> is the
	number of models estimated to date in the current session. See
	also <cmdref targ="eqnprint"/>.
      </para>

      <para>
	If the <lit>--complete</lit> flag is given the &latex; file is
	a complete document, ready for processing; otherwise it must
	be included in a document.
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /LaTeX</menu-path>
    </gui-access>

  </command>

  <command name="testuhat" section="Tests">

    <description>
      <para>
	Must follow a model estimation command.  Gives the frequency
	distribution for the residual from the model along with a
	chi-square test for normality, based on the procedure
	suggested by Doornik and Hansen (1984).
      </para>
    </description>

    <gui-access>
      <menu-path>Model window, /Tests/normality of residual</menu-path>
    </gui-access>

  </command>

  <command name="tobit" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
        </option>
        <option>
	  <flag>--verbose</flag>
	  <effect>print details of iterations</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>Estimates a Tobit model.  This model may be appropriate
	when the dependent variable is <quote>truncated</quote>.  For
	example, positive and zero values of purchases of durable
	goods on the part of individual households are observed, and
	no negative values, yet decisions on such purchases may be
	thought of as outcomes of an underlying, unobserved
	disposition to purchase that may be negative in some cases.
	For details see Greene's <book>Econometric Analysis</book>,
	Chapter 20.</para>
    </description>

    <gui-access>
      <menu-path>/Model/Tobit</menu-path>
    </gui-access>

  </command>

  <command name="tsls" section="Estimation">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
	<argument separated="true">instruments</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
        </option>
      </options>      
      <examples>
        <example>tsls y1 0 y2 y3 x1 x2 ; 0 x1 x2 x3 x4 x5 x6</example>
      </examples>
    </usage>

    <description>
      <para>
	Computes two-stage least squares (TSLS) estimates:
	<repl>depvar</repl> is the dependent variable,
	<repl>indepvars</repl> is the list of independent variables
	(including right-hand side endogenous variables) in the
	structural equation for which TSLS estimates are needed; and
	<repl>instruments</repl> is the combined list of exogenous and
	predetermined variables in all the equations. If the
	<repl>instruments</repl> list is not at least as long as
	<repl>indepvars</repl>, the model is not identified.</para>

      <para>
	In the above example, the <lit>y</lit>s are the endogenous
	variables and the <lit>x</lit>s are the exogenous and
	predetermined variables.  
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Two-Stage least Squares</menu-path>
    </gui-access>

  </command>

  <command name="var" section="Estimation">

    <usage>
      <arguments>
        <argument>order</argument>
        <argument>varlist</argument>
	<argument separated="true">detlist</argument>
      </arguments>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>don't print impulse responses etc.</effect>
        </option>
      </options>
      <examples>
        <example>var 4 x1 x2 x3 ; const time</example>
      </examples>
    </usage>

    <description>
      <para>
	Sets up and estimates (using OLS) a vector autoregression
	(VAR).  The first argument specifies the lag order, then
	follows the setup for the first equation.  Don't include lags
	among the elements of <repl>varlist</repl> &mdash; they will
	be added automatically.  The semi-colon separates the
	stochastic variables, for which <repl>order</repl> lags will
	be included, from deterministic terms in <repl>detlist</repl>,
	such as the constant, a time trend, and dummy
	variables.</para>

      <para>
	In fact, gretl is able to recognize the more common
	deterministic variables (constant, time trend, dummy variables
	with no values other than 0 and 1) as such, so these do not
	have to placed after the semi-colon.  More complex
	deterministic variables (e.g. a time trend interacted with a
	dummy variable) must be put after the semi-colon.</para>

      <para>
	A separate regression is run for each variable in varlist.
	Output for each equation includes <mathvar>F</mathvar>-tests
	for zero restrictions on all lags of each of the variables; an
	<mathvar>F</mathvar>-test for the significance of the maximum
	lag; forecast variance decompositions; and impulse response
	functions.</para>

      <para>
	The variance decompositions and impulse responses are based on
	the Cholesky decomposition of the contemporaneous covariance
	matrix, and in this context the order in which the
	(stochastic) variables are given matters.  The first variable
	in the list is assumed to be <quote>most exogenous</quote>
	within-period.</para> 
    </description>

    <gui-access>
      <menu-path>/Model/Vector autoregression</menu-path>
    </gui-access>

  </command>

  <command name="varlist" section="Dataset">

    <description>
      <para>
	Prints a listing of variables currently available.
	<cmd>list</cmd> and <cmd>ls</cmd> are synonyms.  
      </para>
    </description>

  </command>

  <command name="vartest" section="Tests">

    <usage>
      <arguments>
        <argument>var1</argument>
        <argument>var2</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Calculates the <mathvar>F</mathvar> statistic for the null
	hypothesis that the population variances for the variables
	<repl>var1</repl> and <repl>var2</repl> are equal, and shows
	its p-value.
      </para>
    </description>

    <gui-access>
      <menu-path>/Data/Difference of variances</menu-path>
    </gui-access>

  </command>

  <command name="wls" section="Estimation">

    <usage>
      <arguments>
        <argument>wtvar</argument>
        <argument>depvar</argument>
	<argument>indepvars</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>print covariance matrix</effect>
        </option>
      </options> 
    </usage>

    <description>
      <para>
	Computes weighted least squares estimates using
	<repl>wtvar</repl> as the weight, <repl>depvar</repl> as the
	dependent variable, and <repl>indepvars</repl> as the list of
	independent variables.  Specifically, an OLS regression is run
	on <repl>wtvar</repl> <lit>*</lit> <repl>depvar</repl> against
	<repl>wtvar</repl> <lit>*</lit> <repl>indepvars</repl>. If the
	<repl>wtvar</repl> is a dummy variable, this is equivalent to
	eliminating all observations with value zero for
	<repl>wtvar</repl>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Weighted Least Squares</menu-path>
    </gui-access>

  </command>

</commandlist>

