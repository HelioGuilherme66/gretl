<?xml version="1.0" encoding="ISO-8859-1" ?>
<!DOCTYPE commandref SYSTEM "gretl_commands.dtd">

<commandref language="italian">

<?PSGML NOFILL label code altforms altform menu-path equation other-access?>

  <command name="add" section="Tests" label="Aggiunge variabili al modello">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--lm</flag>
	  <effect>effettua un test LM (solo OLS)</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le stime del modello aumentato</effect>
	</option>
 	<option>
 	  <flag>--silent</flag>
 	  <effect>non mostra nulla</effect>
 	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
        <option>
          <flag>--both</flag>
          <effect>aggiunge come regressore e come strumento, solo per TSLS</effect>
        </option>
      </options>
      <examples>
        <example>add 5 7 9</example>
        <example>add xx yy zz --quiet</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Va invocato dopo un comando di stima. Esegue un test congiunto
	per l'aggiunta delle variabili specificate all'ultimo modello
	stimato; si può avere accesso ai risultati del test tramite
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>.
      </para>
      <para context="cli">
	Di default, aggiunge al modello precedente le variabili nella
	<repl>lista-variabili</repl> e stima il nuovo modello.  Il
	test è un test di Wald sul modello aumentato, che rimpiazza
	quello originale come <quote>ultimo modello</quote> per quanto
	riguarda,ad esempio, il contenuto di <lit>$uhat</lit> o test
	ulteriori.
      </para>
      <para context="cli">
	Alternativamente, con l'opzione <opt>lm</opt> (disponibile
	solo per i modelli stimati via OLS), viene effettuato un test
	LM. Viene eseguita una regressione ausiliaria in cui la
	variabile dipendente è il residuo dell'ultimo modello e le
	variabili indipendenti sono quello del modello originale più
	<repl>lista-variabili</repl>. Sotto l'ipotesi nulla che le
	variabili aggiuntive non hanno potere esplicativo, il prodotto
	fra l'R-quadro non aggiustato della regressione ausiliaria e
	il numero di osservazioni si distribuisce come una chi quadro
	con tanti gradi di libertà quante sono le variabili in
	<repl>lista-variabili</repl>. In questo caso, il modello
	originale non viene rimpiazzato.
      </para>
      <para context="cli">
	L'opzione <opt>both</opt> è specifica per le stime con i
	minimi quadrati a due stadi: essa indica che le nuove
	variabili vanno aggiunte sia alla lista dei regressori che a
	quella degli strumenti; di default, infatti, la
	<repl>lista-variabili</repl> viene aggiunta soltanto ai
	regressori.
      </para>
      <para context="gui">
	Aggiunge le variabili selezionate al modello precedente e
	stima il nuovo modello. Viene eseguito anche un test per la
	significatività congiunta delle variabili aggiunte.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/ADD - Aggiungi variabili</menu-path>
    </gui-access>

  </command>

  <command name="addline" section="Graphs" label="Aggiunge una linea al grafico"
    context="gui">

    <description>
      <para>
        Questa finestra di dialogo permette di aggiungere a un grafico
        una linea, definita attraverso una formula che deve essere
        un'espressione accettabile da gnuplot. Occorre usare
        <lit>x</lit> per indicare il valore della variabile sull'asse
        x. Si noti inoltre che gnuplot usa <lit>**</lit> per
        l'elevamento a potenza, e il punto <quote>.</quote> come
        separatore decimale. Esempi:
      </para>
      <code>
	10+0.35*x
	100+5.3*x-0.12*x**2
	sin(x)
	exp(sqrt(pi*x))
      </code>
    </description>
  </command>

  <command name="adf" section="Tests" label="Test Dickey-Fuller aumentato">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>test senza costante</effect>
	</option>
	<option>
	  <flag>--c</flag>
	  <effect>solo con la costante</effect>
	</option>
	<option>
	  <flag>--ct</flag>
	  <effect>con costante e trend</effect>
	</option>
	<option>
	  <flag>--ctt</flag>
	  <effect>con costante, trend e trend al quadrato</effect>
	</option>
        <option>
	  <flag>--seasonals</flag>
	  <effect>include variabili dummy stagionali</effect>
        </option>
        <option>
         <flag>--gls</flag>
         <effect>rimuove la media o il trend usando GLS</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i risultati della regressione</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
	<option>
	  <flag>--difference</flag>
	  <effect>usa la differenza prima della variabile</effect>
	</option>
	<option>
	  <flag>--test-down</flag>
	  <optparm optional="true">criterio</optparm>
	  <effect>ordine di ritardo automatico</effect>
	</option>
      </options>
      <examples>
	<example>adf 0 y</example>
        <example>adf 2 y --nc --c --ct</example>
        <example>adf 12 y --c --test-down</example>
	<demos>
	  <demo>jgm-1996.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="gui">Questo comando richiede un ordine di ritardo intero;
       se si indica un ordine pari a zero, viene eseguito un test
       Dickey&ndash;Fuller standard (non aumentato). Il comando calcola una
       serie di test Dickey&ndash;Fuller sulla variabile selezionata, assumendo
       come ipotesi nulla che la variabile abbia una radice unitaria. Se si usa
       l'opzione di differenziazione, i test vengono condotti sulla differenza
       prima della variabile e la discussione che segue va riferita a questa
       trasformazione della variabile.
       </para>
       
      <para context="cli">
	Le opzioni precedenti e la discussione seguente si riferiscono all'uso del comando 
	<lit>adf</lit> con serie storiche regolari. La discussione dell'uso con
	dati panel è esposta più avanti.
      </para>

      <para context="cli">
	Calcola una serie di test Dickey&ndash;Fuller sulle variabili
	specificate, assumendo come ipotesi nulla che le variabili
	abbiano una radice unitaria. Se si usa l'opzione
	<opt>difference</opt>, i test vengono condotti sulla
	differenza prima delle variabili e la discussione che segue va
	riferita a questa trasformazione delle variabili.
      </para>

      <para context="cli">
        Per impostazione predefinita, vengono mostrate due varianti del
        test: una basata su una regressione che contiene solo una costante,
        e una che include la costante e un trend lineare. È possibile
        controllare le varianti specificando una o più opzioni.
      </para>
      
      <para>
	In tutti i casi, la variabile dipendente è la differenza prima
        della variabile specificata, <math>y</math>, e la variabile
        dipendente più importante è il ritardo (di ordine uno) di
        <math>y</math>. Il modello è costruito in modo che il coefficiente
        della variabile ritardata <math>y</math> è pari a 1 meno
        la radice. Ad esempio, il modello con una costante può essere
        scritto come <equation status="display"
        tex="\[(1-L)y_t=\beta_0+(\alpha-1)y_{t-1}+\epsilon_t\]"
        ascii="(1 - L)y(t) = b0 + (a-1)y(t-1) + e(t)"
	graphic="adf1"/> Sotto l'ipotesi nulla di radice unitaria il coefficiente 
	della <math>y</math> ritardata è nullo; sotto l'alternativa che 
	<math>y</math> sia stazionaria il coefficiente è negativo.
      </para>

      <para context="cli">
        Se l'ordine di ritardi, <math>k</math>, è maggiore di 0, ai
        regressori di ognuna delle regressioni calcolate per il test
        saranno aggiunti <math>k</math> ritardi della variabile
        dipendente. Se l'ordine è &minus;1, <math>k</math> è impostato
        secondo la raccomandazione di <cite key="schwert89">Schwert
        (1989)</cite>, ossia 12(<math>T</math>/100)<sup>0.25</sup>,
        dove <math>T</math> è l'ampiezza campionaria. In tutti e due i
        casi, comunque, se si usa l'opzione <opt>test-down</opt>,
        <math>k</math> viene interpretato come ritardo massimo, mentre
        l'ordine di ritardo effettivamente usato viene ottenuto
        testando "all'indietro".  Il criterio per effettuare il test
        all'indietro può essere selezionato usando il parametro
        opzionale e deve essere uno fra <lit>MAIC</lit>,
        <lit>MBIC</lit> o <lit>tstat</lit>.  I metodi MAIC e MBIC sono
        descritti in <cite key="ng-perron01">Ng and Perron
        (2001)</cite>; l'ordine dei ritardi viene scelto in modo da
        ottimizzare rispettivamente una versione modificata del
        Criterio di Informazione di Akaike o del Criterio Bayesiano di
        Schwartz. Il metodo MAIC è quello applicato di default quando
        non viene esplicitamente dichiarato un metodo. Il metodo tstat
        è il seguente:
      </para>

      <para context="gui">
        Se l'ordine di ritardi, <math>k</math>, è maggiore di 0, ai
        regressori di ognuna delle regressioni calcolate per il test
        saranno aggiunti <math>k</math> ritardi della variabile
        dipendente, con la precisazione che segue. Se viene
        selezionata la casella <quote>test per il ritardo
        massimo</quote>, l'ordine selezionato verrà considerato come
        ordine massimo, e l'ordine da usare effettivamente sarà
        ricavato applicando la seguente procedura di test
        "all'indietro", usando il criterio scelto tramite la tendina
        associata. I metodi AIC e BIC modificati sono descritti in
        <cite key="ng-perron01">Ng and Perron (2001)</cite>; l'ordine
        dei ritardi viene scelto in modo da ottimizzare
        rispettivamente una versione modificata del Criterio di
        Informazione di Akaike o del Criterio Bayesiano di
        Schwartz. Il metodo della statistica <math>t</math> è il
        seguente:
      </para>

      <nlist>
	<li><para>Stima la regressione Dickey&ndash;Fuller con
	    <math>k</math> ritardi della variabile dipendente.
	  </para>
	</li>
	<li><para>Se questo ordine di ritardi è significativo, esegue
	il test con l'ordine di ritardo <math>k</math>.  Altrimenti,
	prova il test con <math>k</math> = <math>k</math> &minus; 1;
	se <math>k</math> = 0, esegue il test con ordine di ritardo 0,
	altrimenti va al punto 1.
	  </para>
	</li>
      </nlist>

      <para>
        Durante il punto 2 spiegato sopra, <quote>significativo</quote>
        significa che la statistica <math>t</math> per l'ultimo ritardo
        abbia un <emphasis>p</emphasis>-value asintotico a due code per la
        distribuzione normale pari a 0.10 o inferiore.
      </para> 

      <para context="cli">
        L'opzione <opt>gls</opt> può essere usata insieme a una
        delle altre due opzioni <opt>c</opt> e <opt>ct</opt> (il
        modello con costante o quello con costante e trend). L'effetto
        di questa opzione è di rimuovere la media o il trend della
        variabile da testare, usando la procedura GLS suggerita da
        <cite key="ERS96">Elliott, Rothenberg and Stock (1996)</cite>,
        che fornisce un test di potenza maggiore rispetto a
        quell'approccio standard di Dickey&ndash;Fuller. Questa
        opzione non è compatibile con le opzioni <opt>nc</opt>,
        <opt>ctt</opt> o <opt>seasonals</opt>.
      </para>
      <para>
        I <emphasis>p-</emphasis>value per questo test sono basati su
        MacKinnon (1996). Il codice rilevante è incluso per gentile
        concessione dell'autore. Nel caso del test con trend lineare
        usando la procedura GLS questi <emphasis>P</emphasis>-value
        non sono utilizzabili; vengono usati i valori critici
        contenuti nella Tabella 1 di <cite key="ERS96">Elliott,
        Rothenberg and Stock (1996)</cite>.
      </para>

      <subhead context="cli">Dati panel</subhead>

      <para context="cli">
	Quando il comando <lit>adf</lit> è usato con dati panel per calcolare 
	un test panel di radici unitarie le opzioni applicabili sono leggermente
	diverse.
      </para>

      <para context="cli">
	In primo luogo, mentre nel caso di serie storiche regolari è
	possibile indicare un elenco di variabili da testare, con dati panel
	ciascun comando può esaminare una sola variabile alla volta.
	Secondo, le opzioni che governano l'inclusione di trend
	deterministici diventano mutualmente esclusive: è necessario
	scegliere fra il caso senza costante, quello con solo la costante,
	e quello che la costante e il trend; il default è il secondo.
	L'opzione <opt>seasonals</opt>, inoltre, non è disponibile.
	Terzo, l'opzione  <opt>verbose</opt> ha un significato diverso:
	produce un breve resoconto del test per ciascuna singola
	serie storica (il default prevede di mostrare solo il risultato complessivo).
      </para>
      <para context="cli">
	Il test complessivo (ipotesi nulla: la variabile in questione
	ha una radice unitaria per tutte le unità panel) viene
	calcolata in uno o in entrambi i modi disponibili: usando il
	metodo di <cite key="IPS03">Im, Pesaran and Shin (Journal of
	Econometrics, 2003)</cite> oppure quello di <cite
	key="choi01">Choi (Journal of International Money and Finance,
	2001)</cite>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Test di radice unitaria/Test Dickey-Fuller
      aumentato</menu-path>
    </gui-access>

  </command>

  <command name="anova" label="ANOVA" section="Statistics">
    <usage>
      <arguments>
        <argument>response</argument>
        <argument>treatment</argument>
        <argument optional="true">block</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampare i risultati</effect>
	</option>
      </options>
    </usage>
    <description>
      <para>
	Analisi della varianza: <repl>response</repl> è una serie che
	misura un effetto di interesse e <repl>treatment</repl> deve
	essere una variabile discreta che identifica due o più tipi di
	trattamento (o non trattamento).  Nel caso dell'ANOVA a due
	vie, la variabile <repl>block</repl> (anch'essa discreta)
	identifica i valori di qualche variabile di controllo.
      </para>
      <para context="cli">
	Se non è stata selezionata l'opzione <opt>quiet</opt>,
	questo comando stampa una tabella che mostra le somme e le
	medie dei quadrati, nonché un test <math>F</math>.  Il test
	<math>F</math> e il suo <emphasis>p-</emphasis>value possono
	essere recuperati rispettivamente con gli accessori
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>.
      </para>
      <para>
	L'ipotesi nulla del test <math>F</math> è che la risposta
	media sia invariante rispetto al tipo di trattamento; in altre
	parole, che il trattamento non abbia alcun
	effetto. Formalmente, la validità del test richiede che la
	varianza della risposta sia la stessa per tutti i tipi di
	trattamento.
      </para>
      <para>
	Si noti che i risultati prodotti da questo comando
	costituiscono in realtà un sottoinsieme dell'informazione
	fornita dalla procedura seguente, facilmente implementabile in
	gretl. Create un insieme di variabili dummy associate a tutti
	i tipi di trattamento, tranne uno. Nel caso dell'ANOVA a due
	vie, create anche un insieme di variabili dummy associate a
	tutti i <quote>blocchi</quote>, tranne uno. Una volta fatto
	questo, regredite <repl>response</repl> su una costante e le
	dummy usando <cmdref targ="ols"/>.  Per un'analisi a una via
	la tabella ANOVA può essere creata ricorrendo all'opzione
	<opt>anova</opt> del comando <lit>ols</lit>.  Nel caso di
	un'analisi a due vie il test <math>F</math> può essere
	calcolato usando il comando <cmdref targ="omit"/>. Per
	esempio, se assumiamo che <lit>y</lit> sia la risposta,
	<lit>xt</lit> identifichi il trattamento e <lit>xb</lit>
	identifichi i blocchi:
      </para>
      <code>
	# analisi a una via
	list dxt = dummify(xt)
	ols y 0 dxt --anova
	# analisi a due vie
	list dxb = dummify(xb)
	ols y 0 dxt dxb
	# test di significatività congiunta di dxt
	omit dxt --quiet
      </code>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/ANOVA</menu-path>
    </gui-access>

  </command>

  <command name="append" section="Dataset" label="Aggiunge dati" context="cli">

    <usage>
      <arguments>
        <argument>file-dati</argument>
      </arguments>
      <options>
	<option>
	  <flag>--time-series</flag>
	  <effect>si veda oltre</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Apre un file di dati e aggiunge il suo contenuto al dataset
        attuale, se i nuovi dati sono compatibili. Il programma cerca
        di riconoscere il formato del file di dati (interno, testo semplice,
        CSV, Gnumeric, Excel, ecc.).
      </para>
      <para>
	I dati aggiunti possono avere la forma di osservazioni aggiuntive su
        variabili già presenti nel dataset, o di nuove variabili. In
        quest'ultimo caso occorre che il numero delle nuove osservazioni sia
        pari a quello delle osservazioni presenti nel dataset, oppure che i
        nuovi dati includano informazioni precise sulle osservazioni in modo che
        gretl possa capire come aggiungere i valori.
      </para>
      <para>
	Nel caso di aggiunta di dati a un dataset panel, c'è una
	possibilità speciale. Detti <math>n</math> il numero di unità
	cross-section, <math>T</math> il numero di periodi temporali,
	e <math>m</math> il numero di nuove osservazioni da
	aggiungere. Se <math>m = n</math> i nuovi dati saranno
	considerati invarianti nel tempo, e saranno copiati per ognuno
	dei periodi temporali. D'altra parte, se <math>m = T</math> i
	dati saranno trattati come invarianti tra le unità. Se il
	panel è <quote>quadrato</quote>, ed <math>m</math> è pari sia
	ad <math>n</math> che a <math>T</math>, il comportamento
	predefinito consiste nel trattare i nuovi casi come invarianti
	nel tempo, ma è possibile forzare l'interpretazione dei nuovi
	dati come serie storiche usando l'opzione
	<lit>--time-series</lit> (che verrà ignorata in tutti gli
	altri casi).
      </para>
      <para>
	Vedi anche <cmdref targ="join"/> per una gestione più
	sofisticata di più di un file di dati esterno.
      </para>

    </description>

    <gui-access>
      <menu-path>/File/Aggiungi dati</menu-path>
    </gui-access>

  </command>

  <command name="ar" section="Estimation" label="Stima autoregressiva">

    <usage>
      <arguments>
        <argument>ritardi</argument>
	<argument separated="true">variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
      </options>
      <examples>
        <example>ar 1 3 4 ; y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para> 
	Calcola le stime parametriche usando la procedura iterativa
	generalizzata di Cochrane&ndash;Orcutt (si veda il Capitolo
	9.5 di <cite key="ramanathan02">Ramanathan (2002)</cite>. La
	procedura termina quando le somme dei quadrati degli errori
	consecutivi non differiscono per più dello 0.005 per cento,
	oppure dopo 20 iterazioni.</para>

      <para context="gui">
	La <quote>lista dei ritardi AR</quote> specifica la struttura
	del processo dell'errore.  Ad esempio, l'indicazione <quote>1
	3 4</quote> corrisponde al processo:
	<equation status="display" 
	  tex="\[u_t = \rho_1u_{t-1} + \rho_3 u_{t-3} +
	    \rho_4 u_{t-4} + e_t\]"
	  ascii="u(t) = rho1*u(t-1) + rho3*u(t-3) + rho4*u(t-4)"
	  graphic="arlags"/>
      </para>

      <para context="cli">
	<repl quote="true">ritardi</repl> è una lista di ritardi nei
	residui, conclusa da un punto e virgola. Nell'esempio
	precedente, il termine di errore è specificato come
	<equation status="display" 
	  tex="\[u_t = \rho_1u_{t-1} + \rho_3 u_{t-3} +
	    \rho_4 u_{t-4} + e_t\]"
	  ascii="u(t) = rho(1)*u(t-1) + rho(3)*u(t-3) + rho(4)*u(t-4)"
	  graphic="arlags"/>
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/AR - Stima autoregressiva</menu-path>
    </gui-access>

  </command>

  <command name="ar1" section="Estimation" label="Stima AR(1)">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--hilu</flag>
	  <effect>usa la procedura di Hildreth&ndash;Lu</effect>
	</option>
	<option>
	  <flag>--pwe</flag>
	  <effect>usa lo stimatore di Prais&ndash;Winsten</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--no-corc</flag>
	  <effect>non affinare i risultati con Cochrane-Orcutt</effect>
	</option>
      </options>
      <examples>
        <example>ar1 1 0 2 4 6 7</example>
	<example>ar1 y 0 xlist --hilu --no-corc</example>
	<example>ar1 y 0 xlist --pwe</example>
      </examples>
    </usage>

    <description>
      <para>
        Calcola stime feasible GLS per un modello in cui il termine di errore
        segue un processo autoregressivo del prim'ordine.
      </para>
      <para>
	Il metodo predefinito è la procedura iterativa di
	Cochrane&ndash;Orcutt (si veda ad esempio il capitolo 9.4 di
	<cite key="ramanathan02">Ramanathan, 2002</cite>). La
	procedura termina quando le stime successive del coefficiente
	di autocorrelazione non differiscono per più di 0.001, oppure
	dopo 20 iterazioni.
      </para>
      <para>
	Se si usa l'opzione <opt>hilu</opt>, verrà usata la
	procedura di ricerca di Hildreth&ndash;Lu.  I risultati sono
	quindi ottimizzati con la procedura iterativa di
	Cochrane&ndash;Orcutt, a meno che non si usi l'opzione
	<lit>--no-corc</lit> (che viene ignorata se non viene
	specificata <opt>hilu</opt>).
      </para>
      <para>
        Se si usa l'opzione <opt>pwe</opt>, viene usato lo stimatore di
        Prais&ndash;Winsten, che prevede una procedura simile a quella di
        Cochrane&ndash;Orcutt; la differenza è che mentre Cochrane&ndash;Orcutt
        tralascia la prima osservazione, Prais&ndash;Winsten ne fa uso.  Per i
        dettagli, si veda per esempio il capitolo 13 di <book>Econometric
        Analysis</book> di <cite key="greene00">Greene (2000)</cite>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/Cochrane-Orcutt</menu-path>
      <menu-path>/Modello/Serie storiche/Hildreth-Lu</menu-path>
      <menu-path>/Modello/Serie storiche/Prais-Winsten</menu-path>
    </gui-access>

  </command>

  <command name="arbond" section="Estimation" label="Modelli panel dinamici">

    <usage>
      <arguments>
	<argblock>
	  <argument>p</argument>
	  <argument optional="true">q</argument>
	</argblock>
	<argblock separated="true">
          <argument>variabile-dipendente</argument>
	  <argument>variabili-indipendenti</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>strumenti</argument>
	</argblock>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra il modello stimato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra matrice di covarianza</effect>
	</option>
        <option>
	  <flag>--two-step</flag>
	  <effect>usa stima GMM 2-step</effect>
        </option>
        <option>
	  <flag>--time-dummies</flag>
	  <effect>aggiunge variabili dummy temporali</effect>
        </option>
        <option>
	  <flag>--asymptotic</flag>
	  <effect>calcola gli errori standard asintotici nel modo standard</effect>
        </option>
      </options>
      <examples>
        <example>arbond 2 ; y Dx1 Dx2</example>
        <example>arbond 2 5 ; y Dx1 Dx2 ; Dx1</example>
	<example>arbond 1 ; y Dx1 Dx2 ; Dx1 GMM(x2,2,3)</example>
	<demos>
	  <demo>arbond91.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Esegue la stima di modelli panel dinamici (ossia, modelli
	panel che includono uno o più ritardi della variabile
	dipendente) usando il metodo GMM proposto da <cite
	key="arellano-bond91">Arellano and Bond (1991)</cite>.  Vedi,
	tuttavia, il comando <cmdref targ="dpanel"/> per una
	alternativa più avanzata e più flessibile, che offre lo
	stimatore GMM-SYS oltre al GMM-DIF.
      </para>
      <para context="cli">
	Il parametro <repl>p</repl> rappresenta l'ordine
	dell'autoregressione per la variabile dipendente. Il parametro
	opzionale <repl>q</repl> indica il massimo ritardo del livello
	della variabile dipendente da usare come strumento; se si
	omette questo argomento, o lo si pone uguale a 0, vengono
	usati tutti i ritardi disponibili.
      </para>
      <para>
	La variabile dipendente andrebbe specificata in livelli; viene
	differenziata automaticamente, visto che lo stimatore usa la
	differenziazione per eliminare gli effetti individuali. Le
	variabili indipendenti invece non vengono differenziate
	automaticamente: se si intende usare le differenze
	(tipicamente lo si vorrà fare per le variabili quantitative,
	ma non ad esempio per le dummy temporali), occorrerà prima
	creare le variabili differenziate e poi specificarle come
	regressori.
      </para>
      <para context="cli">
	L'ultimo campo (opzionale) del comando consente di specificare
	gli strumenti. Se non viene usato, si assumerà che tutte le
	variabili indipendenti sono strettamente esogene. Se si
	specifica uno strumento, occorre includere nell'elenco tutte
	le variabili indipendenti strettamente esogene. Per i
	regressori predeterminati, è possibile usare la funzione
	<lit>GMM</lit> per includere un intervallo specifico di
	ritardi in stile "diagonale". Questo modo di procedere è
	illustrato nel terzo esempio visto sopra. Il primo argomento
	di <lit>GMM</lit> è il nome della variabile in questione, il
	secondo è il ritardo minimo da usare, mentre il terzo è quello
	massimo. Se il terzo argomento è pari a 0, vengono usati tutti
	i ritardi disponibili.
      </para>
      <para>
	Per impostazione predefinita, vengono mostrati i risultati
	della stima a un passo (con errori standard robusti), ma è
	possibile scegliere una stima a due passi. In entrambi i casi,
	vengono mostrati i testi per l'autocorrelazione di ordine 1 e
	2, oltre al test di sovraidentificazione di Sargan. Si noti
	che in questo modello differenziato l'autocorrelazione del
	prim'ordine non contrasta con la validità del modello, mentre
	quella di ordine 2 viola le ipotesi statistiche che ne sono
	alla base.
      </para>
      <para>
        Nel caso della stima in due passi, gli errori standard sono
        calcolati usando la correzione per campioni finiti suggerita
        da<cite key="windmeijer05">Windmeijer (2005)</cite>.  Gli
        errori standard asintotici calcolati nel modo consueto non
        sono generalmente ritenuti affidabili nel caso dello stimatore
        a due passi, ma se per qualche motivo si vuole usarli, è
        possibile usare l'opzione <opt>asymptotic</opt> per
        disabilitare la correzione di Windmeijer.
      </para>
      <para>
	Se si usa l'opzione <lit>--time-dummies</lit>, viene aggiunto ai
        regressori un insieme di variabili dummy temporali. Il numero di
        variabili dummy è pari al numero massimo dei periodi usati nella stima
        meno uno, per evitare la perfetta collinearità in presenza della
        costante. Le dummy sono specificate in livelli; se si intende usare
        variabili dummy sotto forma di differenze temporali, occorre definirle
        ed aggiungerle manualmente.
       </para>
    </description>

    <gui-access>
      <menu-path>/Model/Panel</menu-path>
    </gui-access>

  </command>

  <command name="arch" section="Estimation" label="Modello ARCH">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <examples>
        <example>arch 4 y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Questo comando è attualmente mantenuto per ragioni di 
	compatibilità con le versioni precedenti, ma è preferibile
	usare lo stimatore di massima verosimiglianza disponibile
	mediante il comando <cmdref targ="garch"/>; per un modello 
	ARCH puro, fissate a 0 il primo parametro GARCH.
      </para>
      <para>
	Stima il modello specificato tenendo conto della possibile
        eteroschedasticità condizionale autoregressiva (ARCH,
	Autoregressive Conditional Heteroskedasticity). Per prima cosa il
        modello viene stimato con OLS, quindi viene eseguita una regressione
        ausiliaria, in cui i quadrati dei residui della prima regressione
        vengono regrediti sui loro valori ritardati. Il passo finale è una stima
        con minimi quadrati ponderati, in cui i pesi sono i reciproci delle
        varianze dell'errore della regressione ausiliaria (se la varianza
        prevista di qualche osservazione nella regressione ausiliaria non
        risulta positiva, viene usato il corrispondente residuo al quadrato).
       </para>
      <para>
	I valori <lit>alpha</lit> mostrati sotto i coefficienti sono i parametri
        del processo ARCH stimati nella regressione ausiliaria.
      </para>
      <para>
	Si veda anche <cmdref targ="garch"/> e <cmdref targ="modtest"/>
        (l'opzione <opt>arch</opt>).
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/ARCH</menu-path>
    </gui-access>

  </command>

  <command name="arima" section="Estimation" label="Stima ARMA/ARIMA">

    <usage>
      <arguments>
        <argblock>
          <argument>p</argument>
          <argument>d</argument>
          <argument>q</argument>
        </argblock>
 	<argblock separated="true" optional="true">
 	  <argument>P</argument>
	  <argument>D</argument>
 	  <argument>Q</argument>
 	</argblock>
	<argument separated="true">variabile-dipendente</argument>
	<argument optional="true">variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
	  <flag>--hessian</flag>
	  <effect>si veda sotto</effect>
        </option>
        <option>
         <flag>--opg</flag>
	 <effect>si veda sotto</effect>
        </option>
        <option>
         <flag>--nc</flag>
         <effect>non include l'intercetta</effect>
        </option>
        <option>
	  <flag>--conditional</flag>
	  <effect>usa la massima verosimiglianza condizionale</effect>
        </option>
        <option>
	  <flag>--x-12-arima</flag>
	  <effect>usa X-12-ARIMA per la stima</effect>
        </option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa il massimizzatore L-BFGS-B</effect>
	</option>
	<option>
	  <flag>--y-diff-only</flag>
	  <effect>speciale per ARIMAX, si veda sotto</effect>
	</option>
	<option>
	  <flag>--save-ehat</flag>
	 <effect>si veda sotto</effect>
	</option>
      </options>
      <examples>
        <example>arima 1 0 2 ; y</example>
	<example>arima 2 0 2 ; y 0 x1 x2 --verbose</example>
	<example>arima 0 1 1 ; 0 1 1 ; y --nc</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Se non viene fornita una lista di
	<repl>variabili-indipendenti</repl>, stima un modello
	autoregressivo integrato a media mobile (ARIMA:
	Autoregressive, Integrated, Moving Average) univariato.  I
	valori <repl>p</repl>, <repl>d</repl> e <repl>q</repl>
	rappresentano rispettivamente gli ordini dei termini
	autoregressivi (AR), l'ordine di differenziazione, e quello
	dei termini a media mobile (MA).  Questi valori possono essere
	indicati in forma numerica o con i nomi di variabili scalari
	preesistenti. Ad esempio, un valore <repl>d</repl> pari a 1
	significa che prima di stimare i parametri ARMA occorre
	prendere la differenza della variabile dipendente.
      </para>

      <para context="cli">
        Se si vuole includere solo alcuni specifici ritardi AR o MA
        (invece che tutti i ritardi fino all'ordine specificato) è
        possibile sostituire <repl>p</repl> e/o <repl>q</repl> in due
        modi: col nome di una matrice predefinita che contiene un
        insieme di valori interi, oppure con un'espressione come
        <lit>{1 4}</lit>, ossia un insieme di ritardi separati da
        spazi e racchiusi tra parentesi graffe.
      </para>
        
      <para context="cli">
        I valori interi opzionali <repl>P</repl>, <repl>D</repl> e
        <repl>Q</repl> rappresentano rispettivamente, l'ordine dei
        termini AR stagionali, l'ordine di differenziazione stagionale
        e l'ordine dei termini MA stagionali. Essi sono rilevanti solo
        la frequenza dei dati è superiore a 1 (ad esempio, dati
        trimestrali o mensili). Questi valori devono essere indicati
        in forma numerica o come variabili scalari.
      </para>
      
      <para context="cli">
        Nel caso univariato la scelta predefinita include
        un'intercetta nel modello, ma questa può essere soppressa con
        l'opzione <opt>nc</opt>.  Se vengono aggiunte delle
        <repl>variabili-indipendenti</repl>, il modello diventa un
        ARMAX: in questo caso occorre indicare esplicitamente la
        costante se si desidera un'intercetta (come nel secondo degli
        esempi proposti).
      </para>
      
      <para context="cli">
        È disponibile una sintassi alternativa per questo comando: se
        non si intende applicare alcuna operazione di differenziazione
        (stagionale o non stagionale), è possibile omettere totalmente
        i termini <repl>d</repl> e <repl>D</repl>, invece che
        impostarli esplicitamente pari a 0. Inoltre, <lit>arma</lit> è
        un sinonimo di <lit>arima</lit>, quindi ad esempio il comando
        seguente è un modo valido per specificare un modello
        ARMA(2,1):
      </para>
      <code context="cli">
	arma 2 1 ; y
      </code>
      
      <para context="gui">
	Stima un modello ARMA, con o senza regressori esogeni. Se
	l'ordine di differenziazione è maggiore di zero, il modello
	diventa un ARIMA. Se i dati hanno una frequenza superiore a 1,
	viene offerta la possibilità di includere termini stagionali.
      </para>

      <para context="gui">
        Se si vuole includere solo alcuni specifici ritardi AR o MA (invece che
        tutti i ritardi fino all'ordine specificato) è possibile marcare la
        casella a destra del selettore e scrivere nel campo disponibile
        un elenco di ritardi, separati da spazi. In alternativa, se è stata
        definita una matrice che contiene l'insieme dei ritardi desiderati, è
        possibile scrivere il suo nome nel campo.
      </para>

      <para>
        Il funzionamento predefinito utilizza la funzionalità ARMA
        <quote>interna</quote> di gretl, che usa la stima di massima
        verosimiglianza esatta usando il filtro di Kalman; come
        opzione è possibile usare la stima di massima verosimiglianza
        condizionale.  Se è stato installato il programma
        <program>X-12-ARIMA</program> è possibile usare questo al
        posto del codice interno di gretl.  Per i dettagli su queste
        opzioni si veda la <guideref targ="chap:timeseries"/>.
      </para>

      <para context="cli">
        Quando si usa il codice ARMA interno, le deviazioni standard
        sono stimate basandosi su un'approssimazione numerica
        all'inversa negativa dell'Hessiana, passando automaticamente
        al prodotto esterno del gradiente (OPG) in caso di problemi
        numerici. Se si usa l'opzione <opt>opg</opt> il prodotto
        esterno del gradiente viene usato in ogni caso. L'opzione
        <opt>hessian</opt>, invece, disabilita il passaggio
        automatico all'OPG in caso di problemi. Si noti, peraltro, che
        l'impossibilità di calcolare numericamente l'hessiana è per
        solito indice di un modello mal specificato.
      </para>

      <para context="cli">
	L'opzione <opt>lbfgs</opt> è riservata alla stima basata su codice 
	ARMA nativo e MV esatta; quando viene indicata, la stima usa l'algoritmo 
	L-BFGS a <quote>memoria limitata</quote> anziché l'ottimizzatore BFGS 
	consueto. Questa variante può essere utile in alcune situazioni nelle quali 
	la convergenza all'ottimo è problematica.
      </para>

      <para context="cli">
	L'opzione <opt>y-diff-only</opt> è riservata alla stima di modelli
	ARIMAX (modelli con ordine di integrazione non nullo e che includono
	regressori esogeni), e si applica solo con la stima di MV esatta nativa 
	di gretl. Per questi modelli il comportamento di default consiste nel
	differenziare sia la variabile dipendente che i regressori, ma quando
	viene indicata questa opzione viene differenziata solo la variabile
	dipendente, mentre i regressori restano nei livelli.
      </para>

      <para context="cli">
	L'opzione <opt>save-ehat</opt> è applicabile solo alla stima nativa di MV
	esatta. Il suo effetto è quello di rendere disponibile un vettore
	contenente la stima ottimale alla data <math>t</math> del disturbo
	o innovazione alla stessa data: questo valore può essere recuperato
	grazie all'accessore <fncref targ="$ehat"/>. Questi valori sono diversi
	dalla variabile dei residui (<fncref targ="$uhat"/>) che contiene gli errori 
	di previsione un passo in avanti.
      </para>

      <para>
        Il valore AIC mostrato nei modelli ARIMA è calcolato secondo la
	definizione usata in <program>X-12-ARIMA</program>, ossia
	  <equation status="display" 
	  tex="\[\mbox{AIC}=-2\ell+2k\]"
	  ascii="AIC = -2L + 2k"
	  graphic="aic"/> dove 
	<equation status="inline" 
	  tex="$\ell$" ascii="L"
	  graphic="ell"/>
        è la log-verosimiglianza e <math>k</math> è il numero totale di
        parametri stimati. Si noti che <program>X-12-ARIMA</program> non produce
        criteri di informazione come l'AIC quando la stima è effettuata col
        metodo della massima verosimiglianza condizionale.
      </para> 

      <para context="tex">
	Le radici AR e MA mostrate in occasione della stima ARMA sono
	basate sulla seguente rappresentazione di un processo ARMA($p,q$):
	\[
	(1-\phi_1 L - \phi_2 L^2 - \cdots - \phi_p L^p)Y =
          c + (1 + \theta_1 L + \theta_2 L^2 + \cdots +
         \theta_q L^q)\varepsilon_t
        \]
	Di conseguenza, le radici AR sono le soluzioni di
        \[
         1 - \phi_1 z - \phi_2 z^2 - \cdots - \phi_p L^p = 0
        \]
	e la stazionarietà del processo richiede che queste radici si 
	trovino al di fuori del cerchio di raggio unitario.	
      </para>

      <para context="tex">
	Il valore di <quote>frequency</quote> mostrato assieme alle radici 
	AR e MA è il valore di $\lambda$ che risolve 
	$z=re^{i2\pi\lambda}$, dove $z$ è la radice in questione e $r$ è
	il suo modulo.
      </para>

      <para context="notex">
	Le radici AR e MA mostrate in occasione delkla stima ARMA sono
	basate sulla seguente rappresentazione	di un processo ARMA(p,q):
      </para>
      <mono context="notex">
	(1 - a_1*L - a_2*L^2 - ... - a_p*L^p)Y =
          c + (1 + b_1*L + b_2*L^2 + ... + b_q*L^q) e_t
      </mono>
      <para context="notex">
	Di conseguenza le radici AR sono la soluzione di
      </para>
      <mono context="notex">
         1 - a_1*z - a_2*z^2 - ... - a_p*L^p = 0
      </mono>
      <para context="notex">
	e la stazionarietà del processo richiede che queste radici si 
	trovino al di fuori del cerchio di raggio unitario.	
      </para>

      <para context="notex">
	Il valore di <quote>frequenza</quote> mostrato insieme alle
	radici AR e MA è il valore di &lgr; che risolve <math>z</math>
	= <math>r</math> * exp(i*2*&pi;*&lgr;)dove <math>z</math> è la
	radice in questione e <math>r</math> è il suo modulo.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie Storiche/ARIMA</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
    </gui-access>

  </command>
 
  <command name="bfgs-config" section="Estimation" label="BFGS options"
    context="gui">
    <description>
      <para>
	Questa finestra di dialogo consente di controllare alcuni
	dettagli dell'algoritmo BFGS. Nel caso di mancata convergenza
	può essere utile, in certi casi, aumentare il numero massimo
	di iterazioni e/o il parametro di tolleranza. Tuttavia,
	risultati ottenuti con tolleranze molto alte dovrebbero
	essere considerati un po' sospetti, e va considerata la
	possibilità che il modello sia mal specificato.
      </para>
      <para>
	Nella maggioranza dei casi, consigliamo l'uso dell'algoritmo
	BFGS standard, ma per alcuni problemi, la sua variante
	<quote>a memoria limitata</quote>, L-BFGS-B, può essere più
	efficace. Con questo algoritmo, è possibile fissare il numero
	di correzioni nella matrice di memoria limitata (tra 3 e 20,
	default 8).
      </para>
    </description>
  </command>

  <command name="biprobit" section="Estimation" label="Bivariate probit"
    context="cli">
    <usage>
      <arguments>
        <argument>depvar1</argument>
	<argument>depvar2</argument>
        <argument>indepvars1</argument>
	<argument separated="true" optional="true">indepvars2</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>stampa la matrice di covarianze</effect>
        </option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
        </option>
	<option>
	  <flag>--opg</flag>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--save-xbeta</flag>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>stampa informazione extra</effect>
        </option>
      </options>      
      <examples>
        <example>biprobit y1 y2 0 x1 x2</example>
	<example>biprobit y1 y2 0 x11 x12 ; 0 x21 x22</example>
	<demos>
	  <demo>biprobit.inp</demo>
	</demos>
      </examples>
    </usage>
    <description>
      <para>
	Stima un modello probit bivariato massimizzando la verosimiglianza
	con il metodo di Newton&ndash;Raphson.
      </para>
      <para>
	L'elenco degli argomenti inizia con due variabili dipendenti (binarie), 
	seguite da una lista di regressori. Un'eventuale seconda lista,
	separata dalla precedente da un punto e virgola, viene interpretata come
	contenente l'insieme dei regressori specifici alla seconda equazione,
	mentre <repl>indepvars1</repl> è specifica alla prima equazione;
	in caso contrario il comando assume che <repl>indepvars1</repl> 
	rappresenti un insieme di regressori comuni alle due equazioni.
      </para>
      <para>
	Per default, gli errori standard sono calcolati usando
	un'approssimazione numerica dell'Hessiana calcolata in
	corrispondenza delle stime dei parametri. L'opzione
	<opt>opg</opt> permette di stimare la matrice di covarianza
	usando il prodotto esterno del gradiente (Outer Product of the
	Gradient, OPG); l'opzione <opt>robust</opt> permette di
	calcolare gli standard error QML a partire dalla matrice di
	covarianza <quote>sandwich</quote> che usa sia l'inversa
	dell'Hessiana che la matrice OPG.
      </para>
      <para>
	Una volta completata con successo la stima, l'accessore
	<fncref targ="$uhat"/> consente di recuperare una matrice di due
	colonne contenente i residui generalizzati delle due
	equazioni; in altre parole, i valori attesi degli errori
	condizionali ai valori osservati delle variabili dipendenti e
	delle covariate. Di default <fncref targ="$yhat"/> restituisce una
	matrice di quattro colonne contenente le stime delle
	probabilità dei quattro possibili esiti congiunti per
	(<math>y</math><sub>1</sub>, <math>y</math><sub>2</sub>),
	nell'ordine (1,1), (1,0), (0,1), (0,0). In alternativa, se il
	comando è seguito dall'opzione <opt>save-xbeta</opt> ,
	<fncref targ="$yhat"/> ha due colonne contenenti i valori delle
	funzioni indice delle rispettive equazioni.
      </para>
      <para>
	L'output comprende un test del rapporto di verosimiglianza
	dell'ipotesi nulla che gli errori delle due equazioni siano
	incorrelati fra loro.
      </para>
    </description>
  </command>

  <command name="bootstrap" section="Tests" label="Opzioni bootstrap"
    context="gui">

    <description>

      <para>In questa finestra di dialogo è possibile scegliere:</para>

      <ilist>
	<li>
	  <para>
	    La variabile o il coefficiente da esaminare (è possibile testare
            solo un coefficiente alla volta usando questo metodo).
	  </para>
	</li>
	<li>
	  <para>
            Il tipo di analisi da eseguire. L'intervallo di confidenza
            predefinito (95 per cento) è basato direttamente sui quantili delle
            stime bootstrap del coefficiente. La versione
	    <quote>studentizzata</quote> corrisponde a quella presentata nel
            capitolo 5 di <book>Economic Theory and Methods</book> (ETM) di
            Davidson e MacKinnon: ad ogni replicazione bootstrap, viene
            calcolato un rapporto
	    <math>t</math> come (a) la differenza tra la stima attuale
            del coefficiente e quella di riferimento, divisa per (b) l'errore
            standard di riferimento. Quindi l'intervallo di confidenza viene
            calcolato usando i quantili di questo rapporto t, come spiegato in
            ETM. L'opzione p-value si basa sulla distribuzione del rapporto
	    <math>t</math> bootstrap: è la proporzione delle replicazioni
            in cui il valore assoluto di questa statistica eccede il valore
            assoluto del rapporto <math>t</math> di riferimento.
	  </para>
	</li>
	<li>
	  <para>Il metodo di bootstrap. Con la prima opzione i residui
	  originali (riscalati, come suggerito in ETM) vengono
	  ricampionati con rimpiazzo. Nel secondo caso, viene
	  effettuato in ricampionamente per <quote>coppie</quote> o
	  <quote>casi</quote>, ossia le righe di dati <math>y</math>,
	  <math>X</math>. Con la terza opzione, i residui originali
	  vengono prima trasformati secondo il metodo di <cite
	  key="davidson-flachaire01">Davidson e Flachaire
	  (2001)</cite>, dopodiché in ogni replicazione bootstrap
	  ognuno di essi viene cambiato di segno con probabilità
	  0.5. Con l'ultima opzione, vengono generati valori normali
	  pseudo-casuali con la varianza dei residui originali.
	  </para>
	</li>
	<li>
	  <para>Il numero di replicazioni da eseguire. Si noti che
	  quando si costruisce un intervallo di confidenza al 95 per
	  cento è opportuno che 0.05(<math>B</math> + 1)/2 sia un
	  intero (dove <math>B</math> è il numero di replicazioni),
	  quindi gretl può aggiustare il numero scelto di replicazioni
	  per assicurare questa condizione.
	  </para>
	</li>
	<li>
	  <para>Se produrre o no un grafico della distribuzione bootstrap.
            Questa opzione usa la procedura di stima kernel di gretl.
	  </para>
	</li>
      </ilist>

    </description>
  </command>


  <command name="boxplot" section="Graphs" label="Grafici boxplot">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--notches</flag>
	  <effect>mostra l'intervallo di confidenza al 90 per cento per la mediana</effect>
	</option>
	<option>
	  <flag>--factorized</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--panel</flag>
	  <effect>vedi sotto</effect>
	</option>
        <option>
	  <flag>--matrix</flag>
	  <optparm>name</optparm>
	  <effect>opera su colonne di una matrice</effect>
        </option>
	<option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>manda l'output a un file specificato</effect>
	</option>
      </options>
    </usage>

    <description>

      <para>
	Questo tipo di grafici (da Tukey e Chambers) mostra la
	distribuzione di una variabile. La <quote>scatola</quote>
	centrale (box) racchiude il 50 per cento centrale dei dati,
	ossia è delimitato dal primo e terzo quartile. I
	<quote>baffi</quote> (whiskers) si estendono fino un valore
	dato da una volta e mezzo il range interquartile a partire dai
	bordi della scatola. Valori esterni a tale intervallo sono
	considerati <quote>outlier</quote> e rappresentati con dei
	punti. Una linea trasversale sulla scatola indica la mediana,
	mentre un segno <quote>+</quote> indica la media. Se viene
	selezionata l'opzione di mostrare un intervallo di confidenza
	per la mediana, quetso viene calcolato via bootstrap e
	mostrato sotto forma di lnee tratteggiate orizzontali sopra e
	sotto la mediana.
      </para> 

      <para context="gui">
	L'opzione <quote>factorized</quote> permette di esaminare la
	distribuzione di una variabile condizionata ai valori di un
	fattore discreto. Ad esempio, se un dataset contiene salari e
	una variable binaria per il genere, si può scegliere di
	analizzare la distribuzione del salario condizionata al genere
	e visualizzare boxplot dei salri per i maschi e per le femmine
	uno di fianco all'altro.
      </para>
      
      <para context="cli">
	L'opzione <quote>factorized</quote> permette di esaminare la
	distribuzione di una variabile condizionata ai valori di un
	fattore discreto. Ad esempio, se un dataset contiene salari e
	una variable binaria per il genere, si può scegliere di
	analizzare la distribuzione del salario condizionata al genere
	e visualizzare boxplot dei salri per i maschi e per le femmine
	uno di fianco all'altro, come ad esempio
      </para>
      <code context="cli">
	boxplot wage gender --factorized
      </code>
      <para context="cli">
	Si noti che, in questo caso, bisogna specificare esattamente
	due variabili, col fattore per secondo.
      </para>

      <para context="cli">
	Se il dataset corrente è un panel ed è stata specificata una sola 
	variabile, l'opzione <opt>panel</opt> produce una serie di grafici
	boxplot affiancati, uno per ogni <quote>unità</quote> o gruppo panel.
      </para>

      <para context="cli">
	In generale l'argomento <repl>varlist</repl> è necessario e deve
	indicare una o più variabili nel dataset corrente (usando il nome
	o il numero di ID). Se viene fornita una matrice usando l'opzione 
	<opt>matrix</opt>, tuttavia, questo argomento diventa opzionale: di
	default viene mostrato un grafico per ciascuna delle colonne della
	matrice specificata.
      </para>

      <para context="cli">
	Il grafici boxplot di gretl sono generati usando <program>gnuplot</program>,
	ed è possibile arricchire il grafico specificando altri comandi
	gnuplot, includendoli fra parentesi graffa. Per maggiori dettagli
	consultate per favore l'help del comando <cmdref targ="gnuplot"/>.
      </para>

      <para context="cli">
	In modalità interattiva il risultato viene mostrato immediatamente.
	In batch il comportamento di default di gretl è di scrivere nella
	directory di lavoro dell'utente un file di comandi gnuplot chiamato
	<filename>gpttmpN.plt</filename>, iniziando da N = <lit>01</lit>. 
	I grafici veri e propri possono essere generati in seguito usando 
	<program>gnuplot</program> (in MS Windows,
	<program>wgnuplot</program>). Questo comportamento può essere modificato 
	usando l'opzione <opt>output=</opt><repl>filename</repl>. 
	Per ulteriori dettagli, si veda il comando <cmdref
	targ="gnuplot"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Visualizza/Grafico/Boxplot</menu-path>
    </gui-access>

  </command>

  <command name="break" section="Programming" label="Esce da un ciclo" context="cli">

    <description>
      <para>Esce da un ciclo. Questo comando può essere usato solo
      all'interno di un ciclo e causa l'immediata interruzione
      dell'esecuzione del ciclo (o di quello più interno, nel caso di
      cicli nidificati). Si veda anche il comando <cmdref
      targ="loop"/>.
      </para> 

    </description>

  </command>

  <command name="bwfilter" section="Transformations" context="gui"
    label="Il filtro di Butterworth">

    <description>
      <para>
	Il filtro di Butterworth è un'approssimazione di un filtro
	ideale a onda quadra che lascia completamente passare tutte le
	frequenze all'interno di un certo intervallo e blocca tutte le
	altre.
      </para>
      <para>
	Valori più elevati del parametro di ordine, <math>n</math>,
	producono una migliore approssimazione del filtro ideale ma al
	costo potenziale di introdurre un certo grado di instabilità
	numerica. Il valore di <quote>cutoff</quote> individua la
	soglia fra intervallo di frequenze lasciate passare e quello
	delle frequenze bloccate. Questo parametro è espresso in gradi
	e deve essere maggiore di 0 e minore di 180&deg; (o &pi;
	radianti, corrispondente alla frequenza massima nei dati).
	Valori inferiori di questa soglia producono un trend più
	regolare.
      </para>
      <para>
	Se si desidera applicare questo filtro è opportuno esaminare 
	prima il periodogramma della serie storica considerata. V. 
	<guideref targ="chap:genr"/> per maggiori dettagli.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Filter/Butterworth</menu-path>
    </gui-access>

  </command>

  <command name="catch" section="Programming" 
    label="Catch errors" context="cli">
    <usage>
      <syntax>
        <lit>catch</lit> <repl>command</repl>
      </syntax>
    </usage>
    <description>
      <para>
	Non si tratta di un vero e proprio comando, quanto piuttosto
	di un prefisso applicabile alla maggior parte dei comandi
	consueti; il suo effetto è quello di prevenire l'interruzione
	di uno script nel caso in cui si verifichi un errore
	nell'esecuzione di un comando. Un eventuale errore viene
	registrato in un codice d'errore interno cui è possibile
	accedere con <fncref targ="$error"/> (un valore nullo indica che
	l'esecuzione ha avuto successo). Il valore di
	<fncref targ="$error"/> dovrebbe sempre essere controllato subito
	dopo aver usato <lit>catch</lit>, in modo da adottare le
	misure più opportune nel caso in cui il comando non dovesse
	aver avuto successo.
      </para> 
      <para>
	<lit>catch</lit> non può essere usato prima di <lit>if</lit>,
	<lit>elif</lit> o <lit>endif</lit>. Inoltre, non può essere
	neanche usato per chiamate a funzioni definite dall'utente; il
	suo uso è limitato ai comandi di gretl e alle chiamate a
	funzioni od operatori <quote>nativi</quote>.
      </para>
    </description>
  </command>

  <command name="chow" section="Tests" label="Test di Chow">

    <usage>
      <arguments>
        <argument>osservazione</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le stime del modello aumentato</effect>
	</option>
      </options>
      <examples>
        <example>chow 25</example>
        <example>chow 1988:1</example>
      </examples>
    </usage>

    <description>
      <para context="gui">Questo comando richiede un numero di osservazione
       (o una data, se il dataset lo consente).</para>

      <para>
	Va eseguito dopo una regressione OLS e fornisce un test per 
        l'ipotesi nulla che non esista un break strutturale del modello
        in corrispondenza del punto di rottura specificato. La procedura
        consiste nel creare una variabile dummy che vale 1 a partire dal punto
        di rottura specificato da <repl>osservazione</repl> fino alla fine del
        campione, 0 altrove; inoltre vengono creati dei termini di interazione
        tra questa dummy e i regressori originali.  Viene quindi stimata una
        regressione che include questi termini.
      </para>
      <para>
        Per impostazione predefinita viene calcolata una statistica
        <math>F</math>, prendendo la regressione aumentata come non
        vincolata e la regressione originale come vincolata. Se il
        modello originale usa uno stimatore robusto per la matrice di
        covarianza, come statistica test viene usato un valore
        chi-quadro di Wald, basato su uno stimatore robusto della
        matrice di covarianza della regressione aumentata.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/CHOW</menu-path>
    </gui-access>

  </command>

  <command name="clear" section="Programming" context="cli">
    <usage>
      <options>
	<option>
	  <flag>--dataset</flag>
	  <effect>cancella solo il dataset</effect>
	</option>
	<option>
	  <flag>--other</flag>
	  <effect>cancella tutto fuorché il dataset</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Senza alcuna opzione, cancella dalla memoria tutti gli oggetti
	salvati, compreso l'eventuale campione corrente. Si noti che
	anche aprire un nuovo dataset o usare il comando
	<cmd>nulldata</cmd> per creare un dataset vuoto ha lo stesso
	effetto; per questo motivo di solito non è necessario usare
	<cmd>clear</cmd>.
      </para>
      <para>
	Con l'opzione <opt>dataset</opt> viene cancellato dalla
	memoria solo il dataset; tutti gli altri oggetti, come matrici
	e scalari salvati in precedenza, vengono conservati.
      </para>
    </description>
  </command>

  <command name="cluster" section="Estimation" 
	   label="Robust variance estimation" context="gui">
    <description>
      <para>
	Scegliendo la seconda opzione è necessario fornire il nome di
	una variabile rispetto alla quale si effettua il clustering.
	Questa variabile dovrebbe assumere almeno due valori diversi,
	ma in generale il numero dei suoi valori distinti dovrebbe
	essere significativamente inferiore al numero di osservazioni
	nell'intervallo campionario considerato.
      </para>
      <para>
	Lo stimatore della varianza <quote>cluster-robust</quote>
	divide il campione in più sottoinsiemi o cluster sulla base dei
	valori assunti dalla variabile selezionata. Questo stimatore
	permette di evitare l'ipotesi classica che il termine d'errore
	sia indipendente e identicamente distribuito, perché ammette
	la possibilità che la sua varianza vari da un cluster
	all'altro e che ogni errore possa presentare un certo grado di
	dipendenza dagli altri errori all'interno dello stesso
	cluster.
      </para>
    </description>
  </command>

  <command name="coeffsum" section="Tests" label="Somma dei coefficienti">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <examples>
        <example>coeffsum xt xt_1 xr_2</example>
	<demos>
	  <demo>restrict.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="gui">Questo comando richiede una lista di variabili,
        selezionate tra le variabili indipendenti di un modello.
      </para>
      <para context="gui">
	Calcola la somma dei coefficienti delle variabili nella lista
        e mostra l'errore standard e il p-value per l'ipotesi nulla che la
        somma sia zero.
      </para>
      <para context="cli">
	Deve essere usato dopo una regressione. Calcola la somma dei 
        coefficienti delle variabili nella <repl>lista-variabili</repl>
        e ne mostra l'errore standard e il p-value per l'ipotesi nulla
        che la loro somma sia zero.
      </para>
      <para>Si noti la differenza tra questo test e <cmdref
	  targ="omit"/>, che assume come ipotesi nulla l'uguaglianza a zero
          di <emphasis>tutti</emphasis> i coefficienti di un gruppo di variabili
          indipendenti.</para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/Somma dei coefficienti</menu-path>
    </gui-access>

  </command>

  <command name="coint" section="Tests" 
    label="Test di cointegrazione di Engle-Granger">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>non include la costante</effect>
	</option>
 	<option>
	  <flag>--ct</flag>
	  <effect>include la costante e il trend</effect>
	</option>
	<option>
	  <flag>--ctt</flag>
	  <effect>include la costante e il trend quadratico</effect>
	</option>
	<option>
	  <flag>--skip-df</flag>
	  <effect>non esegue i test DF sulle variabili individuali</effect>
	</option>
	<option>
	  <flag>--test-down</flag>
	  <effect>scelta automatica dell'ordine dei ritardi</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra dettagli extra sulle regressioni</effect>
	</option>
      </options>
      <examples>
        <example>coint 4 y x1 x2</example>
        <example>coint 0 y x1 x2 --ct --skip-df</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
        Test di cointegrazione di Engle&ndash;Granger. La procedura
        predefinita è la seguente: (1) eseguire dei test
        Dickey&ndash;Fuller aumentati, sull'ipotesi nulla che ognuna
        delle variabili elencate abbia una radice unitaria; (2)
        stimare la regressione di cointegrazione; (3) eseguire un test
        DF sui residui della regressione di cointegrazione. Se si usa
        l'opzione <lit>--skip-df</lit>, il passo (1) viene saltato.
      </para>
      <para context="cli">
        Se l'ordine di ritardo specificato è positivo, tutti i test
        Dickey&ndash;Fuller utilizzano questo ordine. Se l'ordine
        indicato viene preceduto da un segno meno, viene interpretato
        come l'ordine massimo, e l'ordine utilizzato effettivamente
        viene ricavato con la stessa procedura di test "all'indietro"
        descritta per il comando <cmdref targ="adf"/>.
      </para>
       <para context="cli">
	L'impostazione predefinita consiste nell'includere una
	costante nella regressione di cointegrazione; se si vuole
	omettere la costante, basta usare l'opzione
	<opt>nc</opt>. Se si vuole aggiungere all'elenco dei termini
	deterministici della regressione un trend lineare o
	quadratico, basta usare le opzioni <opt>ct</opt> o
	<opt>ctt</opt>. Queste opzioni sono mutualmente esclusive.
      </para>
      <para context="cli">
        Test di cointegrazione di Engle&ndash;Granger. La procedura
        predefinita è la seguente: (1) eseguire dei test
        Dickey&ndash;Fuller aumentati, sull'ipotesi nulla che ognuna
        delle variabili elencate abbia una radice unitaria; (2)
        stimare la regressione di cointegrazione; (3) eseguire un test
        DF sui residui della regressione di cointegrazione. Se si
        attiva la casella <lit>Salta i test DF iniziali</lit>, il
        passo (1) viene saltato.
      </para>
      <para context="gui">
	Se l'ordine di ritardo, <math>k</math>, è maggior di 0,
	verranno inclusi <math>k</math> ritardi della variabile
	dipendente al secondo membro di ognuna delle regressioni di
	test, a meno che non si usi la casella <quote>test dal massimo
	ordine di ritardi all'indietro</quote>: in questo caso,
	l'ordine specificato viene considerato come massimo e l'ordine
	usato effettivamente viene determinato con la procedura di
	test "all'indietro" descritta per il comando <cmdref
	targ="adf"/>.
      </para>
      <para context="gui">
	L'impostazione predefinita consiste nell'includere una
	costante nella regressione di cointegrazione. Se si vuole
	omettere la costante, o aggiungere un trend lineare o
	quadratico, basta selezionare le relative opzioni nella
	finestra di dialogo.
      </para>
      <para>
        I <emphasis>pvalue</emphasis> per questo test si basano su
	MacKinnon (1996). Il codice relativo è stato incluso per gentile
        concessione dell'autore.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/Test di cointegrazione/Engle-Granger</menu-path>
    </gui-access>

  </command>

  <command name="coint2" section="Tests" label="Test di cointegrazione di Johansen">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>lista-y</argument>
	<argblock optional="true" separated="true">
	  <argument>lista-x</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>lista-rx</argument>
	</argblock>
      </arguments>
      <options>
        <option>
	  <flag>--nc</flag>
	  <effect>senza costante</effect>
        </option>
        <option>
	  <flag>--rc</flag>
	  <effect>costante vincolata</effect>
        </option>
        <option>
	  <flag>--uc</flag>
	  <effect>costante non vincolata</effect>
        </option>
        <option>
	  <flag>--crt</flag>
	  <effect>costante e trend vincolato</effect>
        </option>
        <option>
	  <flag>--ct</flag>
	  <effect>costante e trend non vincolato</effect>
        </option>
        <option>
	  <flag>--seasonals</flag>
	  <effect>include dummy stagionali centrate</effect>
        </option>
        <option>
	  <flag>--asy</flag>
	  <effect>registra i p-value asintotici</effect>
        </option>
        <option>
	  <flag>--silent</flag>
	  <effect>non mostra nulla</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>mostra solo i test</effect>
        </option>
        <option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle regressioni ausiliarie</effect>
        </option>
      </options>
      <examples>
        <example>coint2 2 y x</example>
	<example>coint2 4 y x1 x2 --verbose</example>
	<example>coint2 3 y x1 x2 --rc</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
        Esegue il test di Johansen per la cointegrazione tra le
        variabili della <repl>lista-y</repl> per l'ordine specificato
        di ritardi. Per dettagli, si veda <guideref targ="chap:vecm"/>
        oppure <cite key="hamilton94">Hamilton (1994)</cite>, capitolo
        20. I valori critici sono calcolati con l'approssimazione
        gamma di J. Doornik (Doornik, 1998). Per il test traccia,
        vengono formiti due set di valori critici: asintotici e
        aggiustati per l'ampiezza campionaria. Di default, l'accessore
        <fncref targ="$pvalue"/> riporta la variante aggiustata, ma i valori
        asintotici possono essere ottenuti usando l'opzione
        <opt>asy</opt>
      </para>
      <para context="gui">
        Esegue il test di Johansen per la cointegrazione tra le variabili
        elencate per l'ordine specificato di ritardi. I valori critici
        sono calcolati con l'approssimazione gamma di J. Doornik (Doornik,
        1998). Per i dettagli su questo test, si veda Hamilton, <book>Time
        Series Analysis</book> (1994), Cap. 20. Per il test traccia,
        vengono formiti due set di valori critici: asintotici e
        aggiustati per l'ampiezza campionaria.
      </para>
      <para context="cli">
	L'inclusione di trend deterministici nel modello è controllata dalle
        opzioni del comando. Se non si indica alcuna opzione, viene inclusa una
	<quote>costante non vincolata</quote>, che permette la presenza di
        un'intercetta diversa da zero nelle relazioni di cointegrazione e di un
        trend nei livelli delle variabili endogene. Nella letteratura originata
        dal lavoro di Johansen (si veda ad esempio il suo libro del 1995),
        si fa riferimento a questo come al <quote>caso 3</quote>.  Le prime
        quattro opzioni mostrate sopra, che sono mutualmente esclusive,
        producono rispettivamente i casi 1, 2, 4 e 5. Il significato di questi
        casi e i criteri per scegliere tra di essi sono spiegati nella
	<guideref targ="chap:vecm"/>.
      </para>
      <para context="gui">
	L'inclusione di termini deterministici nel modello è controllata dai
        pulsanti delle opzioni. L'opzione predefinita è di includere una
	<quote>costante non vincolata</quote>, che permette la presenza di
        un'intercetta diversa da zero nelle relazioni di cointegrazione e di un
        trend nei livelli delle variabili endogene. Nella letteratura originata
        dal lavoro di Johansen (si veda ad esempio il suo libro del 1995),
        si fa riferimento a questo come al <quote>caso 3</quote>.  Le prime
        quattro opzioni mostrate sopra, che sono mutualmente esclusive,
        producono rispettivamente i casi 1, 2, 4 e 5. Il significato di questi
        casi e i criteri per scegliere tra di essi sono spiegati nella
	<guideref targ="chap:vecm"/>.
      </para>
      <para context="cli">
	Le liste opzionali <repl>lista-x</repl> e
	<repl>lista-rx</repl> permettono di controllare per specifiche
	variabili esogene che entrano nel sistema in modo non
	vincolato (<repl>lista-x</repl>) o vincolate allo spazio di
	cointegrazione (<repl>lista-rx</repl>). Queste liste vanno
	separate tra di loro e dalla <repl>lista-y</repl> usando il
	carattere punto e virgola.
      </para>
      <para context="gui">
	È possibile controllare per le variabili esogene aggiungendole
	nel campo inferiore. Per impostazione predefinita, le
	variabili vengono aggiunte al modello in forma non vincolata
	(indicata da una lettera <lit>N</lit> vicino al nome della
	variabile). Se si vuole che una certa variabile esogena sia
	vincolata allo spazio di cointegrazione, basta fare clic col
	tasto destro e selezionare <quote>Vincolata</quote> dal menu
	pop-up. Il simbolo vicino alla variabile diventerà una V.
      </para>
      <para context="cli">
        L'opzione <opt>seasonals</opt>, che può accompagnare una qualsiasi
        delle altre opzioni, specifica l'inclusione di un gruppo di variabili
        dummy stagionali centrate. Questa opzione è disponibile solo per dati
        trimestrali o mensili.
      </para>
      <para context="gui">
	Se i dati sono trimestrali o mensili, è presente anche una casella che
        permette di includere un gruppo di variabili dummy stagionali centrate.
	In tutti i casi, la casella <quote>Mostra dettagli</quote> permette di
        vedere il risultato delle regressioni ausiliarie che sono il punto di
        partenza per la procedura di stima di massima verosimiglianza di
        Johansen.
      </para>
      <para context="notex">
	La tabella seguente fornisce un esempio di interpretazione dei
	risultati del test nel caso di 3 variabili. <lit>H0</lit> denota
        l'ipotesi nulla, <lit>H1</lit> l'ipotesi alternativa e <lit>c</lit>
        il numero delle relazioni di cointegrazione.
      </para>
      <code context="notex">
                 Rango    Test traccia       Test Lmax
                          H0     H1          H0     H1
                 ---------------------------------------
                  0      c = 0  c = 3       c = 0  c = 1
                  1      c = 1  c = 3       c = 1  c = 2
                  2      c = 2  c = 3       c = 2  c = 3
                 ---------------------------------------
      </code>

      <para context="tex">
	La tabella seguente fornisce un esempio di interpretazione dei
	risultati del test nel caso di 3 variabili. $H_0$ denota
        l'ipotesi nulla, $H_1$ l'ipotesi alternativa e $c$
        il numero delle relazioni di cointegrazione.

	\begin{center}
	\begin{tabular}{cllll}
	&amp; \multicolumn{2}{c}{Test traccia} &amp;
	   \multicolumn{2}{c}{Test $\lambda$-max} \\
	Rango &amp;  \multicolumn{1}{c}{$H_0$} &amp; 
	       \multicolumn{1}{c}{$H_1$} &amp; 
	       \multicolumn{1}{c}{$H_0$} &amp; 
	       \multicolumn{1}{c}{$H_1$} \\ [4pt]
 	0 &amp; $c$ = 0 &amp; $c$ = 3 &amp; $c$ = 0 &amp; $c$ = 1 \\
	1 &amp; $c$ = 1 &amp; $c$ = 3 &amp; $c$ = 1 &amp; $c$ = 2 \\
	2 &amp; $c$ = 2 &amp; $c$ = 3 &amp; $c$ = 2 &amp; $c$ = 3 
	\end{tabular}
	\end{center}
      </para>      
 
      <para>
	Si veda anche il comando <cmdref targ="vecm"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/Test di cointegrazione/Johansen</menu-path>
    </gui-access>

  </command>

  <command name="compact" section="Dataset" context="gui"
    label="Compattamento dei dati">

    <description>

      <para>Quando viene aggiunta a un dataset una serie di frequenza
        maggiore, occorre <quote>compattare</quote> la nuova serie.
	Ad esempio, una serie mensile deve essere compattata per
        adattarsi a un dataset trimestrale.</para>  

      <para>Inoltre, a volte può essere necessario compattare un intero
	dataset abbassandone la frequenza (ad esempio, prima di aggiungere
	al dataset una variabile a frequenza minore).</para>

      <para>Ci sono quattro opzioni per il compattamento:</para>

      <ilist>
	<li><para>Media: i nuovi valori saranno la media aritmetica
	    dei corrispondenti valori della serie a frequenza maggiore.
            Ad esempio, il valore per il primo trimestre del 1990 sarà la
            media dei valori di gennaio, febbraio e marzo del 1990.</para>
	</li>

	<li><para>Somma: i nuovi valori saranno la somma dei 
            corrispondenti valori della serie a frequenza maggiore.
            Ad esempio, il valore per il primo trimestre sarà la somma dei
            valori di gennaio, febbraio e marzo.</para>
	</li>

	<li><para>Valori di fine periodo: il nuovo valore è l'ultimo
            valore corrispondente nella serie a frequenza maggiore.
	    Ad esempio, il valore del primo trimestre del 1990 sarà quello
            del marzo 1990.</para>
	</li>

	<li><para>Valori di inizio periodo: il nuovo valore è il primo
            valore corrispondente nella serie a frequenza maggiore.
            Ad esempio, il valore del primo trimestre del 1990 sarà quello
            del gennaio 1990.</para>
	</li>
      </ilist>

      <para>Se si compatta un intero dataset, il metodo di
      compattamento scelto diventa quello predefinito, ma se si è
      scelto un metodo di compattamento per una certa variabile (nel
      menù <quote>Variabile/Modifica attributi</quote>) viene usato
      quel metodo al posto di quello predefinito.  Se il metodo di
      compattamento è già stato scelto per tutte le variabili, non
      viene presentata la scelta per il metodo di compattamento
      predefinito.
	</para>

    </description>
  </command>

  <command name="controlled" section="Graphs" context="gui"
    label="Grafici a dispersione con controllo">

    <description>
      <para>
        Questo comando richiede la scelta di tre variabili, una per l'asse X,
        una per l'asse Y e una variabile di controllo (chiamata Z). Il grafico
        mostra le variabili X e Y controllate per la variabile Z, ossia i
        residui della regressione OLS di ogni variabile su Z.
      </para>
      <para>
	Esempio: si hanno dati sui salari, l'esperienza e il livello
        educativo in un campione di persone e si vuole un grafico dei salari
        rispetto all'educazione, controllando per l'esperienza. In questo caso,
        basta selezionare i salari per l'asse Y, l'educazione per l'asse X e
        l'esperienza come variabile di controllo: il grafico mostrerà la
        relazione tra le due variabili <quote>depurate</quote> dall'effetto
        dell'esperienza.
      </para>
    </description>

  </command>

  <command name="corr" section="Statistics" label="Coefficienti di correlazione">

    <usage>
      <arguments>
        <argument optional="true">lista-variabili</argument>
      </arguments>
      <options>
 	<option>
	 <flag>--uniform</flag>
         <effect>assicura l'uniformità del campione</effect>
	</option>
	<option>
	  <flag>--spearman</flag>
	  <effect>Rho di Spearman</effect>
	</option>
	<option>
	  <flag>--kendall</flag>
	  <effect>Tau di Kendall</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i ranghi</effect>
	</option>
      </options>
      <examples>
        <example>corr y x1 x2 x3</example>
	<example>corr ylist --uniform</example>
	<example>corr x y --spearman</example>
      </examples>
    </usage>

    <description context="gui">
      <para>
        Mostra le coppie di coefficienti di correlazione (la correlazione del
        prodotto dei momenti di Pearson) per le variabili selezionate. Il
        comportamento predefinito consiste nell'usare tutte le osservazioni
        disponibili per calcolare ognuno dei coefficienti, ma attivando
        l'opportuna casella il campione verrà limitato (se necessario) in modo
        che per tutti i coefficienti venga usato lo stesso insieme di
        osservazioni. Questa opzione ha effetto solo se le diverse variabili
        contengono un numero diverso di valori mancanti.
      </para>
    </description>

    <description context="cli">
      <para>
        Per impostazione predefinita, mostra le coppie di coefficienti di
        correlazione (la correlazione del prodotto dei momenti di Pearson)
        per le variabili date nella <repl>lista-variabili</repl>, o
        per tutte le variabili del dataset se non viene specificata alcuna
        <repl>lista-variabili</repl>. Il comportamento predefinito consiste
        nell'usare tutte le osservazioni disponibili per calcolare ognuno dei
        coefficienti, ma se si usa l'opzione <flag>--uniform</flag> il campione
        verrà limitato (se necessario) in modo che per tutti i coefficienti
        venga usato lo stesso insieme di osservazioni. Questa opzione ha effetto
        solo se le diverse variabili contengono un numero diverso di valori
        mancanti.
      </para>
      <para>
	Le opzioni (mutualmente esclusive) <opt>spearman</opt> e
	<opt>kendall</opt> producono rispettivamente, la correlazione di rango
        di Spearman (rho) e la correlazione di rango di Kendall (tau), invece
        del solito coefficiente di Pearson. Quando si usa una di queste opzioni,
        la <repl>lista-variabili</repl> deve contenere solo due variabili.
       </para>
      <para>
        Quando viene calcolata la correlazione di rango, si può usare l'opzione
        <opt>verbose</opt> per mostrare i dati originali e ordinati
        (altrimenti questa opzione verrà ignorata).
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Matrice di correlazione</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione multipla)</other-access>
    </gui-access>

  </command>

  <command name="corrgm" section="Statistics" label="Correlogramma">

    <usage>
      <arguments>
        <argument>variabile</argument>
        <argument optional="true">max-ritardo</argument>
      </arguments>
      <options>
       <option>
	  <flag>--plot</flag>
	  <optparm>mode-or-filename</optparm>
	  <effect>si veda sotto</effect>
        </option>	  
      </options>
      <examples>
        <example>corrgm x 12</example>
      </examples>
    </usage>

    <description>
      <para context="notex">
	Mostra i valori della funzione di autocorrelazione per la
	<repl>variabile</repl> specificata (dal nome o dal numero).  I
	valori sono definiti come &rgr;(<math>u</math><sub>t</sub>,
	<math>u</math><sub>t-s</sub>) dove <math>u</math><sub>t</sub>
	è la <math>t</math>-esima osservazione della variabile
	<math>u</math> e <math>s</math> è il numero dei
	ritardi.
      </para>
      <para context="tex">
	Mostra i valori della funzione di autocorrelazione per la
	<repl>variabile</repl> specificata (dal nome o dal numero).  I
	valori sono definiti come $\hat{\rho}(u_t, u_{t-s})$, where
	$u_t$ è la $t$-esima osservazione della variabile e $s$ è il
	numero dei ritardi.
      </para>

      <para>
	Vengono mostrate anche le autocorrelazioni parziali (calcolate con
        l'algoritmo di Durbin&ndash;Levinson), ossia al
	netto dell'effetto dei ritardi intermedi. Il comando produce anche
        un grafico del correlogramma e mostra la statistica
        <math>Q</math> di Ljung&ndash;Box per testare l'ipotesi nulla
        che la serie sia <quote>white noise</quote> (priva di
        autocorrelazione). La statistica si distribuisce asintoticamente come
        chi-quadro con gradi di libertà pari al numero di ritardi specificati.
      </para>

      <para>
	Se viene specificato un valore <repl>max-ritardo</repl>, la
	lunghezza del correlogramma viene limitata al numero di
	ritardi specificato, altrimenti viene scelta automaticamente
	in funzione della frequenza dei dati e del numero di
	osservazioni.
      </para>

      <para>
	Di default viene mostrato un grafico del correlogramma: un grafico
	gnuplot in modalità interattiva o un grafico ASCII in modalità batch.
	Questo comportamento può essere modificato con l'opzione <opt>plot</opt>.
	Per questa opzione i parametri accettabili sono <lit>none</lit> (per
	eliminare il grafico); <lit>ascii</lit> (per produrre un grafico
	in formato testo anche in modalità interattiva); <lit>display</lit> (per
	produrre un grafico gnuplot anche in modalità batch); oppure il  
	nome di un file. In quest'ultimo caso l'effetto è quello descritto
	per l'opzione <opt>output</opt> del comando <cmdref targ="gnuplot"/>.
      </para>

      <para>
	Se il comando va a buon fine, gli accessori <fncref targ="$test"/> e
	<fncref targ="$pvalue"/> conterranno i valori corrispondenti per la
	statistica di Ljung&ndash;Box, per l'ordine
	<repl>max-ritardo</repl>. Peraltro, se si vuole semplicemente
	calcolare la statistica <math>Q</math> senza che il programma
	produca alcun output, consigliamo di usare la funzione <fncref
	targ="ljungbox"/> anziché questo comando.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Correlogramma</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
    </gui-access>

  </command>

  <command name="count-model" section="Estimation" context="gui"
    label="Models for count data">

    <description>
      <para>
	Il comando assume che la variabile dipendente rappresenti un
	conteggio del numero di volte in cui si è verificato un certo
	evento e deve assumere solo valori interi non negativi. Di
	default viene utilizzata la distribuzione di Poisson, ma il
	menu a tendina da' la possibilità di usare la distribuzione
	Binomale Negativa. (In econometria viene di solito usata la
	variante NegBin 2, ma è comunque disponibile anche la meno
	frequente NegBin 1).
      </para>
      <para>
	Fra le opzioni è possibile aggiungere alla specificazione una
	variabile di <quote>offset</quote>, un fattore di scala il cui
	logaritmo viene aggiunto alla funzione di regressione lineare
	(implicitamente con un coefficiente unitario). Questa
	operazione è ragionevole se si ritiene che il numero di
	realizzazioni dell'evento sia, a parità di tutte le altre
	variabili, proporzionale a un fattore noto. Per esempio,
	potremmo ritenere che, a parità di condizioni, il numero di
	incidenti stradali sia proporzionale al volume del traffico;
	in questo caso quest'ultimo potrebbe essere indicato come
	variabile di <quote>offset</quote> in un modello che studia il
	numero di incidenti. La variabile di offset deve essere
	strettamente positiva.
      </para>
      <para>
	Di default, gli standard error vengono calcolati usando
	un'approssimazione numerica della matrice Hessiana in
	corrispondenza delle stime dei parametri.  Se viene
	selezionata l'opzione <quote>Robust standard errors</quote> il
	comando calcola gli standard error QML a partire dalla matrice
	di covarianza <quote>sandwich</quote> che usa sia l'inversa
	dell'Hessiana che la matrice OPG.
      </para>
    </description>
  </command>

  <command name="curve" section="Graphs" label="Plot a curve"
    context="gui">

    <description>
      <para>
	Questa finestra di dialogo permette di creare un grafico
	gnuplot specificando una formula, a condizione che
	quest'ultima sia un'espressione che gnuplot è in grado di
	accettare. Per indicare la variabile sull'asse orizzontale
	usate <lit>x</lit>. Si noti che gnuplot usa <lit>**</lit> per
	indicare l'elevamento a potenza e che il separatore dei
	decimali deve essere <quote>.</quote>.  Esempi:
      </para>
      <code>
	10+0.35*x
	100+5.3*x-0.12*x**2
	sin(x)
	exp(sqrt(pi*x))
      </code>
      <para>
	Per inserire una nuova linea in un grafico usando questo comando, 
	cliccate sul grafico, selezionate <quote>Edit</quote> e 
	<quote>Lines</quote> nel menu dei comandi di modifica del grafico, 
	e usate il pulsante <quote>Add line</quote>.
      </para>
    </description>
  </command>

  <command name="cusum" section="Tests" label="Test CUSUM">

    <usage>
      <options>
	<option>
	  <flag>--squares</flag>
	  <effect>esegue il test CUSUMSQ</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>stampa solamente il test di Harvey&ndash;Collier</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello OLS. Esegue il test
	CUSUM (o, se si usa l'opzione <opt>squares</opt>, il test
        CUSUMSQ ) per la stabilità dei parametri. Viene calcolata una 
        serie di errori di previsione per il periodo successivo,
        attraverso una serie di regressioni: la prima usa le prime
	<math>k</math> osservazioni e viene usata per generare
        la previsione della variabile dipendente per l'osservazione 
	<math>k</math> + 1; la seconda usa le prime
        <math>k</math> + 1 osservazioni per generare una previsione
        per l'osservazione <math>k</math> + 2 e cos via (dove
	<math>k</math> è il numero dei parametri nel modello originale).
      </para>
      <para>
	Viene mostrata, anche graficamente, la somma cumulata degli
	errori scalati di previsione (o dei quadrati degli
	errori). L'ipotesi nulla della stabilità dei parametri è
	rifiutata al livello di significatività del 5 per cento se la
	somma cumulata va al di fuori delle bande di confidenza al 95
	per cento.
      </para>

      <para>
        Nel caso di test CUSUM, viene mostrata anche la statistica
        <math>t</math> di Harvey&ndash;Collier per testare l'ipotesi nulla
        della stabilità dei parametri. Si veda il Capitolo 7 di
        <book>Econometric Analysis</book> di Greene, per i dettagli. Per il test
	CUSUMSQ, la banda di confidenza al 95% è calcolata usando l'algoritmo
        descritto in Edgerton e Wells (1994).

      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/CUSUM(SQ)</menu-path>
    </gui-access>

  </command>

  <command name="data" section="Dataset" 
	   label="Importazione da database" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati tranne che in caso di errore</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Legge le variabili nella <repl>lista-variabili</repl> da un
        database (gretl, RATS 4.0 o PcGive), che deve essere stato
        precedentemente aperto con il comando <cmdref
        targ="open"/>. La frequenza dei dati l'intervallo del campione
        possono essere impostati usando i comandi <cmdref
        targ="setobs"/> e <cmdref targ="smpl"/> prima di questo
        comando. Ecco un esempio completo:</para>
      <code>
	open macrodat.rat 
	setobs 4 1959:1 
	smpl ; 1999:4 
	data GDP_JP GDP_UK
      </code>
      <para>
	Questi comandi aprono un database chiamato
	<filename>macrodat.rat</filename>, impostano un dataset
	trimestrale che inizia nel primo trimestre del 1959 e finisce
	nel quarto trimestre del 1999 e infine importano le serie
	<lit>GDP_JP</lit> e <lit>GDP_UK</lit>.
      </para>
      <para>
        Se non si specificano <lit>setobs</lit> e <lit>smpl</lit> nel
        modo descritto, la frequenza dei dati e l'intervallo del
        campione vengono impostati usando la prima variabile letta dal
        database.
      </para>
      <para>
        Se le serie da leggere hanno frequenza maggiore di quella
        impostata nel dataset, è possibile specificare un metodo di
        compattamento, come mostrato di seguito
      </para>
      <code>
	data (compact=average) LHUR PUNEW
      </code>
      <para>I quattro metodi di compattamento disponibili sono
	<quote>average</quote> (usa la media delle osservazioni ad alta
	frequenza), <quote>last</quote> (usa l'ultima osservazione),
	<quote>first</quote> e <quote>sum</quote>. Se non si specifica alcun
        metodo, verrà usata la media delle osservazioni.
      </para> 

    </description>

    <gui-access>
      <menu-path>/File/Database</menu-path>
    </gui-access>

  </command>

  <command name="dataset" section="Dataset" 
    label="Manipola il dataset" context="cli">

    <usage>
      <arguments>
        <argument>parola-chiave</argument>
	<argument>parametri</argument>
      </arguments>
      <examples>
        <example>dataset addobs 24</example>
        <example>dataset compact 1</example>
        <example>dataset compact 4 last</example>
        <example>dataset expand interp</example>
        <example>dataset transpose</example>
        <example>dataset sortby x1</example>
	<example>dataset resample 500</example>
	<example>dataset renumber x 4</example>
	<example>dataset clear</example>
      </examples>
    </usage>

    <description>
      <para>
	Esegue varie operazioni sull'intero dataset, a seconda della
	<repl>parola-chiave</repl> usata, che può essere
	<lit>addobs</lit>, <lit>insobs</lit>, <lit>clear</lit>,
	<lit>compact</lit>, <lit>expand</lit>, <lit>transpose</lit>,
	<lit>sortby</lit>, <lit>dsortby</lit>, <lit>resample</lit> o
	<lit>renumber</lit>.  Nota: questi comandi non sono
	disponibili quando sul dataset è definito un sotto-campione
	ottenuto selezionando le osservazioni con un criterio
	Booleano.
      </para>
      <para>
	<lit>addobs</lit>: deve essere seguito da un intero positivo. Aggiunge
        il numero specificato di osservazioni alla fine del dataset, tipicamente
        a scopo di ottenere delle previsioni. I valori della maggior parte delle
        variabili nell'intervallo aggiunto sono impostati come valori mancanti,
        ma alcune variabili deterministiche, ad esempio le tendenze lineari e le
        variabili dummy periodiche, sono riconosciute ed estese.
      </para>
      <para>
	<lit>insobs</lit>: Deve essere seguito da un intero positivo inferiore
	o uguale al numero corrente  di osservazioni. Inserisce una singola
	ossrevazione nella posizione specificata. Tutti i dati successivi sono
	spostati di una posizione e il dataset è allungato di un'osservazione. 
	In corrispondenza della nuova osservazione a tutte le variabili, 
	a parte la costante, vengono assegnati valori mancanti. Questa azione non
	è disponibile in dataset panel.
      </para>
      <para>
	<lit>clear</lit>: Non richiede parametri. Elimina il campione corrente e 
	riporta gretl al suo stato iniziale senza dati.
      </para>      
       <para>
	<lit>compact</lit>: deve essere seguito da un intero positivo che
        rappresenta la nuova frequenza dei dati, che dovrebbe essere minore di
        quella attuale (ad esempio un valore 4 quando la frequenza attuale è 12
        significa che si compatterà un dataset mensile in uno trimestrale).
        Questo comando è disponibile solo se il dataset contiene serie storiche:
        compatta tutte le serie del dataset alla nuova frequenza. È possibile
        dare un secondo parametro, tra <lit>sum</lit>,
	<lit>first</lit> o <lit>last</lit>, per specificare, rispettivamente, di
        compattare usando la somma dei valori alla frequenza maggior, i valori
        di inizio periodo, o di fine periodo. Il comportamento predefinito
        consiste nel prendere la media dei valori sul periodo.
      </para>
      <para>
	<lit>expand</lit>: Questo comando è disponibile solo per serie
	storiche annuali o trimestrali. I dati annuali vengono espansi
	a trimestrali, quelli trimestrali a mensili. Per default,
	tutte le serie nel dataset verranno espanse assegnando alle
	nuove osservazioni i valori del periodo corrispondente nel
	vecchio dataset, ma con il modificatore <lit>interp</lit> le
	serie vengono espanse usando l'interpolazione di
	Chow&ndash;Lin (si veda <cite key="chowlin71">Chow e Lin,
	1971</cite>): i regressori sono costante e trend quadratico;
	il disturbo è assunto AR(1).
      </para>
      <para>
	<lit>transpose</lit>: non richiede parametri aggiuntivi. Traspone il
        dataset attuale: ogni osservazione (riga) del dataset attuale diventerà
        una variabile (colonna), e ogni variabile un'osservazione. Questo
        comando è utile quando si importano da fonti esterne dei dati
        organizzati con le variabili disposte per riga.
      </para>
      <para>
        <lit>sortby</lit>: richiede il nome di una variabile o di una
        lista. Con una variabile, questa viene usata come criterio di
        ordinamento. Le osservazioni di tutte le altre variabili del
        dataset sono riordinate secondo valori crescenti della
        variabile indicata. Nel caso di una lista, il comando procede
        gerarchicamente: il primo criterio di rdinamento è la prima
        variabile, e così via. Questo comando è disponibile solo per
        dati non datati.
      </para>
      <para>
       <lit>dsortby</lit>: funziona come <lit>sortby</lit> ma riordina le
       osservazioni secondo i valori decrescenti della variabile specificata.
      </para>
      <para>
	<lit>resample</lit>: costruisce un nuovo dataset attraverso un
        campionamento causale, con reimmissione, delle righe del dataset
        attuale. È richiesto un argomento, ossia il numero di righe da
        includere, che può essere minore, uguale o maggiore del numero di
        osservazioni nei dati originali. Il dataset originale può essere
        recuperato usando il comando <lit>smpl full</lit>.  
      </para>
      <para>
	<lit>renumber</lit>: Richiede il nome di una variabile esistente seguito da
	un intero compreso fra 1 e il numero delle variabili nel campione meno 1. Sposta
	la serie specificata nel dataset nella posizione indicata, rinumerando le altre 
	variabili di conseguenza. (La posizione 0 è occupata dalla costante che non può
	essere spostata.)
      </para>
    </description>

    <gui-access>
      <menu-path>/Dati</menu-path>
    </gui-access>

  </command>

  <command name="datasort" section="Dataset" context="gui"
    label="Ordina i dati">
  
    <description>
      <para>
        La variabile selezionata viene usata come chiave di ordinamento per
        l'intero dataset. Le osservazioni di tutte le variabili sono riordinate
        secondo valori crescenti della variabile indicata, o secondo valori
        decrescenti, se si usa l'opzione <quote>Decrescente</quote>.
      </para>
    </description>
  </command>

  <command name="debug" section="Programming" context="cli"
    label="Debugging">

    <usage>
      <arguments>
        <argument>function</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Un debugger sperimentale per funzioni definite dall'utente,
	disponibile a partire dalla linea di comando, gretlcli e dalla
	console GUI.  Il comando <lit>debug</lit> dovrebbe essere
	utilizzato dopo aver definito la funzione in questione ma
	prima di chiamarla. Il suo effetto è quello di sospendere
	l'esecuzione quando la funzione viene chiamata; la sospensione
	è segnalata dalla presenza di un prompt speciale.
      </para>
      <para>
	Una volta attivato il prompt di debug è possibile digitare
	<lit>next</lit> per eseguire il comando successivo della
	funzione, o <lit>continue</lit> per far proseguire
	l'esecuzione della funzione senza ulteriori arresti.  Questi
	comandi possono essere rispettivamente abbreviati con
	<lit>n</lit> e <lit>c</lit>. Al prompt di debug è anche
	possibile interpolare un'istruzione, per esempio un comando
	<lit>print</lit> per esaminare il valore corrente di qualche
	variabile di interesse.
      </para>
    </description>
  </command>  

  <command name="delete" section="Dataset" label="Elimina variabili" context="cli">

    <usage>
      <arguments>
        <argument optional="true">lista-variabili</argument>
      </arguments>
      <options>
       <option>
         <flag>--db</flag>
         <effect>rimuove dal database aperto</effect>
       </option>
	<option>
	  <flag>--type</flag>
	  <optparm>nome di tipo</optparm>
	  <effect>tutte le variabili di un dato tipo</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Questo comando è uno strumento multi-uso per eliminare variabili con un nome
	(serie, scalari, matrici, stringhe o bundle). Deve essere usato con
	cautela: non viene chiesta alcuna conferma.
      </para>
      <para>
	Nel caso di variabili, <repl>varname</repl> può essere il nome di una lista,
	e in questo caso vengono eliminate tutte le variabili incluse in essa, oppure
	può essere una lista esplicita di variabili indicate per nome o numero ID. 
	Si noti che quando cancellate variabili, quelle con numeri ID maggiori di quelli
	inclusi nella lista da cancellare saranno rinumerati.
      </para>
      <para>
       Se si usa l'opzione <opt>db</opt>, il comando rimuove le variabili
       elencate non dal dataset attuale ma da un database gretl, assumendo che
       questo sia stato aperto in precedenza e che l'utente abbia il permesso
       di scrittura sul file che contiene il database. Si veda anche il comando
       <cmdref targ="open"/>.
      </para>
      <para>
	Se viene indicata l'opzione <opt>type</opt> è necessario accompagnarla
	con uno dei nomi di tipi seguenti: <lit>matrix</lit>, <lit>bundle</lit>, 
	<lit>string</lit>, 	<lit>list</lit> o <lit>scalar</lit>. L'effetto 
	è quello di cancellare tutte le variabili di un certo tipo. Solo in questo caso
	non è necessario fornire l'argomento <repl>varname</repl>.
      </para>
    </description>

    <gui-access>
      <menu-path>Pop-up nella finestra principale (selezione singola)</menu-path>
    </gui-access>

  </command>

  <command name="density" section="Statistics" context="gui"
    label="Stima kernel di densità">

    <description>

      <para>
	La stima kernel di densità avviene definendo un insieme di
	punti di riferimento distanziati in modo uniforme su un
	appropriato intervallo dei dati, e attribuendo ad ognuno di
	essi un valore di densità basato sui valori delle osservazioni
	circostanti.
      </para>
      
      <para>
        La formula usata per calcolare la densità stimata in ognuno dei punti di
        riferimento <math>x</math> è
      <equation status="display"
	tex="\[f(x)=(1/nh) \sum_{t-1}^{n} k\left((x-x_t)/h\right)\]"
	ascii="f(x) = (1/nh) sum(t=1 to n) k((x - x(t)) / h)"
	graphic="kernel1"/>
      dove <math>n</math> denota il numero delle osservazioni,
      <math>h</math> è un parametro di "larghezza di banda" e
      <math>k</math>() è la funzione kernel. All'aumentare del parametro
      di banda, aumenta il livellamento della densità stimata.
      </para>

      <para>
	È possibile usare un kernel Gaussiano (la densità normale
	standard) o il kernel di Epanechnikov, mentre la larghezza di
	banda predefinita è quella suggerita da Silverman (1986),
	ossia
	<equation status="display"
	  tex="\[h=0.9 {\rm min}(s, {\rm IQR}/1.349) n^{1/5}\]"
	  ascii="h = 0.9 min(s, IQR/1.349) n^{1/5}"
	  graphic="kernel2"/>

      dove <math>s</math> denota lo scarto quadratico medio dei dati e
      IQR denota il range interquartile. È possibile allargare o
      restringere la banda usando il <quote>fattore di aggiustamento
      della banda</quote>: la banda effettivamente utilizzata si
      ottiene moltiplicando il valore di Silverman per il fattore di
      aggiustamento.
      </para>

      <para>Per una buona discussione introduttiva della stima kernel,
      si veda il capitolo 15 di <book>Econometric Theory and
      Methods</book> di Davidson e MacKinnon.
      </para>

    </description>

  </command>  

  <command name="dfgls" section="Tests" context="gui"
    label="Il test ADF-GLS">

    <description>
      <para>
       Il test ADF-GLS è una variante del test Dickey&ndash;Fuller per radici
       unitarie, per il caso in cui la variabile da testare ha media diversa da
       zero o esibisce un trend lineare. La differenza consiste nel fatto che la
       rimozione della media o del trend è eseguita secondo la procedura
       suggerita da Elliott, Rothenberg e Stock (1996). Questa produce un test
       di potenza maggiore rispetto a quello dell'approccio standard di
       Dickey&ndash;Fuller.
      </para>
      <para>
       Si veda anche l'opzione <opt>gls</opt> del comando <cmdref
       targ="adf"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/ADF-GLS test</menu-path>
    </gui-access>

  </command>

  <command name="dialog" section="Estimation" context="gui"
    label="Finestra di dialogo Modello">

    <description>
      <para>Per selezionare la variabile dipendente, fare clic su una
      variabile nella lista di sinistra e premere il pulsante
      <quote>Scegli</quote> con la freccia che punta verso il riquadro
      della variabile dipendente.  Selezionando la casella
      <quote>Imposta come predefinito</quote>, la variabile scelta
      verrà sempre pre-selezionata come variabile dipendente durante
      le prossime aperture della finestra di dialogo.  Trucco: facendo
      doppio clic su una variabile sulla sinistra, viene selezionata
      come variabile dipendente e impostata come scelta predefinita.
	</para>

      <para>Per selezionare le variabili indipendenti, fare clic su di
      esse nella lista di sinistra e premere il pulsante
      <quote>Aggiungi</quote> (o fare clic col pulsante destro del
      mouse). È possibile selezionare più variabili contigue
      trascinando il mouse; se le variabili da selezionare non sono
      contigue, occorre fare clic tenendo premuto il tasto
      <lit>Ctrl</lit>.
      </para>
    </description>

  </command>

  <command name="diff" section="Transformations" label="Differenze prime" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Calcola la differenza prima di ogni variabile nella
	<repl>lista-variabili</repl> e la salva in una nuova variabile
	il cui nome è prefissato con <lit>d_</lit>.  Quindi <cmd>diff
	x y</cmd> crea le nuove variabili
      </para>
      <code>
	d_x = x(t) - x(t-1)
        d_y = y(t) - y(t-1)
      </code>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Differenze</menu-path>
    </gui-access>

  </command>

  <command name="difftest" section="Tests" 
    label="Test non parametrici per le differenze" context="cli">

    <usage>
      <arguments>
        <argument>var1</argument>
	<argument>var2</argument>
      </arguments>
      <options>
	<option>
	  <flag>--sign</flag>
	  <effect>Test del segno, scelta predefinita</effect>
	</option>
	<option>
	  <flag>--rank-sum</flag>
	  <effect>Test "rank-sum" di Wilcoxon</effect>
	</option>
	<option>
	  <flag>--signed-rank</flag>
	  <effect>Test "signed-rank" di Wilcoxon</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>Mostra informazioni aggiuntive</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Esegue un test non parametrico per la differenza tra due popolazioni o
        gruppi; il tipo di test dipende dall'opzione usata.
      </para>
      <para>
	Con l'opzione <opt>sign</opt>, viene eseguito il test del segno,
        che si basa sul fatto che per due campioni
	<math>x</math> e <math>y</math> estratti casualmente dalla
        stessa distribuzione, la probabilità che valga
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub> per ogni osservazione
	<math>i</math> dovrebbe valere 0.5. La statistica test è
	<math>w</math>, ossia il numero di osservazioni per cui vale
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub>. Sotto l'ipotesi nulla, questa
        grandezza si distribuisce come una binomiale con parametri
	(<math>n</math>, 0.5), dove <math>n</math> è il numero di
        osservazioni.
      </para>
      <para>
	Con l'opzione <lit>--rank-sum</lit>, viene eseguito il test
	"rank-sum" di Wilcoxon. Questo test procede ordinando le
	osservazioni estratte da entrambi i campioni dalla più piccola
	alla più grande, e quindi calcolando la somma dei ranghi delle
	osservazioni da uno dei campioni. I due campioni non devono
	necessariamente avere la stessa dimensione: se sono diversi,
	viene usato il campione più piccolo per calcolare la somma dei
	ranghi. Sotto l'ipotesi nulla che i campioni siano estratti da
	popolazioni con la stessa mediana, la distribuzione di
	probabilità della somma dei ranghi può essere calcolata per
	ogni valore dell'ampiezza dei due campioni, mentre per
	campioni abbastanza ampi essa approssima la distribuzione
	normale.
      </para>
      <para>
	Con l'opzione <lit>--signed-rank</lit>, viene eseguito il test
        "signed-rank" di Wilcoxon. Questo test è valido per "coppie di
        campioni", come possono essere ad esempio i valori di una variabile in
        un gruppo di individui prima e dopo un certo trattamento. Il test
        procede calcolando le differenze tra le coppie di osservazioni
	<math>x</math><sub>i</sub> &minus;
	<math>y</math><sub>i</sub>, ordinando queste differenze per valore
        assoluto e assegnando ad ogni coppia un valore di rango con segno, in
        cui il segno rispecchia il segno della differenza. Quindi viene
        calcolato <math>W</math><sub>+</sub>, la somma di tutti i ranghi
        con segno positivo. Come avviene per il test rank-sum, questa
        statistica ha una distribuzione precisa nell'ipotesi nulla che la
        differenza mediana sia zero, distribuzione che converte alla normale nel
        caso di campioni abbastanza ampi.
      </para>
      <para>
        Usando l'opzione <opt>verbose</opt> con i test di Wilcoxon viene
        mostrato l'ordinamento delle osservazioni (l'opzione non ha effetto se
        usata con il test del segno).
      </para>
    </description>

  </command>
  
  <command name="discrete" section="Transformations" 
	   label="Marca variabili discrete" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--reverse</flag>
	  <effect>marca le variabili come continue</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Marca ogni variabile della <repl>lista-variabili</repl> come discreta.
        In modalità predefinita, tutte le variabili sono considerate come
        continue; marcando una variabile come discreta, essa viene trattata in
        modo speciale nei diagrammi di frequenza, e può esere usata con il
        comando <cmdref targ="dummify"/>.
      </para>
      <para>
        Usando l'opzione <opt>reverse</opt>, l'operazione viene invertita,
        ossia, le variabili nella <repl>lista-variabili</repl> sono marcate come
        continue.
      </para>
    </description>
    
    <gui-access>
      <menu-path>/Variabile/Modifica attributi</menu-path>
    </gui-access>

  </command>

  <command name="dpanel" section="Estimation" label="Dynamic panel models">

    <usage>
      <arguments>
	<argument>p</argument>
	<argblock separated="true">
	  <argument>depvar</argument>
	  <argument>indepvars</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>instruments</argument>
	</argblock>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra il modello stimato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
        <option>
	  <flag>--two-step</flag>
	  <effect>calcola la stima GMM a due passi</effect>
        </option>
        <option>
	  <flag>--system</flag>
	  <effect>aggiunge equazioni nei livelli</effect>
        </option>
        <option>
	  <flag>--time-dummies</flag>
	  <effect>aggiunge variabili dummy temporali</effect>
        </option>
        <option>
	  <flag>--dpdstyle</flag>
	  <effect>emula il pacchetto DPD per Ox</effect>
        </option>
        <option>
	  <flag>--asymptotic</flag>
	  <effect>errori standard asintotici non modificati</effect>
        </option>
      </options>
      <examples>
        <example>dpanel 2 ; y x1 x2</example>
	<example>dpanel 2 ; y x1 x2 --system</example>
        <example>dpanel {2 3} ; y x1 x2 ; x1</example>
	<example>dpanel 1 ; y x1 x2 ; x1 GMM(x2,2,3)</example>
	<demos>
	  <demo>bbond98.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Stima modelli dinamici per dati di panel (in altre parole, 
	modelli panel con uno o più ritardi della variabile dipendente)
	usando il metodo GMM-DIF o quello GMM-SYS.
      </para>
      <para context="cli">
	Il paramtro <repl>p</repl> rappresenta l'ordine autoregressivo 
	della variabile dipendente. Nel caso più semplice si tratta di 
	uno scalare, ma per specificare un insieme di ritardi (non 
	consecutivi) da è possibile indicare una matrice definita
	in precedenza.
      </para>
      <para>
	La variabile dipendente e i regressori dovrebbero essere indicati 
	in livelli; il comando provvede autonomamente a differenziarli
	(dato che questo stimatore usa le differenze per eliminare
	gli effetti individuali).
      </para>
      <para context="cli">
	L'ultimo campo (opzionale) nel comando serve a specificare
	strumenti.  Se questi ultimi non vengono indicati si assume
	che tutte le variabili indipendenti siano strettamente
	esogene. Se si sceglie di specificare alcuni strumenti è
	opportuno includere nell'elenco anche le variabili
	indipendenti strettamente esogene. Nel caso di regressori
	predeterminati è possibile usare la funzione <lit>GMM</lit>
	per includere uno specifico intervallo di ritardi seguendo uno
	schema diagonale a blocchi. Una situazione di questo tipo è
	stata illustrata in precedenza nel terzo esempio. Il primo
	argomento di <lit>GMM</lit> è il nome della variabile in
	questione, il secondo è il ritardo minimo da usare come
	strumento e il terzo è il ritardo massimo.  La stessa sintassi
	può essere utilizzata con la funzione <lit>GMMlevel</lit> per
	specificare strumenti di tipo GMM per le equazioni nei
	livelli.
      </para>
      <para context="gui">
	Per quanto riguarda la gestione degli strumenti, si consulti
	la documentazione di questo comando in modalità
	scripting. Attualmente non è possibile specificare
	esplicitamente degli strumenti nella GUI: tutte le variabili
	indipendenti sono considerate strettamente esogene.
      </para>
      <para>
	Di default vengono riportati (con errori standard robusti) i
	risultati della stima al primo stadio; la stima al secondo
	stadio può essere richiesta indicato l'opzione
	corrispondente. In entrambi i casi vengono forniti i test di
	autocorrelazione del primo e del secondo ordine, così come il
	test di sovraidentificazione di Sargan e un test di Wald della
	significatività congiunta dei regressori. Si noti che in
	questo modello nelle differenze l'autocorrelazione del primo
	ordine non impedisce che il modello sia valido;
	l'autocorrelazione al secondo ordine, tuttavia, viola le
	ipotesi statistiche che ne sono alla base.
      </para>
      <para context="cli">
	Nel caso della stima a due passi, gli errori standard sono per
	default calcolati usando la correzione per campioni finiti
	suggerita da <cite key="windmeijer05">Windmeijer
	(2005)</cite>. In generale l'inferenza basata sugli errori
	standard asintotici associati allo stimatore al secondo stadio
	è considerata inaffidabile, ma se per qualche ragione
	desiderate conoscere il loro valore potete usare l'opzione
	<opt>asymptotic</opt> per disattivare la correzione di
	Windmeijer.
      </para>
      <para context="cli">
	Se viene indicata l'opzione <opt>time-dummies</opt> il
	comando aggiunge ai regressori specificati un insieme di
	variabili dummy.  Il numero di queste ultime è pari al numero
	massimo di periodi usati nella stima meno uno, allo scopo di
	evitare di avere collinearità perfetta con la costante.  Le
	dummy vengono incluse in differenza, a meno che non sia
	indicata l'opzione <opt>dpdstyle</opt>; in questo caso le
	dummy sono incluse in livello.
      </para>
      <para>
	Per ulteriori dettagli ed esempi, si veda <guideref
	targ="chap:dpanel"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Panel/Dynamic panel model</menu-path>
    </gui-access>

  </command>

  <command name="dummify" section="Transformations" context="gui"
    label="Create sets of dummies">

    <description>
      <para>
	L'operazione <quote>dummify</quote> è disponibile solo per
	variabili discrete. Ha l'effetto di creare un insieme di
	variabili dummy (binarie) per ognuno dei valori presenti nella
	variabile.
      </para>
      <para>
	Come esempio, si immagini di avere una variabile chiamata
	<lit>statociv</lit>, con valori 1 per
	<quote>celibe/nubile</quote>, 2 per <quote>coniugato</quote>,
	3 per <quote>separato/divorziato</quote> e 4 per
	<quote>vedovo</quote>. L'operazione di cui stiamo parlando
	creerebbe 4 variabili binarie: la prima avrebbe valore 1 per
	chi non si è mai sposato e zero per gli altri; la seconda
	avrebbe valore 1 per chi è sposato e zero per gli altri, e
	così via.
      </para>
      <para>
	Nella pratica, per una serie discreta con <math>k</math>
	categorie di solito il numero di dummy che vengono create è
	<math>k</math> &minus; 1, per evitare la cosiddetta
	<quote>trappola delle dummy</quote>. Di conseguenza, vi
	offriamo l'opzione di saltare il valore più alto o quello più
	basso della codifica.
      </para>
    </description>

  </command>

  <command name="dummify" section="Transformations" label="Crea variabili dummy" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--drop-first</flag>
	  <effect>omette dalla codifica il valore minimo</effect>
	</option>
	<option>
	  <flag>--drop-last</flag>
	  <effect>omette dalla codifica il valore massimo</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Per ogni variabile rilevante nella
	<repl>lista-variabili</repl>, crea un insieme di variabili
	dummy che codificano i valori distinti di quella variabile. Le
	variabili rilevanti sono quelle che sono state marcate
	esplicitamente come discrete, o quelle che assumono un numero
	limitato di valori che devono essere <quote>abbastanza
	arrotondati</quote> (multipli di 0.25).
      </para>
      <para>
	Per impostazione predefinita, viene aggiunta una variabile
	dummy per ognuno dei valori distinti della variabile in
	questione.  Ad esempio, se una variabile discreta <lit>x</lit>
	ha 5 valori distinti, verranno create 5 variabili dummy, di
	nome <lit>Dx_1</lit>, <lit>Dx_2</lit> e così via. La prima
	variabile dummy avrà valore 1 per le osservazioni in cui
	<lit>x</lit> assume il suo valore minimo, e 0 altrove; la
	successiva variabile dummy avrà valore 1 dove <lit>x</lit>
	assume il secondo tra i suoi valori, e così via. Se viene
	usata una delle opzioni <lit>--drop-first</lit> o
	<lit>--drop-last</lit>, il più basso o il più alto dei valori
	della variabile viene omesso dalla codifica (questa funzione
	può essere utile per evitare la cosiddetta <quote>trappola
	delle variabili dummy</quote>).
      </para>
      <para>
	Questo comando può anche essere usato nel contesto di una
	regressione.  Ad esempio, la riga seguente specifica un
	modello in cui <lit>y</lit> viene regredita sull'insieme di
	variabili dummy che codificano <lit>x</lit> (in questo
	contesto non è possibile passare opzioni al comando
	<cmd>dummify</cmd>).
      </para>
      <code>
	ols y dummify(x)
      </code>
    </description>

  </command>
 
  <command name="duration" section="Estimation" label="Duration models" 
    context="cli">
    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
        <argument separated="true" optional="true">censvar</argument>
      </arguments>
      <options>
        <option>
          <flag>--exponential</flag>
          <effect>usa la distribuzione esponenziale</effect>
        </option>
        <option>
          <flag>--loglogistic</flag>
          <effect>usa la distribuzione log-logistica</effect>
        </option>
        <option>
          <flag>--lognormal</flag>
          <effect>usa la distribuzione log-normale</effect>
        </option>
        <option>
          <flag>--medians</flag>
          <effect>i valori previsti sono mediane</effect>
        </option>
        <option>
          <flag>--robust</flag>
          <effect>errori standard robusti (QML)</effect>
        </option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>v. <cmdref targ="logit"/> per una spiegazione</effect>
        </option>
        <option>
          <flag>--vcv</flag>
          <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
          <flag>--verbose</flag>
          <effect>mostra dettagli delle iterazioni</effect>
        </option>
      </options>      
      <examples>
        <example>duration y 0 x1 x2</example>
	<example>duration y 0 x1 x2 ; cens</example>
      </examples>
    </usage>

    <description>
      <para>
	Stima un modello di durata: la variabile dipendente (che deve essere
	positiva) rappresenta la durata di un certo fenomeno, per esempio
	la lunghezza di un periodo di disoccupazione per una cross-section
	di intervistati. Di default viene utilizzata una distribuzione Weibull,
	ma sono disponibili anche le distribuzioni esponenziale, log-logistica 
	e log-normale.
      </para>
      <para>
	Se alcune delle durate misurate sono censurate a destra (&eg;
	il periodo di disoccupazione di un individuo non si è concluso
	all'interno del periodo di osservazione), deve essere
	specificato l'argomento accessorio <repl>censvar</repl> che
	indica una variabile i cui valori positivi segnalano
	osservazioni censurate a destra.
      </para>
      <para>
	Di default i valori stimati ottenuti mediante l'accessore
	<fncref targ="$yhat"/> rappresentano le medie condizionali delle
	durate; se tuttavia viene indicata l'opzione
	<opt>medians</opt>, <fncref targ="$yhat"/> fornisce le mediane
	condizionali.
	  </para>
      <para>
	Vedi <guideref targ="chap:probit"/> per ulteriori dettagli.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Nonlinear models/Duration data...</menu-path>
    </gui-access>

  </command>  

  <command name="elif" section="Programming" label="Strutture di controllo" context="cli">

    <description><para>Si veda <cmdref targ="if"/>.</para>
    </description>

  </command>

  <command name="else" section="Programming" label="Strutture di controllo" context="cli">

    <description>
      <para>Si veda <cmdref targ="if"/>. Si noti che <cmd>else</cmd>
      dev'essere su un linea a sé stante, prima del comando
      corrispondente. Si può aggiungere un commento, come ad esempio
      </para>
      <code>
	else # OK, fa' un'altra cosa
      </code>
      <para>
	ma nn si può aggiungere un comando, come in
      </para>
      <code>
	else x = 5 # wrong!
      </code>
    </description>

  </command>

  <command name="end" section="Programming" 
	   label="Chiude un blocco di comandi" context="cli">

    <description>
      <para>
	Termina un blocco di comandi di qualsiasi tipo.
        Ad esempio, <cmd>end system</cmd> termina un <cmdref targ="system"/>
        (sistema di equazioni).
      </para>
    </description>

  </command>

  <command name="endif" section="Programming" label="Strutture di controllo" context="cli">

    <description><para>Si veda <cmdref targ="if"/>.</para>
    </description>
  </command>

  <command name="endloop" section="Programming" label="Chiude un ciclo di comandi" context="cli">
    <description>
      <para>
	Indica la fine di un ciclo (loop) di comandi.  Si veda <cmdref targ="loop"/>.
      </para>
    </description>

  </command>

  <command name="eqnprint" section="Printing" label="Stampa un modello come equazione" context="cli">

    <usage>
      <options>
        <option>
	  <flag>--complete</flag>
	  <effect>crea un documento completo</effect>
        </option>
        <option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>send output to specified file</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello. Stampa il modello
	stimato sotto forma di equazione &latex;. Se viene specificato
	un nome di file usando l'opzione <opt>output</opt>, il
	risultato viene scritto in quel file, altrimenti viene scritto
	in un file il cui nome ha la forma
	<filename>equation_N.tex</filename>, dove <lit>N</lit> è il
	numero di modelli stimati finora nella sessione in corso. Si
	veda anche <cmdref targ="tabprint"/>.
      </para>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo. 
      </para>
      <para>
	Usando l'opzione <opt>complete</opt>, il file &latex; è un
        documento completo, pronto per essere processato; altrimenti il
        file va incluso in un documento.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /LaTeX</menu-path>
    </gui-access>

  </command>

  <command name="equation" section="Estimation" label="Definisce un'equazione in un sistema" context="cli">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <examples>
        <example>equation y x1 x2 x3 const</example>
      </examples>
    </usage>

    <description>
      <para>
	Specifica un'equazione all'interno di un sistema di equazioni
	(si veda <cmdref targ="system"/>). La sintassi per specificare
	un'equazione in un sistema SUR è la stessa usata ad esempio in
	<cmdref targ="ols"/>. Per un'equazione in un sistema con
	minimi quadrati a tre stadi, invece è possibile usare una
	specificazione simile a quella usata per OLS e indicare una
	lista di strumenti comuni usando l'istruzione <cmd>instr</cmd>
	(si veda ancora <cmdref targ="system"/>), oppure si può usare
	la stessa sintassi di <cmdref targ="tsls"/>.
      </para>
    </description>

  </command>

  <command name="estimate" section="Estimation" 
	   label="Stima sistemi di equazioni" context="cli">

    <usage>
      <arguments>
        <argument optional="true">nome-sistema</argument>
	<argument optional="true">stimatore</argument>
      </arguments>
      <options>
       <option>
         <flag>--iterate</flag>
         <effect>itera fino alla convergenza</effect>
       </option>
       <option>
         <flag>--no-df-corr</flag>
         <effect>nessuna correzione per i gradi di libertà</effect>
       </option>
       <option>
         <flag>--geomean</flag>
         <effect>si veda oltre</effect>
       </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
      </options>
      <examples>
        <example>estimate "Klein Model 1" method=fiml</example>
	<example>estimate Sys1 method=sur</example>
        <example>estimate Sys1 method=sur --iterate</example>
      </examples>
    </usage>

    <description>
      <para>
	Esegue la stima di un sistema di equazioni, che deve essere
	stato definito in precedenza usando il comando <cmdref
	targ="system"/>.  Per prima cosa va indicato il nome del
	sistema, racchiuso tra virgolette se contiene spazi, quindi il
	tipo di stimatore, preceduto dalla stringa
	<lit>method=</lit>. Gli stimatori disponibili sono:
	<cmd>ols</cmd>, <cmd>tsls</cmd>, <cmd>sur</cmd>,
	<cmd>3sls</cmd>, <cmd>fiml</cmd> o <cmd>liml</cmd>. Questi
	argomento sono opzionali si il sistema in questione è già
	stato stimato e occupa il posto dell'<quote>ultimo
	modello</quote>; in tal caso, per default viene usato il
	metodo di stima precedente.
      </para>
      <para>Se al sistema in questione sono stati imposti dei vincoli (si veda
       il comando <cmdref targ="restrict"/>), la stima sarà soggetta a tali
       vincoli.
      </para>
      <para>
       Se il metodo di stima è <cmd>sur</cmd> o <cmd>3sls</cmd>
       e viene usata l'opzione <opt>iterate</opt>, lo stimatore verrà
       iterato. Nel caso di SUR, se la procedura converge, i risultati
       saranno stime di massima verosimiglianza. Invece l'iterazione della
       procedura dei minimi quadrati a tre stadi non produce in genere
       risultati di massima verosimiglianza a informazione completa.
       L'opzione <opt>iterate</opt> viene ignorata con gli altri metodi di
       stima.
      </para>
      <para>Se vengono scelti gli stimatori "equazione per equazione"
      <cmd>ols</cmd> o <cmd>tsls</cmd>, nel calcolo degli errori standard viene
      applicata in modo predefinito una correzione per i gradi di libertà, che
      può essere disabilitata usando l'opzione <lit>--no-df-corr</lit>. Questa
      opzione non ha effetti nel caso vengano usati altri stimatori, che non
      prevedono correzioni per i gradi di libertà.
      </para>
      <para>
	La formula usata in modo predefinito per calcolare gli
	elementi della matrice di covarianza tra equazioni è
       <equation status="display"
       tex="\[\hat{\sigma}_{i,j}=\frac{\hat{u}_i' \hat{u}_j}{T}\]"
       ascii="sigma(i,j) = u(i)' * u(j) / T"
       graphic="syssigma1"/>
       Se viene usata l'opzione <opt>geomean</opt>, viene applicata
       una correzione per i gradi di libertà secondo la formula
       <equation status="display"
       tex="\[\hat{\sigma}_{i,j}=\frac{\hat{u}_i' \hat{u}_j}{\sqrt{(T-k_i)(T-k_j)}}\]"
       ascii="sigma(i,j) = u(i)' * u(j) / sqrt((T - ki) * (T - kj))"
       graphic="syssigma2"/>
       dove i <math>k</math> indicano il numero di parametri
       indipendenti in ogni equazione.
      </para>
      <para>
        Se si usa l'opzione <opt>verbose</opt> e un metodo iterativo, vengono
        mostrati i dettagli delle iterazioni.
      </para>
    </description>

  </command>

  <command name="eval" section="Utilities">
    <usage>
      <arguments>
        <argument>espressione</argument>
      </arguments>
      <examples>
        <example>eval x</example>
	<example>eval inv(X'X)</example>
	<example>eval sqrt($pi)</example>
      </examples>
    </usage>    
    <description>
      <para>
	Con questo comando, gretl diventa una specie di grande
	calcolatrice. Il programma valuta
	l'<argname>espressione</argname> e stampa il
	risultato. L'argomento può essere il nome di una variabile, o
	qualcosa di più complicato. In ogni caso, dev'essere
	un'espressione ammissibile a destra dell'operatore di
	assegnamento.
      </para>
    </description>
  </command>

  <command name="expand" section="Dataset" context="gui"
    label="Espansione dei dati">

    <description>

      <para>
	Se si vuole aggiungere a un dataset una serie di frequenza
	inferiore, è necessario <quote>espandere</quote> la nuova
	serie. Ad esempio, una serie trimestrale dovrà essere espansa
	per essere aggiunta a un dataset mensile. Altre volte
	occorrerà espandere un intero dataset a una frequenza
	superiore prima di aggiungervi una serie che ha una frequenza
	superiore.
      </para>
      <para>
        L'operazione di espansione dei dati è riservata gli utenti
        <quote>esperti</quote>: occorre sapere bene cosa si sta
        facendo. Quando si combinano serie di frequenza diversa nello
        stesso dataset, di solito è più consigliabile compattare i
        dati ad alta frequenza piuttosto che espandere quelli a bassa
        frequenza
      </para>
      <para>
	Ciò premesso, gretl offre due opzioni: valori ad altra
	frequenza possono essere espansi usando il metodo di <cite
	key="chowlin71">Chow e Lin (1971)</cite> oppure ripetendo i
	dati a frequenza più bassa per il numero necessario di volte.
      </para>
      <para>
	Il metodo di Chow&ndash;Lin è basato su una regressione su
	costante e trend quadratico; il disturbo è assunto
	AR(1). Questa procedura richiede 4 gradi di libertà.
      </para>
      <para>
	Per quanto riguarda il metodo della ripetizione del dato,
	invece, diamo un esempio. Se si ha una serie trimestrale con
	il valore 35.5 per l'osservazione 1990:1 (il primo trimestre
	del 1990), espandendo la serie, il valore 35.5 verrà assegnato
	alle osservazioni per gennaio, febbraio e marzo del 1990. La
	variabile espansa non potrà quindi essere utilizzata per
	analisi temporali "a grana fine", tranne nel caso si abbia
	ragione di ritenere che la variabile in questione rimanga
	costante nei vari sotto-periodi.
      </para>


    </description>
  </command>

  <command name="export" section="Dataset" context="gui"
    label="Esportazione dei dati">

    <description>
      <para>È possibile esportare dati in formato separato da virgole
      (CSV: Comma-Separated Values), in modo che possano essere aperti
      con fogli elettronici e molti altri programmi
      applicativi. Selezionando questa opzione, sarà possibile
      scegliere diverse caratteristiche del file CSV.
	</para>
      <para>
	E' anche possibile esportare dati sotto forma di file di dati 
	<quote>native</quote> di gretl, oppure (se i dati lo rendono possibile)
	esportare un database di gretl. V. <url>gretl.sourceforge.net/gretl_data.html</url> 
	per una discussione dei database di gretl.
      </para>
      <para>
	E' anche possibile esportare i dati in un formato pronto per essere usato
	dai programmi seguenti:	
      </para>
      <ilist>
	<li>
	  <para>GNU R (<url>www.r-project.org</url>)</para>
	</li>
	<li>
	  <para>GNU octave (<url>www.gnu.org/software/octave</url>)
	  </para>
	</li>
	<li>
	  <para>JMulTi (<url>www.jmulti.de</url>)</para>
	</li>
	<li>
	  <para>PcGive (<url>www.pcgive.com</url>)</para>
	</li>
      </ilist>
      <para>
	Se desiderate esportare i dati copiandoli negli appunti invece di 
	scriverli in un file di dati, selezionate le variabili che volete
	copiare nella finestra principale, cliccate sul pulsante destro e
	selezionate <quote>Copia negli appunti</quote>. 
	(In questo contesto è supportato solo il formato CSV.)
      </para>

    </description>
  </command>

  <command name="factorized" section="Graphs" context="gui"
    label="Grafici X-Y con fattore">

    <description>
      <para>Questo comando richiede che si selezionino tre variabili,
        l'ultima delle quali deve essere una variabile dummy (con valori
        1 o 0). La variabile Y è rappresentata rispetto alla variabile X,
        con i punti colorati diversamente a seconda del valore della terza
        variabile.</para>

      <para>Esempio: si hanno dati sui salari e il livello di scolarità
        per un campione di persone; si dispone anche di una variabile
        dummy che vale 1 per gli uomini e 2 per le donne (come nel file
	<filename>data7-2</filename> di Ramanathan).  Un <quote>Grafico
        X-Y con fattore</quote> di <lit>WAGE</lit> rispetto a <lit>EDUC</lit>
	usando la dummy <lit>GENDER</lit> mostrerà le osservazioni che si
        riferiscono agli uomini in un colore e quelle delle donne in un altro
        (insieme a una legenda per identificarli).</para>

    </description>

  </command>
  

  <command name="fcast" section="Prediction" label="Genera previsioni">

    <usage>
      <altforms>
	<altform><lit>fcast [</lit><repl>oss-iniziale oss-finale</repl><lit>] [</lit><repl>nome-variabile</repl><lit>]</lit></altform>
	<altform><lit>fcast [</lit><repl>oss-iniziale oss-finale</repl><lit>]</lit> <repl>passi-avanti</repl> <lit>[</lit><repl>nome-variabile</repl><lit>] --rolling</lit></altform>
      </altforms>
      <options>
	<option>
	  <flag>--dynamic</flag>
	  <effect>crea previsioni dinamiche</effect>
	</option>
	<option>
	  <flag>--static</flag>
	  <effect>crea previsioni statiche</effect>
	</option>
	<option>
	  <flag>--out-of-sample</flag>
	  <effect>genera previsioni fuori dal campione</effect>
	</option>
	<option>
	  <flag>--no-stats</flag>
	  <effect>non mostra le statistiche di previsione</effect>
	</option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra le previsioni</effect>
        </option>
        <option>
          <flag>--rolling</flag>
          <effect>vedi sotto</effect>
        </option>
        <option>
	  <flag>--plot</flag>
	  <optparm>nome di file</optparm>
	  <effect>vedi sotto</effect>
        </option>
      </options>
      <examples>
        <example>fcast 1997:1 2001:4 f1</example>
	<example>fcast fit2</example>
        <example>fcast 2004:1 2008:3 4 rfcast --rolling</example>
      </examples>
    </usage>

    <description>
      <para contest="gui">
	Deve seguire un comando di stima.  Calcola previsioni
        per l'intervallo specificato. A seconda del tipo di modello, calcola
        anche gli errori standard (si veda oltre).
      </para>
      <para context="cli">
	Deve seguire un comando di stima.  Calcola previsioni
        per un certo intervallo delle osservazioni. L'intervallo può essere
        specificato indicando <repl>oss-iniziale</repl>
        e <repl>oss-finale</repl>, oppure con l'opzione
        <lit>--out-of-sample</lit> (in questo caso la previsione sarà per le
        osservazioni successive a quelle su cui è stato stimato il modello); se
        non si usa alcuna opzione, l'intervallo sarà quello attualmente
        impostato. Se si sceglie una previsione fuori dal campione ma non sono
        disponibili osservazioni, viene segnalato un errore. A seconda del tipo
        di modello, calcola anche gli errori standard (si veda oltre).
        L'opzione <opt>rolling</opt> produce un comportamento speciale
        spiegato oltre.
      </para>
      <para context="cli">
	Se l'ultimo modello stimato consiste in un'equazione singola,
        l'argomento opzionale <repl>nome-variabile</repl> ha l'effetto seguente:
	i valori della previsione non sono mostrati, ma vengono salvati nel
        dataset con il nome di variabile indicato. Se l'ultimo modello stimato è
        un sistema di equazioni, <repl>nome-variabile</repl> ha un effetto
        diverso, ossia seleziona una particolare varabile endogena per cui
        effettuare la previsione (l'impostazione predefinita consiste nel
        produrre previsioni per tutte le variabili endogene). Nel caso del
        sistema, o se non viene specificata <repl>nome-variabile</repl>, i
        valori della previsione possono essere recuperati usando la varaiabile
        accessoria <fncref targ="$fcast"/>, mentre gli errori standard, se
        disponibili, con <fncref targ="$fcerr"/>.
      </para>
      <para>
	La scelta tra previsione statica e dinamica è rilevante solo nel caso di
        modelli dinamici, che comprendono un processo di errore autoregressivo,
        o che comprendono uno o più valori ritardati della variabile dipendente
        come regressori. Le previsioni statiche sono per il periodo successivo,
        basate sui valori effettivi nel periodo precedente, mentre quelle
        dinamiche usano la regola della previsione a catena.
        Ad esempio, se la previsione per <math>y</math> nel 2008
 	richiede come input il valore di <math>y</math> nel 2007,
        non è possibile calcolare una previsione statica se non si hanno dati
        per il 2007. È possibile calcolare una previsione dinamica per il 2008
        se si dispone di una precedente previsione per
 	<math>y</math> nel 2007.
       </para>
 
       <para>
 	La scelta predefinita consiste nel fornire una previsione statica per
        ogni porzione dell'intervallo di previsione che fa parte dell'intervallo
        del campione su cui il modello è stato stimato, e una previsione
        dinamica (se rilevante) fuori dal campione. L'opzione
 	<lit>dynamic</lit> richiede di produrre previsioni dinamiche a partire
        dalla prima data possibile, mentre l'opzione <lit>static</lit>
        richiede di produrre previsioni statiche anche fuori dal campione.
       </para>

       <para context="cli">
         L'opzione <lit>rolling</lit> al momento è disponibile solo per i
         modelli composti da una singola equazione e stimati via OLS. Quando si
         usa questa opzione, le previsioni calcolate sono ricorsive, ossia: ogni
         previsione è generata da una stima del modello che usa i dati
         a partire da un certo punto fisso (ossia l'inizio dell'intervallo del
         campione usato per la stima originaria) fino alla data di previsione
         meno <math>k</math> osservazioni, dove <math>k</math> è il numero di
         <lit>passi-avanti</lit> specificato come argomento. Le previsioni sono
         sempre dinamiche quando è possibile. Si noti che l'argomento
         <lit>passi-avanti</lit> deve essere utilizzato solo insieme all'opzione
         <lit>rolling</lit>.
       </para>
 
      <para context="cli">
	L'opzione <opt>plot</opt> (disponibile solo nel caso della stima di un
	modello uniequazionale) consente di ottenere un file con un grafico delle 
	previsioni. L'estensione dell'argomento <repl>filename</repl> 
	di questa opzione controlla il formato del grafico: <lit>.eps</lit>
	per EPS, <lit>.pdf</lit> per PDF, <lit>.png</lit> per PNG,
	<lit>.plt</lit> per un file di comandi gnuplot. Il nome di file dummy 
	<lit>display</lit> può essere usato per mostrare il grafico in una finestra. 
	Per esempio, 
      </para>
      <code>
	fcast --plot=fc.pdf
      </code>
      <para>
	genererà un grafico in formato PDF. Vengono rispettati gli indirizzi
	di file assoluti; in caso contrario i fail vengono scritti nella directory
	di lavoro di gretl.
      </para>

       <para>
 	La natura degli errori standard della previsione (se disponibili)
        dipende dalla natura del modello e della previsione. Per i modelli
        lineari statici, gli errori standard sono calcolati seguendo il metodo
        delineato in Davidson and MacKinnon (2004); essi incorporano sia
        l'incertezza dovuta al processo d'errore, sia l'incertezza dei parametri
        (sintetizzata dalla matrice di covarianza delle stime dei parametri).
        Per modelli dinamici, gli errori standard della previsione sono
        calcolati solo nel caso di previsione dinamica, e non incorporano
        incertezza dei parametri. Per modelli non lineari, al momento non sono
        disponibili errori standard della previsione.
       </para>

    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Analisi/Previsioni</menu-path>
    </gui-access>

  </command>

  <command name="flush" section="Programming" context="cli">

    <description>
     <para>
       Questo smplice comando non ha argomenti né opzioni; è pensato
       per l'esecuzione di script, la cui esecuzione richieda qualche
       tempo, attraverso l'interfaccia grafica (la versione di gretl
       da linea di comando lo ignora). L'idea è di fornire all'utente
       un'indicazione visuale che sta succedendo qualcosa e il
       programma non si è <quote>piantato</quote>.
     </para>
     <para>
       Normalmente, quando uno script viene fatto girare nel client
       grafico, non viene mostrato alcun output finché l'esecuzione
       non è completa; se perà si usa  <lit>flush</lit> l'effetto
       prodotto è il seguente:
     </para>
     <ilist>
       <li>
	 <para>
	   Alla prima invocazione, gretl apre una finestra, mostra
	   l'output prodotto fino a quel momento, e aggiunge il
	   messaggio <quote>elaborazione in corso...</quote>.
	 </para>
       </li>
       <li>
	 <para>
	   Ad ogni invocazione successiva, il testo mostrato nella
	   finestra di output viene aggiornato e un nuovo messaggio
	   <quote>elaborazione in corso</quote> viene aggiunto.
	 </para>
       </li>
     </ilist>
     <para>
       Tutto il resto dell'output viene automaticamente mostrato al
       completamenteo dell'esecuzione dello script.
     </para>
     <para>
       Attenzione: non ha senso usare <lit>flush</lit> in script la
       cui esecuzione richiede pochi secondi. Inoltre, bisognerebbe
       evitare di usare questo comando in un punto dello script dove
       non c'è più output da mostrare, perché il messaggio
       <quote>elaborazione in corso</quote> risulterebbe fuorviante.
     </para>
     <para>
       L'uso che abbiamo in mente per il comando <lit>flush</lit> è
       esemplificato dal seguente frammento:
     </para>
     <code>
       set echo off
       scalar n = 10
       loop i=1..n
           # qualcosa che richiede del tempo
           loop 100 --quiet
               a = mnormal(200,200)
               b = inv(a)
           endloop
           # stampa qualcosa in output
           printf "Iterazione %2d fatta\n", i
           if i &lt; n
               flush
           endif
       endloop
     </code>
    </description>

  </command>

  <command name="foreign" section="Programming"
    label="Script esterni" context="cli">

    <usage>
      <syntax><lit>foreign language=</lit><repl>lang</repl></syntax>
      <options>
       <option>
         <flag>--send-data</flag>
         <effect>pre-carica il dataset attuale</effect>
       </option>
       <option>
         <flag>--quiet</flag>
         <effect>sopprime l'output dal programma esterno</effect>
       </option>
      </options>
    </usage>

    <description>
     <para>
       Questo comando apre una modalità speciale, in cui vengono
       accettati comandi che verranno eseguiti da un programma
       esterno.  Con il comando <lit>end foreign</lit> si esce da
       questa modalità e i comandi verranno eseguiti.
      </para>
      <para>
       Al momento, i programmi esterni compatibili con questa modalità
       sono (<lit>language=R</lit>), Ox di Jurgen Doornik Ox
       (<lit>language=Ox</lit>), GNU Octave
       (<lit>language=Octave</lit>), Python e, in minor misura, Stata.
       I nomi dei programmi esterni sono case-insensitive.
      </para>
      <para>
	Con R, Octave e Stata l'opzione <opt>send-data</opt> ha
	l'effetto di rendere disponibile all'interno del programma di
	destinazione l'intero dataset corrente.
      </para>
      <para>
       Si veda la <guideref targ="chap:gretlR"/> per dettagli ed esempi.
      </para>
    </description>

  </command>

  <command name="fractint" section="Statistics" label="Fractional integration">
  
    <usage>
      <arguments>
        <argument>series</argument>
	<argument optional="true">order</argument>
      </arguments>
      <options>
        <option>
	  <flag>--gph</flag>
	  <effect>calcola il test di Geweke e Porter-Hudak</effect>
        </option>
        <option>
	  <flag>--all</flag>
	  <effect>calcola entrambi i test</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Verifica la presenza di integrazione frazionale 
	(<quote>long memory</quote>) per la variabile specificata. 
	L'ipotesi nulla è che l'ordine di integrazione della variabile
	sia zero. Di default viene utilizzato lo stimatore locale di 
	Whittle <cite key="robinson95" p="true">(Robinson,
	1995)</cite>, ma se si indica l'opzione <opt>gph</opt> il comando 
	usa il test GPH <cite key="GPH83" p="true">(Geweke and
	Porter-Hudak, 1983)</cite>. L'opzione 
	<opt>all</opt> permette di ottenere i risultati di 
	entrambi i test.
      </para>
      <para>
	Per maggiori dettagli su questo tipo di test, v. <cite
	key="phillips04">Phillips e Shimotsu (2004)</cite>.
      </para>
      <para>
	Se non si specifica l'argomento opzionale <repl>order</repl>, 
	l'ordine del test (o dei test) è automaticamente fissato al 
	più piccolo fra 
	<math>T</math>/2 e <math>T</math><sup>0.6</sup>.
      </para>
      <para>
	I risultati possono essere recuperati usando gli accessori
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>. Questi valori sono
	basati sullo stimatore locale di Whittle a meno che non sia
	stata indicata l'opzione <opt>gph</opt>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Unit root tests/Fractional integration</menu-path>
    </gui-access>

  </command>

  <command name="freq" section="Statistics" label="Distribuzione di frequenza">

    <usage>
      <arguments>
        <argument>variabile</argument>
      </arguments>
      <options>
        <option>
	  <flag>--nbins</flag>
	  <optparm>n</optparm>
	  <effect>specifica il numero di intervalli</effect>
        </option>
        <option>
	  <flag>--min</flag>
	  <optparm>minval</optparm>
	  <effect>specifica il valore minimo, v. oltre</effect>
        </option>
        <option>
	  <flag>--binwidth</flag>
	  <optparm>width</optparm>
	  <effect>specifica l'ampiezza degli intervalli, v. oltre</effect>
        </option>
        <option>
         <flag>--quiet</flag>
         <effect>non mostra il grafico</effect>
        </option>
        <option>
         <flag>--normal</flag>
         <effect>test per la distribuzione normale</effect>
        </option>
        <option>
         <flag>--gamma</flag>
         <effect>test per la distribuzione gamma</effect>
        </option>
        <option>
         <flag>--silent</flag>
         <effect>non mostra nulla</effect>
        </option>
        <option>
	  <flag>--show-plot</flag>
	  <effect>v. oltre</effect>
        </option>
        <option>
	  <flag>--matrix</flag>
	  <optparm>nome</optparm>
	  <effect>usa una colonna di una matrice indicata per nome</effect>
        </option>
      </options>
      <examples>
        <example>freq x</example>
	<example>freq x --normal</example>
	<example>freq x --nbins=5</example>
	<example>freq x --min=0 --binwidth=0.10</example>
      </examples>
    </usage>

    <description context="cli">
      <para>
        Se non vengono indicate opzioni, mostra la distribuzione di
        frequenza per la <repl>variabile</repl> (indicata con il nome
        o il numero).
      </para>
      <para>
	Se viene indicata l'opzione <opt>matrix</opt>, <repl>var</repl>
	(che deve essere un intero) viene invece interpretato come un indice
	di base 1 che individua una colonna in una matrice indicata per nome.
      </para>
      <para>
	Per controllare la presentazione della distribuzione è
	possibile specificare <emphasis>o</emphasis> il numero di
	intervalli o il valore minimo più l'ampiezza degli intervalli,
	come illustrato negli ultimi due esempi precedenti. L'opzione
	<opt>min</opt> fissa il limite inferiore dell'intervallo più
	a sinistra.
      </para>
      <para>
       Usando l'opzione <opt>normal</opt>, vengono mostrati i
       risultati del test chi-quadro di Doornik&ndash;Hansen per la
       normalità.  Usando l'opzione <opt>gamma</opt>, al posto del
       test di normalità viene eseguito il test non parametrico di
       Locke per l'ipotesi nulla che la variabile segua la
       distribuzione gamma; si veda <cite key="locke76">Locke
       (1976)</cite>, <cite key="shapiro-chen01">Shapiro e Chen
       (2001)</cite>. Si noti che la parametrizzazione della
       distribuzione gamma in gretl è (forma, scala).
      </para>
      <para>
        In modalità interattiva viene mostrato anche un grafico della
        distribuzione, a meno che non si usi l'opzione
        <opt>quiet</opt>. Per converso, il grafico non viene
        mostrato quando il comando è invocato da script, a meno che
        non venga usata l'opzione <opt>show-plot</opt>. (Questo non
        si applica alla versione di gretl a linea di comando,
        <lit>gretlcli</lit>.)
      </para>
      <para>
       L'opzione <opt>silent</opt> sopprime interamente l'output
       mostrato di solito. Ha senso usarla insieme a una delle opzioni
       riguardanti la distribuzione: in questo modo la statistica test
       e il suo p-value verranno salvati nelle variabili accessorie
       <fncref targ="$test"/> e <fncref targ="$pvalue"/>.
      </para>
    </description>
 
    <description context="gui">
      <para>
        Nella finestra di dialogo della distribuzione di frequenza è
        possibile controllare le caratteristiche del grafico in due
        modi diversi.
      </para>
      <para>
	Per prima cosa è possibile scegliere il numero di intervalli;
	in questo caso la larghezza e la posizione degli intervalli
	sono calcolate automaticamente.
      </para>
      <para>
        In alternativa, è possibile specificare il limite inferiore del primo
        intervallo e la larghezza degli intervalli; in questo caso il numero di
        intervalli viene calcolato automaticamente.
      </para>
      <para>
        Se si vuole che gli intervalli corrispondano a numeri interi, è
        possibile procedere in questo modo: iniziare specificando il numero di
        intervalli, controllare il grafico prodotto, prendere nota delle
        modifiche da fare (ad esempio impostare l'inizio del primo intervallo al
        valore 100 e la larghezza pari a 200), quindi ricreare il grafico
        specificando i valori scelti.
      </para>
      <para>
	Questa finestra permette inoltre di scegliere una distribuzione teorica
        da sovrapporre ai dati: la normale o la gamma. Se si sceglie la
        distribuzione normale, viene calcolato il test di normalità di
	Doornik&ndash;Hansen. Se si sceglie la gamma, gretl calcola il test
        non parametrico di Locke per l'ipotesi nulla che la variabile segua
        questa distribuzione. Si noti che la parametrizzazione della
        distribuzione gamma in gretl è (forma, scala).
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Distribuzione di frequenza</menu-path>
    </gui-access>

  </command>

  <command name="function" section="Programming" label="Definisce una funzione" context="cli">

    <usage>
      <arguments>
        <argument>nome_funzione</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Apre un blocco di istruzioni che definiscono una funzione. Il blocco va
        chiuso con <lit>end function</lit>. Per i dettagli, si veda
        la <guideref targ="chap:functions"/>.
      </para>
    </description>

  </command>  

  <command name="garch" section="Estimation" label="Stima GARCH">

    <usage>
      <arguments>
        <argument>p</argument>
	<argument>q</argument>
	<argument separated="true">variabile-dipendente</argument>
	<argument optional="true">variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
         <option>
	  <flag>--nc</flag>
	  <effect>non include una costante</effect>
        </option>
        <option>
	  <flag>--stdresid</flag>
	  <effect>standardizza i residui</effect>
        </option>
        <option>
	  <flag>--fcp</flag>
	  <effect>usa l'algoritmo di Fiorentini, Calzolari e Panattoni</effect>
        </option>
        <option>
	  <flag>--arma-init</flag>
	  <effect>parametri di varianza iniziale da ARMA</effect>
        </option>
      </options>
      <examples>
        <example>garch 1 1 ; y</example>
	<example>garch 1 1 ; y 0 x1 x2 --robust</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Stima un modello GARCH (Generalized Autoregressive
	Conditional Heteroskedasticity) univariato, o, se sono specificate delle
	<repl>variabili-indipendenti</repl>, includendo delle variabili esogene.
	I valori interi <repl>p</repl> e <repl>q</repl> (che possono essere
        indicati in forma numerica o col nome di variabili scalari preesistenti)
        rappresentano gli ordini di ritardo nell'equazione della varianza
        condizionale.
	<equation status="display"
	  tex="\[h_t = \alpha_0 + \sum_{i=1}^q \alpha_i \varepsilon^2_{t-i} +
	  \sum_{j=1}^p \beta_j h_{t-j}\]"
	  ascii="h(t) = a(0) + somma(per i da 1 a q) a(i)*u(t-i)^2 + somma( per j da 1 a p) b(j)*h(t-j)"
	  graphic="garch_h"/>
      </para>
      <para context="cli">
	Il parametro <repl>p</repl> rappresenta quindi l'ordine generalizzato
	(o <quote>AR</quote>), mentre <repl>q</repl> rappresenta il consueto
        ordine ARCH (o <quote>MA</quote>). Se <repl>p</repl> è diverso da zero,
	anche <repl>q</repl> deve essere diverso da zero, altrimenti il modello
        non è identificato. Comunque, è possibile stimare un modello ARCH
        consueto impostando <repl>q</repl> a un valore positivo e <repl>p</repl>
        a zero. La somma di <repl>p</repl> e <repl>q</repl> non deve superare 5.
        Si noti che nell'equazione della media viene automaticamente inclusa una
        costante, a meno che non si usi l'opzione <opt>nc</opt>.
      </para>

      <para context="gui">
        Stima un modello GARCH (Generalized Autoregressive Conditional
        Heteroskedasticity) univariato, o, se sono specificate delle
        variabili-indipendenti, includendo delle variabili esogene.
	L'equazione della varianza condizionale è la seguente:
	<equation status="display" tex="\[h_t = \alpha_0 + 
	\sum_{i=1}^q \alpha_i \varepsilon^2_{t-i} + \sum_{j=1}^p
	\beta_i h_{t-j}\]" ascii="h(t) = a(0) + somma (i da 1 a q) a(i)*u(t-i) +
	somma(j da 1 a p) b(j)*h(t-j)" graphic="garch_h"/>
      </para>
      <para context="gui">
	Il parametro <repl>p</repl> rappresenta quindi l'ordine generalizzato
	(o <quote>AR</quote>), mentre <repl>q</repl> rappresenta il consueto
        ordine ARCH (o <quote>MA</quote>). Se <repl>p</repl> è diverso da zero,
	anche <repl>q</repl> deve essere diverso da zero, altrimenti il modello
        non è identificato. Comunque, è possibile stimare un modello ARCH
        consueto impostando <repl>q</repl> a un valore positivo e <repl>p</repl>
        a zero. La somma di <repl>p</repl> e <repl>q</repl> non deve superare 5.
      </para>

      <para>
        Per impostazione predefinita, i modelli GARCH vengono stimati usando il
        codice nativo gretl, ma è anche possibile usare l'algoritmo di
        Fiorentini, Calzolari e Panattoni (1996). Il primo usa il massimizzatore
        BFGS, mentre il secondo usa la matrice di informazione per massimizzare
        la verosimiglianza, con un raffinamento usando l'Hessiana.
      </para>

      <para context="cli">
        Sono disponibili varie stime della matrice di covarianza dei
        coefficienti. Il metodo predefinito è quello dell'Hessiana, a meno che
        non si usi l'opzione <opt>robust</opt>, nel qual caso viene usata la
        matrice di covarianza QML (White).  Altre possibilità (ad es. la matrice
        di informazione, o lo stimatore di Bollerslev&ndash;Wooldridge) possono
        essere specificate con il comando <cmdref targ="set"/>.
      </para>

      <para context="gui">
        Sono disponibili varie stime della matrice di covarianza dei
        coefficienti. Il metodo predefinito è quello dell'Hessiana, a meno di
        non selezionare la casella <quote>Errori standard robusti</quote>, nel
        qual caso viene usata la matrice di covarianza QML (White). Altre
        possibilità (ad es. la matrice di informazione, o lo stimatore di
        Bollerslev&ndash;Wooldridge) possono essere specificate con il comando
        <cmdref targ="set"/>.
      </para>

      <para context="gui">La varianza condizionale stimata, insieme ai
      residui e ad altre statistiche del modello, può essere
      richiamata ed aggiunta al dataset usando il menù
      <quote>Analisi</quote> presente nella finestra del modello. Se
      viene spillata la casella <quote>Standardizza i residui</quote>,
      i resuidi vengono divisi per la radice della varianzqa
      condizionale stimata.
      </para>

      <para context="cli">
	In modalità predefinita, le stime dei parametri di varianza
	sono inizializzate usando la varianza dell'errore non
	condizionale, ottenuta dalla stima OLS iniziale, per la
	costante, e piccoli valori positivi per i coefficienti dei
	valori passati dell'errore al quadrato e per la varianza
	dell'errore. L'opzione <lit>--arma-init</lit> fa in modo che i
	valori iniziali per questi parametri siano ricavati da un
	modello ARMA iniziale, sfruttando la relazione tra GARCH e
	ARMA mostrata nel capitolo 21 di <book>Time Series
	Analysis</book> di Hamilton.  In alcuni casi, questo metodo
	può aumentare le probabilità di convergenza.
      </para>

      <para context="cli">
        I residui GARCH e la varianza condizionale stimata sono memorizzate
        rispettivamente nelle variabili <fncref targ="$uhat"/> e <fncref targ="$h"/>. Ad
        esempio, per ottenere la varianza condizionale è possibile scrivere: 
        </para>
      <code context="cli">
        genr ht = $h
      </code>
      <para context="cli">
	Con l'opzione <opt>stdresid</opt>, i valori di <fncref targ="$uhat"/>
	vengono divisi per la radice di <math>h</math><sub>t</sub>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/GARCH</menu-path>
    </gui-access>

  </command>

  <command name="genr" section="Dataset"
    label="Generazione di una nuova variabile">

    <usage>
      <arguments>
        <argument>nuova-variabile</argument>
        <argument>= formula</argument>
      </arguments>
    </usage>

    <description>
      <para>
	NOTA: questo comando ha subito molti cambiamenti e migliorie
	da quando l'help seguente è stato scritto, per cui per
	informazioni complete e aggornate consigliamo di far
	riferimento alla <guideref targ="chap:genr"/>. D'altro canto,
	il testo che segue non contiene informazioni erronee, per cui
	può essere interpretato come <quote>questo ed altro</quote>.
      </para>

      <para>
	In contesti appropriati, <lit>series</lit>, <lit>scalar</lit>
	e <lit>matrix</lit> sono sinonimi per questo comando.
      </para>
      <para context="cli">
	Crea nuove variabili, di solito per mezzo di trasformazioni di
	variabili esistenti. Si veda anche <cmdref targ="diff"/>,
	<cmdref targ="logs"/>, <cmdref targ="lags"/>, <cmdref
	targ="ldiff"/>, <cmdref targ="sdiff"/> e <cmdref
	targ="square"/> per alcune scorciatoie. Nel contesto di una
	formula <lit>genr</lit>, le variabili esistenti devono essere
	referenziate per nome, non per numero identificativo. La
	formula dev'essere una combinazione ben definita di nomi di
	variabile, costanti, operatori e funzioni (descritte
	oltre). Ulteriori dettagli su alcuni aspetti di questo comando
	si possono trovare nella <guideref targ="chap:genr"/>.
      </para>

      <para context="gui">
	Usate questa riga per definire una nuova variabile seguendo lo schema 
	<repl>nome</repl> = <repl>formula</repl>.  La formula dovrebbe essere 
	una combinazione sintatticamente corretta di nomi di variabili, 
	operatori e funzioni (v. oltre per ulteriori dettagli). Per essere sicuri
	di ottenere una variabile del tipo desiderato è possibile premettere alla
	formula il nome di un tipo, &eg;
	<lit>scalar</lit>, <lit>series</lit> o <lit>matrix</lit>.  Per esempio, 
	per creare una variabile con un valore costante pari a 10 possiamo digitare
      </para>
      <code context="gui">
	series c = 10
      </code>
      <para context="gui">
	(in caso contrario <lit>c = 10</lit> creerebbe una variabile scalare).
      </para>

      <para>
	Il comando <lit>genr</lit> può produrre come risultato una serie o uno scalare. Ad
        esempio, la formula <lit>x2 = x * 2</lit> produce una serie se la variabile
	<lit>x</lit> è una serie e uno scalare se <lit>x</lit> è uno scalare.
        Le formule <lit>x = 0</lit> e <lit>mx = mean(x)</lit> producono degli
        scalari. In alcune circostanze, può essere utile che un risultato
        scalare sia espanso in una serie o in un vettore: è possibile ottenere
        questo risultato usando <lit>series</lit> come <quote>alias</quote> per il comando
	<lit>genr</lit>. Ad esempio, <lit>series x = 0</lit> produce una
	serie con tutti i valori pari a 0. Allo stesso modo, è possibile usare
        <lit>scalar</lit> come alias per <lit>genr</lit>, ma non è possibile
        forzare un risultato vettoriale in uno scalare: con questa parola chiave
        si indica che il risultato <emphasis>dovrebbe essere</emphasis> uno scalare;
        se non lo è, viene emesso un messaggio di errore.
      </para>

      <para>
        Quando una formula produce come risultato una serie,
        l'intervallo su cui essi sono definiti dipende
        dall'impostazione attuale del campione. È quindi possibile
        definire una serie a pezzi, alternando l'uso dei comandi
        <lit>smpl</lit> e <lit>genr</lit>.
      </para>

      <para>
        Gli <emphasis>operatori aritmetici</emphasis> supportati sono, in
        ordine di precedenza: <lit>^</lit> (esponenziale); <lit>*</lit>,
        <lit>/</lit> e <lit>%</lit> (modulo o resto); <lit>+</lit> e
        <lit>-</lit>. 
      </para>

      <para>
	Gli <emphasis>operatori Booleani</emphasis> disponibili sono
	(ancora in ordine di precedenza): <lit>!</lit> (negazione),
	<lit>&amp;&amp;</lit> (AND logico), <lit>||</lit> (OR logico),
	<lit>&gt;</lit>, <lit>&lt;</lit>, <lit>=</lit>,
	<lit>&gt;=</lit> (maggiore o uguale), <lit>&lt;=</lit>
	(minore o uguale) e <lit>!=</lit> (disuguale).  Gli operatori
	Booleani possono essere usati per costuire variabili dummy:
	ad esempio <lit>(x > 10)</lit> produce 1 se <lit>x</lit>
	&gt; 10, 0 altrimenti.</para>
 
      <para>
        Le costanti predefinite sono <lit>pi</lit> e <lit>NA</lit>. L'ultima
        rappresenta il codice per i valori mancanti: è possibile inizializzare
        una variabile con valori mancanti usando <lit>scalar x = NA</lit>.
      </para>

      <para>
 	Il comando <lit>genr</lit> supporta un'ampia gamma di funzioni
        matematiche e statistiche, da quelle più comuni a quelle di uso
        specifico in econometria. Inoltre offre l'accesso a numerose variabili
        interne che vengono definite nel corso della stima di regressioni,
        dell'esecuzione di test, e così via.
	<refnote xref="false"> 
	  Per un elenco delle funzioni e degli accessori, eseguire:
	  <quote>help functions</quote>. 
	</refnote> 
	<refnote xref="true">
	  Per un elenco delle funzioni e degli accessori, si veda:
	  <gfr targ="chap:funcref"/>. 
	</refnote>
      </para>
      
      <para>
        Oltre agli operatori e alle funzioni mostrati, ci sono alcuni
        usi speciali del comando <cmd>genr</cmd>:
      </para>

      <ilist>
	<li><para><cmd>genr time</cmd> crea una variabile trend temporale
	    (1,2,3,&hellip;) chiamata <cmd>time</cmd>.
            <cmd>genr index</cmd> fa la stessa cosa, ma chiamando la variabile
	    <lit>index</lit>.</para>
	</li>
	<li>
          <para>
            <cmd>genr dummy</cmd> crea una serie di variabili dummy a seconda
            della periodicità dei dati. Ad esempio, nel caso di dati trimestrali
            (periodicità 4) il programma crea <lit>dq1</lit>, che vale 1 
            nel primo trimestre e 0 altrove, <lit>dq2</lit> che vale 1
            nel secondo trimestre e 0 altrove, e così via. Nel caso di dati
            mensili, le dummy si chiamano <lit>dm1</lit>, <lit>dm2</lit> e così
            via. Con altre frequenze dei dati, i nomi delle dummy sono <lit>dummy_1</lit>,
            <lit>dummy2</lit>, ecc.
          </para>
	</li>
        <li><para><cmd>genr unitdum</cmd> e <cmd>genr timedum</cmd> creano insiemi di
            variabili dummy speciali da usare in un dataset di tipo panel. Il
            primo comando crea dummy che rappresentano le unità cross section,
            il secondo i periodi di osservazione.
	    </para>
	</li>
      </ilist>

      <para>
	<emphasis>Nota</emphasis>: nella versione a riga di comando del programma,
        i comandi <cmd>genr</cmd> che estraggono dati relativi al modello
	si riferiscono sempre al modello stimato per ultimo. Questo vale anche
        per la versione grafica del programma se si usa <cmd>genr</cmd> nel
        <quote>terminale di gretl</quote> o si immette una formula usando
        l'opzione <quote>Definisci nuova variabile</quote> nel menù Variabile
        della finestra principale. Usando la versione grafica, però, è
        possibile anche estrarre i dati da qualunque modello mostrato in una
        finestra (anche se non è il modello più recente) usando il menù
        <quote>Analisi</quote> nella finestra del modello.
      </para>

      <para>
        La variabile speciale <lit>obs</lit> serve da indice per le
        osservazioni.  Ad esempio, <lit>genr dum = (obs=15)</lit> crea
        una variabile dummy che vale 1 per l'osservazione 15 e 0
        altrove. È anche possibile usare questa variabile per
        selezionare alcune osservazioni particolari secondo la data o
        il nome. Ad esempio <lit>genr d = (obs&gt;1986:4)</lit>,
        <lit>genr d = (obs&gt;"2008/04/01")</lit>, <lit>genr d =
        (obs="CA")</lit>.  Quando si usano in questo contesto date
        giornaliere o etichette per le osservazioni, bisogna
        racchiuderle fra virgolette.  Questo non è necessario per date
	trimestrali o annuali. Si noti che, per serie storiche
	annuali, l'anno non è sintatticmante distiguibile da un
	sempilce intero; per cui, per confrontare un'osservazione con
	<lit>obs</lit> per anno, bisogna usare la funzione
	<lit>obsnum</lit> per convertire l'anno in un numero
	progressivo, come ad esempio in in <lit>genr d =
        (obs&gt;obsnum(1986))</lit>.
      </para>

      <para>
        È possibile estrarre dei valori scalari da una serie usando
        una formula <lit>genr</lit> con la sintassi
	<repl>nome-variabile</repl><lit>[</lit><repl>osservazione</repl><lit>]</lit>.
	Il valore di <repl>osservazione</repl> può essere specificato con
        un numero o una data.
	Esempi: <lit>x[5]</lit>, <lit>CPI[1996:01]</lit>.  Per i dati
        giornalieri occorre usare la forma <repl>AAAA/MM/GG</repl>, ad esempio
	<lit>ibm[1970/01/23]</lit>.
      </para>

      <para>
        È possibile modificare una singola osservazione in una serie
        usando <lit>genr</lit>. Per farlo, occorre aggiungere un numero
        di osservazione o una data valida tra parentesi quadre al nome
	della variabile nel lato sinistro della formula. Ad esempio:
	<lit>genr x[3] = 30</lit> o <lit>genr x[1950:04] =
	303.7</lit>.
      </para>

      <table id="tab-genr" title="Esempi di utilizzo del comando genr"
	lhead="Formula" rhead="Commento"
	lwidth="100pt" rwidth="300pt" 
	style="rpara">
	<row>
	  <cell><lit>y = x1^3</lit></cell>
	  <cell><lit>x1</lit> al cubo</cell>
	</row>          
	<row>
	  <cell><lit>y = ln((x1+x2)/x3)</lit></cell>
	  <cell></cell>
	</row>
	<row>
	  <cell><lit>z = x&gt;y</lit></cell>
	  <cell><lit>z(t)</lit> = 1 se <lit>x(t) &gt; y(t)</lit>,
	    0 altrove</cell>
	</row> 
	<row>
	  <cell><lit>y = x(-2)</lit></cell>
	  <cell><lit>x</lit> ritardata di 2 periodi</cell>
	</row>     
	<row>
	  <cell><lit>y = x(+2)</lit></cell>
	  <cell><lit>x</lit> anticipata di 2 periodi</cell>
	</row>
	<row>
	  <cell><lit>y = diff(x)</lit></cell>
	  <cell><lit>y(t) = x(t) - x(t-1)</lit></cell>
	</row>
	<row>
	  <cell><lit>y = ldiff(x)</lit></cell>
	  <cell><lit>y(t) = log x(t) - log x(t-1)</lit>, il
            tasso di crescita istantaneo di <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>y = sort(x)</lit></cell>
	  <cell>ordina <lit>x</lit> in senso crescente e la salva in
	    <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>y = dsort(x)</lit></cell>
	  <cell>ordina <lit>x</lit> in senso decrescente</cell>
	</row>
	<row>
	  <cell><lit>y = int(x)</lit></cell>
	  <cell>tronca <lit>x</lit> e salva il valore intero in
	    <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>y = abs(x)</lit></cell>
	  <cell>salva il valore assoluto di <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>y = sum(x)</lit></cell>
	  <cell>somma i valori di <lit>x</lit> escludendo i valori mancanti <lit>NA</lit></cell>
	</row>
	<row>
	  <cell><lit>y = cum(x)</lit></cell>
	  <cell>cumulativa: 
		<equation status="inline"
		  tex="$y_t = \sum_{\tau=1}^t x_{\tau}$"
		  ascii="y(t) = somma di x(s) per s da 1 a t"
		  graphic="cumulate"/>
	  </cell>
	</row>
	<row>
	  <cell><lit>aa = $ess</lit></cell>
	  <cell>imposta <lit>aa</lit> uguale alla somma dei quadrati degli errori
            dell'ultima regressione</cell>
	</row>
	<row>
	  <cell><lit>x = $coeff(sqft)</lit></cell>
	  <cell>estrae il coefficiente stimato per la variabile
	    <lit>sqft</lit> nell'ultima regressione</cell>
	</row>
	<row>
	  <cell><lit>rho4 = $rho(4)</lit></cell>
	  <cell>estrae il coefficiente di autoregressione del quarto
            ordine dall'ultimo modello (presume un modello
            <lit>ar</lit> model)</cell>
	</row>
	<row>
	  <cell><lit>cvx1x2 = $vcv(x1, x2)</lit></cell>
	  <cell>estrae il coefficiente di covarianza stimato tra le
            variabili <lit>x1</lit> e <lit>x2</lit> dall'ultimo modello</cell>
	</row>
	<row>
	  <cell><lit>foo = uniform()</lit></cell>
	  <cell>variabile pseudo-casuale uniforme nell'intervallo
	    0&ndash;1</cell>
	</row>
	<row>
	  <cell><lit>bar = 3 * normal()</lit></cell>
	  <cell>variabile pseudo-casuale normale con &mu; = 0, &sigma; =
	    3</cell>
	</row>
	<row>
	  <cell><lit>samp = ok(x)</lit></cell>
	  <cell>vale 1 per le osservazioni dove il valore di <lit>x</lit>
            non è mancante.</cell>
	</row>
      </table>

    </description>

    <gui-access>
      <menu-path>/Variabile/Definisci nuova variabile</menu-path>
      <other-access>Menù pop-up nella finestra principale</other-access>
    </gui-access>

  </command>

  <command name="genrand" section="Programming" context="gui"
    label="Generazione di variabili casuali">

    <description>
      <para>
        In questa finestra occorre specificare il nome da dare alla
        variabile da generare, seguito da alcune informazioni aggiuntive
        che dipendono dal tipo di distribuzione.
      </para>

      <ilist>
	<li>
	  <para>
	    Uniforme: limite superiore e inferiore per la distribuzione.
	  </para>
	</li>
	<li>
	  <para>
	    Normale: la media e lo scarto quadratico medio (deve essere positivo).
	  </para>
	</li>
	<li>
	  <para>
	    Chi-quadro e t di Student: i gradi di libertà (devono essere positivi).
	  </para>
	</li>
        <li>
          <para>
	    F: gradi di libertà al numeratore e denominatore.
          </para>
        </li>
        <li>
          <para>
            Gamma: parametri di forma e scala (entrambi positivi).
          </para>
        </li>
        <li>
          <para>
            Binomiale: numero di prove (un intero positivo)
            e la probabilità di <quote>successo</quote>.
          </para>
        </li>
        <li>
          <para>
            Poisson: la media (che è pari anche alla varianza).
          </para>
        </li>

      </ilist>

      <para>
	Se occorre generare sequenze ripetibili di numeri pseudo-casuali, è
        possibile impostare il seme del generatore, nel menù Strumenti.
      </para>

    </description>
  </command>

  <command name="genseed" section="Programming" context="gui"
    label="Impostare il seme per i numeri casuali">

    <description>
      <para>
	Il "seme" rappresenta il punto di partenza per la sequenza di numeri
        pseudo-casuali generati in una sessione di gretl. Per impostazione
        predefinita, il seme viene impostato all'avvio del programma, basandosi
        sull'orologio di sistema. Ciò fa sì che si ottenga una diversa sequenza
        di numeri casuali ogni volta che si usa il programma; se invece si vuole
        usare sequenze ripetibili di numeri, occorre impostare manualmente il
        seme (e ricordarsi il valore usato).
      </para>
      <para>
	Si noti che il generatore viene re-impostato ogni volta che si fa clic
        sul pulsante "OK" di questa finestra di dialogo, quindi, ad esempio,
	se si imposta il seme a 147, si genera una serie dalla distribuzione
        normale standard, si riapre questa finestra di dialogo e si fa clic su
        "OK" indicando ancora 147 come seme, e infine si genera una seconda
        serie dalla normale standard, le due serie generate saranno identiche.
      </para>
    </description>
  </command>

  <command name="gmm" section="Estimation" label="Stima GMM">

    <usage>
      <options>
	<option>
	  <flag>--two-step</flag>
	  <effect>Stima a due passi</effect>
	</option>
	<option>
	  <flag>--iterate</flag>
	  <effect>GMM iterato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>Mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>Mostra i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa il massimizzatore L-BFGS-B anziché il BFGS standard</effect>
	</option>
      </options>
    </usage>

    <description>

      <para>
        Esegue la stima col metodo dei momenti generalizzato (Generalized Method
        of Moments, GMM) usando l'algoritmo BFGS (Broyden, Fletcher, Goldfarb,
        Shanno). Occorre specificare uno o più comandi per aggiornare le
        quantità rilevanti (tipicamente i residui GMM), una o più condizioni di
        ortogonalità, una matrice iniziale dei pesi e un elenco dei parametri da
        stimare, il tutto racchiuso tra le parole chiave
	<lit>gmm</lit> e <lit>end gmm</lit>.
      </para>
      <para>
	Si veda la <guideref targ="chap:gmm"/> per i dettagli. Quello che segue
        è un semplice esempio illustrativo.
      </para>
      <code>
	gmm e = y - X*b
	  orthog e ; W
	  weights V
	  params b
	end gmm
      </code>
      <para>
	Nell'esempio si assume che <lit>y</lit> e <lit>X</lit> siano matrici di
        dati, <lit>b</lit> sia un vettore con i valori dei parametri, <lit>W</lit>
        sia una  matrice di strumenti, e <lit>V</lit> un'appropriata matrice dei pesi.
        La dichiarazione
      </para>
      <code>
	orthog e ; W
      </code>
      <para>
	indica che il vettore dei residui <lit>e</lit> è in linea di principio
        ortogonale ad ognuno degli strumenti che compongono le colonne di
	<lit>W</lit>.
      </para>

    </description>
 
    <gui-access>
      <menu-path>/Modello/GMM</menu-path>
    </gui-access>

  </command>

  <command name="gnuplot" section="Graphs" label="Crea un grafico Gnuplot" context="cli">

    <usage>
      <arguments>
        <argument>variabili-y</argument>
        <argument>variabile-x</argument>
	<argument optional="true">variabile-dummy</argument>
      </arguments>
      <options>
        <option>
	  <flag>--with-lines</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee invece che punti</effect>
        </option>
        <option>
	  <flag>--with-lp</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee e punti</effect>
        </option>
        <option>
	  <flag>--with-impulses</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee verticali</effect>
        </option>
        <option>
	  <flag>--time-series</flag>
	  <effect>mostra rispetto al tempo</effect>
        </option>
        <option>
	  <flag>--suppress-fitted</flag>
	  <effect>non mostra la linea stimata</effect>
        </option>
        <option>
	  <flag>--single-yaxis</flag>
	  <effect>forza l'uso di un solo asse delle ordinate</effect>
        </option>
        <option>
	  <flag>--linear-fit</flag>
	  <effect>mostra fit minimi quadrati</effect>
        </option>
        <option>
	  <flag>--inverse-fit</flag>
	  <effect>mostra fit inverso</effect>
        </option>
        <option>
	  <flag>--quadratic-fit</flag>
	  <effect>mostra fit quadratico</effect>
        </option>
        <option>
	  <flag>--cubic-fit</flag>
	  <effect>mostra fit cubico</effect>
        </option>
        <option>
	  <flag>--loess-fit</flag>
	  <effect>mostra fit non-parametrico</effect>
        </option>
        <option>
	  <flag>--semilog-fit</flag>
	  <effect>mostra fit semilogaritmico</effect>
        </option>
        <option>
	  <flag>--dummy</flag>
	  <effect>si veda sotto</effect>
        </option>
        <option>
	  <flag>--matrix</flag>
	  <optparm>name</optparm>
	  <effect>mostra le colonne di una data matrice</effect>
        </option>
        <option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>ridirige l'output su file</effect>
        </option>
        <option>
	  <flag>--input</flag>
	  <optparm>filename</optparm>
	  <effect>prende l'input da file</effect>
        </option>
      </options>
      <examples>
        <example>gnuplot y1 y2 x</example>
        <example>gnuplot x --time-series --with-lines</example>
	<example>gnuplot wages educ gender --dummy</example>
	<example>gnuplot y1 y2 x --with-lines=y2</example>
      </examples>
    </usage>

    <description>
       <para>
 	Le variabili nella lista <repl>variabili-y</repl> vengono
 	mostrate rispetto alla variabile <repl>variabile-x</repl>. Per
 	avere un grafico storico è possibile usare <lit>time</lit>
 	come <repl>variabile-x</repl>, oppure usare l'opzione
 	<lit>--time-series</lit>.
       </para>
      <para>
	Per default, i dati sono mostrati come punti; ma questa scelta
	può essere modificata usando una delle opzioni
	<opt>with-lines</opt>, <opt>with-lp</opt> or
	<opt>with-impulses</opt>. Se il grafico contiene più di una
	serie, l'effetto di queste opzioni può essere limitato ad un
	sottoinsieme delle variabili usando il parametro
	<repl>varspec</repl>. Esso deve essere dato sotto forma di una
	lista separata da virgole dei nomi (o dei numeri) delle
	variabili da tracciare con linee e/o con impulsi. L'esempio
	più sotto mostra come tracciare <lit>y1</lit> e <lit>y2</lit>
	contro <lit>x</lit>, in modo tale che <lit>y2</lit> sia
	rappresentata da una linea ma <lit>y1</lit> da punti.
      </para>

      <para>
 	Usando l'opzione <opt>dummy</opt>, occorre fornire
 	esattamente tre variabili: una variabile <math>y</math>, una
 	variabile <math>x</math>, e una variabile dummy
 	<repl>dumvar</repl>. L'effetto è quello di mostrare
 	<repl>y</repl> rispetto a <repl>x</repl> colorando in modo
 	diverso i vari punti, a seconda che <repl>dumvar</repl> valga
 	1 o 0.
      </para>

       <para>
	In generale è necessario specificare sia l'argomento <repl>yvars</repl> 
	che quello <repl>xvar</repl>; entrambi devono indicare variabili
	nel dataset corrente (per nome o numero identificativo). Se tuttavia 
	viene specificata con l'opzione <opt>matrix</opt> una matrice definita 
	in precedenza questi argomenti diventano opzionali: se la matrice
	specificata ha <math>k</math> colonne, di default le prime <math>k</math>
	&minus; 1 sono considerate come <repl>yvars</repl>, e l'ultima come 
	<repl>xvar</repl>. Se viene indicata l'opzione <opt>time-series</opt>, 
	tuttavia, il comando fornisce il grafico di tutte le <math>k</math> 
	variabili rispetto al tempo. Se si desidera il grafico solo di alcune
	colonne della matrice è necessario identificare 
	<repl>yvars</repl> e <repl>xvar</repl> fornendo l'indice delle colonne 
	corrispondenti, dove la prima colonna ha indice 1. Per esempio, 
	se si desidera un grafico a dispersione della colonna 2 della 
	matrice <lit>M</lit> rispetto alla colonna 1, il comando da digitare è:
      </para>
      <code>
	gnuplot 2 1 --matrix=M
      </code>

      <para>
	In modalità interattiva il risultato è mostrato
	immediatamente.  In modalità <quote>batch</quote>, viene
	scritto un file di comandi gnuplot, chiamato
	<filename>gpttmpN.plt</filename>, a partire da N =
	<lit>01</lit>; il grafico vero e proprio può essere generato
	usando il programma <program>gnuplot</program> (su MS Windows:
	<program>wgnuplot</program>).  Questo comportamento può essere
	modificato usando l'opzione
	<opt>output=</opt><repl>filename</repl>, che controlla il
	nome del file utilizzato e contemporaneamente permette di
	specificare un particolare formato di output usando
	l'estensione del nome del file (le tre lettere che seguono il
	.): <lit>.eps</lit> produce un file Encapsulated PostScript
	(EPS); <lit>.pdf</lit> produce un file PDF; <lit>.png</lit>
	produce un formato PNG, <lit>.emf</lit> un formato EMF
	(Enhanced MetaFile), <lit>.fig</lit> un file Xfig, e
	<lit>.svg</lit> uno SVG (Scalable Vector Graphics). Se come
	nome del file si indica <quote><lit>display</lit></quote>, il
	grafico è inviato allo schermo come nella modalità
	interattiva.  Se si indica un nome del file con un'estensione
	diversa da quelle appena citate viene prodotto un file di
	comandi gnuplot.
      </para>

      <para>
	Le varie opzioni <quote>fit</quote> si applicano solo nel caso di un
        diagramma a dispersione bivariato. Il comportamento predefinito consiste
        nel mostrare la linea con le stime OLS, se e solo se il coefficiente di
        pendenza è significativo almeno al 10 per cento. Se si usa l'opzione
	<lit>suppress</lit> non viene mostrata alcuna linea.
        Se si usa l'opzione <lit>linear</lit>, la linea OLS viene mostrata a
        prescindere dalla sua significatività. Le altre opzioni
        (<lit>inverse</lit>, <lit>quadratic</lit> e <lit>loess</lit>) mostrano
        rispettivamente un fit inverso (la regressione di <math>y</math>
        su 1/<math>x</math>), un fit quadratico o un fit loess (chiamato
        a volte anche <quote>lowess</quote>, una regressione robusta con pesi locali).
      </para>

      <para>È disponibile un'ulteriore opzione per questo comando: dopo la
        specificazione delle variabili e le eventuali opzioni, è possibile
        aggiungere direttamente dei comandi gnuplot per modificare l'aspetto
        visivo del grafico (ad esempio, impostando il titolo e o gli intervalli
        degli assi). Questi comandi aggiuntivi vanno inclusi tra parentesi
        graffe e ogni comando va separato con un punto e virgola; è possibile
        usare una barra rovesciata (<lit>\</lit>) per continuare un gruppo di
        comandi gnuplot sulla riga successiva. Ecco un esempio della sintassi:
      </para>

      <code>
	{ set title 'Il mio titolo'; set yrange [0:1000]; }
      </code>

    </description>

    <gui-access>
      <menu-path>/Visualizza/Grafico</menu-path>
      <other-access>Menù pop-up nella finestra principale, pulsante grafico sulla barra degli strumenti</other-access>
    </gui-access>

  </command>

  <command name="graphing" section="Graphs" context="gui"
    label="Grafici">

    <description>

      <para>
        Gretl richiama un programma separato, gnuplot, per generare i
        grafici. Gnuplot è un programma di grafica molto completo, con
        una miriade di opzioni; gretl fornisce l'accesso, attraverso
        un'interfaccia grafica, a una parte di queste opzioni,
        cercando di scegliere dei valori, ma è possibile anche
        controllare l'aspetto di un grafico in tutti i suoi dettagli,
        se si vuole.
      </para>

      <para>
        Mentre un grafico viene visualizzato, facendo clic sulla
        finestra del grafico si aprirà un menù pop-up con le seguenti
        opzioni:
      </para>

      <ilist>
	<li><para>Salva come postscript: salva il grafico in formato encapsulated
	    postscript (EPS)</para>
	</li>
	<li><para>Salva come PNG: salva in formato Portable Network Graphics</para>
	</li>
	<li><para>Salva alla sessione come icona: il grafico apparirà
        sotto forma di icona quando si seleziona <quote>Visualizza
        Icone</quote> dal menù Sessione</para>
	</li>
	<li><para>Ingrandisci: permette di selezionare un'area
        all'interno del grafico per visualizzarla da vicino</para>
	</li>
        <li><para>Stampa: permette di stampare il grafico direttamente
        (disponibile solo in Gnome e MS Windows)</para>
	</li>
	<li><para>Copia negli appunti: permette di copiare il grafico
        per poi incollarlo in altri programmi Windows, come ad esempio
        MS Word (disponibile solo in MS Windows)</para>
	</li>
	<li><para>Modifica: apre una finestra che permette di modificare
        vari dettagli dell'aspetto del grafico</para>
	</li>
	<li><para>Chiudi: chiude la finestra del grafico</para>
	</li>
      </ilist>

      <para>
	Se si conosce gnuplot e si desidera un controllo sull'aspetto del
	grafico più preciso di quello fornito dalla finestra di modifica
	del grafico (opzione <quote>Modifica</quote>), ci sono due
	possibilità:
      </para>

      <ilist>
	<li>
          <para>
            Una volta salvato il grafico come icona di sessione,
            facendo clic col tasto destro sull'icona si apre un altro menù
            pop-up. Una delle opzioni disponibili è <quote>Comandi per
            modificare il grafico</quote>, che apre una finestra di modifica
            con i comandi di gnuplot. È possibile modificare questi comandi
            e salvarli per il futuro, oppure inviarli direttamente a
            gnuplot (con il comando <quote>File/Invia a gnuplot</quote> del
            menù della finestra di modifica dei comandi).
          </para>
        </li>
        <li>
          <para>
            Un altro modo per salvare i comandi del grafico (o per
            salvare il grafico in formati diversi da EPS o PNG) è quello di
            usare il comando <quote>Modifica</quote> nel menù pop-up del
            grafico per aprire la finestra di modifica del grafico, quindi
            fare clic su <quote>File</quote>: verrà visualizzato un menù a
            discesa con i formati in cui è possibile salvare il grafico.
          </para>
	</li>
      </ilist>

      <para>
	Per saperne di più su gnuplot, si veda
	<url>http://www.gnuplot.info</url>
      </para>

    </description>

  </command>

  <command name="graphpg" section="Graphs" label="Pagina dei grafici">

    <usage>
      <altforms>
        <altform><lit>graphpg add</lit></altform>
	<altform><lit>graphpg fontscale </lit><repl>value</repl></altform>
	<altform><lit>graphpg show</lit></altform>
	<altform><lit>graphpg free</lit></altform>
	<altform><lit>graphpg --output=</lit><repl>filename</repl></altform>
      </altforms>
    </usage>

    <description>

      <para>
        La <quote>pagina dei grafici</quote> funzionerà solo se
        si è installato il sistema di composizione &latex; e si è
        in grado di generare e visualizzare file in formato postscript.
      </para>

      <para>
        Nella finestra della sessione, è possibile trascinare fino
	a otto grafici sull'icona della pagina dei grafici. Facendo doppio
	clic sull'icona della pagina dei grafici (o facendo clic col tasto
        destro e selezionando <quote>Mostra</quote>), la pagina contenente
        i grafici selezionati verrà composta e aperta con il proprio
        visualizzatore di file postscript, da cui sarà possibile stamparla.
      </para>

      <para>
        Per pulire la pagina dei grafici, fare clic col tasto destro
        sull'icona e selezionare <quote>Pulisci</quote>.
      </para> 

      <para>
        Su sistemi diversi da MS Windows, può essere necessario modificare
        l'impostazione del programma per visualizzare il postscript, che si
        trova nella sezione <quote>Programmi</quote> della finestra di dialogo
        delle Preferenze di gretl (nel menù Strumenti della finestra principale).
      </para>

      <para>
	E' anche possibile operare sulla pagina del grafico usanod uno script
	oppure usando la console (nel programma GUI). Sono disponibili i comandi seguenti:
      </para>
      <para>
	Per aggiungere un grafico alla pagina dei grafici, digitate il comando
	<lit>graphpg add</lit> dopo aver salvato un grafico con un
	nome, come in 
      </para>
      <code>
	grf1 &lt;- gnuplot Y X
	graphpg add
      </code>
       <para>
	Per aprire la pagina dei grafici: <lit>graphpg show</lit>.
      </para>
      <para>
	Per svuotare la pagina dei grafici: <lit>graphpg free</lit>.
      </para>
      <para>
	Per modificare la dimensione del font usato nella pagina dei grafici usate 
	<lit>graphpg fontscale</lit> <repl>scale</repl>, dove 
	<repl>scale</repl> è un moltiplicatore (con un valore di default pari a 1.0). 
	Per rendere il fonto più grande del 50 per cento, dunque, 
	è possibile scrivere
      </para>
      <code>
	graphpg fontscale 1.5
      </code>
      <para>
	Per stampare su un file la pagina dei grafici usate l'opzione 
	<opt>output=</opt> seguita dal nome di un file; questo nome deve avere 
	il suffisso <quote><lit>.pdf</lit></quote>,
	<quote><lit>.ps</lit></quote> o
	<quote><lit>.eps</lit></quote>. Per esempio:
      </para>
      <code>
	graphpg --output="myfile.pdf"
      </code>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo. 
      </para>
      <para>
	In questo contesto l'output usa linee colorate di default; per usare 
	linee punteggiate o tratteggiate al posto dei colori è possibile aggiungere
	l'opzione <opt>monochrome</opt>.
      </para>
    </description>

  </command>

  <command name="3-D" section="Graphs" context="gui"
    label="Grafici tridimensionali">

    <description>
      <para>
        Questa funzionalità consente di manipolare il grafico 3D con
        il mouse (ruotandolo ed allungando o riducendo gli assi).
      </para>

      <para>
        Nella composizione di un grafico 3D, si noti che l'asse Z
        sarà l'asse verticale, quindi se si ha una variabile dipendente
        che si pensa possa essere influenzata da due variabili indipendenti,
        è meglio mettere la variabile dipendente sull'asse Z e le altre
        due variabili sugli assi X e Y.
      </para>  

      <para>
        A differenza di molti altri grafici di gretl, i grafici 3D
        sono controllati da gnuplot invece che da gretl, quindi il menù
        di modifica dei grafici in questo caso non è disponibile.
      </para>

    </description>
  </command>

  <command name="gui-funcs" section="Programming" 
	   label="Special functions" context="gui">
    <description>
      <para>
	Questo comando permette di specificare se ad alcune delle
	funzioni di un pacchetto devono essere attribuiti alcuni
	compiti specifici, e se sì a quali. Si noti che a una data
	funzione può essere attribuito al massimo uno dei compiti
	seguenti, e che per poter essere candidata a uno di questi
	compiti la funzione deve soddisfare alcuni criteri.
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>bundle-print</lit>: stampa l'output sulla base del contenuto
		di un bundle di risultati generati dal vostro pacchetto. Criteri:
		questa funzione deve avere come primo parametro un puntatore 
		del bundle. Se presente, il secondo parametro deve assumere valori
		interi, ed è necessario che ne sia specificato uno di default.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>bundle-plot</lit>: produce uno o più grafici usando un bundle
		generato dal vostro pacchetto. Criteri: come per 
	    <lit>bundle-print</lit>.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>bundle-test</lit>: calcola qualche test statistico
	    usando un bundle generato dal vostro pacchetto. Criteri:
	    come per <lit>bundle-print</lit>.
	  </para>
	</li>	
	<li>
	  <para>
	    <lit>gui-main</lit>: l'interfaccia pubblica che per default dovrebbe 
		essere offerta agli utenti in modalità GUI. Questa opzione è utile
		solo se il pacchetto può offrire più di un'interfaccia pubblica.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>gui-precheck</lit>: funzione di controllo che restituisce 0 se
		le funzionalità del vostro pacchetto possono essere applicate
		al contesto corrente, e un valore diverso da 0 in caso contrario.
		Questa opzione serve per i pacchetti che svolgono qualche operazione
		a partire da un modello, in modo da evitare i tipi di modelli 
		non gestibili dal pacchetto.
	  </para>
	</li>	
      </ilist>
    </description>
  </command>

  <command name="gui-htest" section="Tests" context="gui"
    label="Calcolatore per le statistiche test">

    <description>
      <para>
	Il calcolatore dei test di Gretl calcola statistiche test e p-value
        per molti tipi di test di ipotesi su una o più popolazioni.
        Per utilizzarlo, occorre indicare le statistiche campionarie derivate
        da uno o due campioni, a seconda del test scelto. Queste possono essere
        indicate esplicitamente in forma numerica, oppure, se si ha un file di
        dati aperto, è possibile far calcolare a gretl le statistiche test per
        una o più variabili selezionate dal dataset (nel caso delle medie e
        varianze, ma non nel caso delle proporzioni).
      </para>

      <para>
	Per eseguire un test indicando una variabile del dataset, occorre per
        prima cosa attivare questa opzione selezionando la casella "Usa
        variabile dal dataset", e poi scegliere la variabile nella lista.
        Appena si sceglie una variabile, i valori della statistica rilevante
        sono automaticamente inseriti nelle caselle sottostanti.
      </para>

      <para>
	Oltre che selezionare semplicemente una variabile, è possibile
        specificare un sotto-campione. Ad esempio, si ipotizzi di avere dei dati
        sui salari in una variabile chiamata "salari" e una variabile dummy
        chiamata "genere", pari a 1 per gli uomini e 0 per le donne (o
        viceversa). Quindi, nel test per la differenza fra le medie, è possibile
        selezionare "salari" in entrambi i campi, ma aggiungendo nel campo
        superiore "(genere=0)" e nel campo inferiore "(genere=1)" si otterrà
        un test per la differenza tra il reddito medio degli uomini e delle
        donne. Quando si specifica un vincolo che identifica un sotto-campione,
        occorre premere il tasto Invio perché le statistiche campionarie siano
        calcolate.
      </para>

      <para>
	Il vincolo che definisce il sotto-campione deve essere indicato tra
        parentesi e in generale prende la forma "variabile operatore valore",
        dove "variabile" è il nome di una variabile nel dataset attuale,
        "valore" è un valore numerico e "operatore" è un operatore di confronto,
        da scegliere tra =, !=, &lt;, &gt;, &lt;= or &gt;= (rispettivamente uguale
        diverso, minore, maggiore, minore o uguale, maggiore o uguale). Gli
        spazi prima e dopo l'operatore sono opzionali.
      </para>

    </description>
  </command>

  <command name="gui-htest-np" section="Tests" context="gui"
    label="Test non parametrici">

    <description>
      <para>
       Nella finestra <quote>Test delle differenze</quote> è possibile svolgere
       dei test non parametrici per la differenza tra due popolazioni o gruppi;
       è possibile scegliere vari tipi specifici di test:
      </para>
      <para>
       Test del segno: si basa sul fatto che per due campioni
	<math>x</math> e <math>y</math> estratti casualmente dalla
        stessa distribuzione, la probabilità che valga
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub> per ogni osservazione
	<math>i</math> dovrebbe valere 0.5. La statistica test è
	<math>w</math>, ossia il numero di osservazioni per cui vale
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub>. Sotto l'ipotesi nulla, questa
        grandezza si distribuisce come una binomiale con parametri
	(<math>n</math>, 0.5), dove <math>n</math> è il numero di
        osservazioni.
      </para>
      <para>
       Test rank sum di Wilcoxon. Questo test procede ordinando le
       osservazioni estratte da entrambi i campioni dalla più piccola
       alla più grande, e quindi calcolando la somma dei ranghi delle
       osservazioni da uno dei campioni. I due campioni non devono
       necessariamente avere la stessa dimensione: se sono diversi,
       viene usato il campione più piccolo per calcolare la somma dei
       ranghi. Sotto l'ipotesi nulla che i campioni siano estratti da
       popolazioni con la stessa mediana, la distribuzione di
       probabilità della somma dei ranghi può essere calcolata per
       ogni valore dell'ampiezza dei due campioni, mentre per campioni
       abbastanza ampi essa approssima la distribuzione normale.
      </para>
      <para>
       Test signed rank di Wilcoxon.  Questo test è valido per "coppie di
       campioni", come possono essere ad esempio i valori di una variabile in un
       gruppo di individui prima e dopo un certo trattamento. Il test procede
       calcolando le differenze tra le coppie di osservazioni
       <math>x</math><sub>i</sub> &minus;
       <math>y</math><sub>i</sub>, ordinando queste differenze per valore
       assoluto e assegnando ad ogni coppia un valore di rango con segno, in cui
       il segno rispecchia il segno della differenza. Quindi viene calcolato
       <math>W</math><sub>+</sub>, la somma di tutti i ranghi con segno
       positivo. Come avviene per il test rank-sum, questa statistica ha una
       distribuzione precisa nell'ipotesi nulla che la differenza mediana sia
       zero, distribuzione che converte alla normale nel caso di campioni
       abbastanza ampi.
      </para>
      <para>
       Nella finestra <quote>Test delle successioni</quote> è possibile
       eseguire un test per la casualità di una certa variabile, basato
       sul numero di successioni di valori consecutivi positivi o negativi.
       Con l'opzione <quote>Usa la differenza prima</quote>, la variabile viene
       differenziata prima dell'analisi, quindi le successioni sono
       interpretabili come sequenze di incrementi o decrementi consecutivi nel
       valore della variabile. La statistica test è basata su un'approssimazione
       normale alla distribuzione del numero di sequenze sotto l'ipotesi nulla
       di casualità.
      </para>
    </description>
  </command>
    
  <command name="hausman" section="Tests" label="Diagnosi panel">

    <description>
      <para>
        Questo test è disponibile solo dopo aver stimato un modello OLS su dati
        panel (si veda anche <cmd>setobs</cmd>). Testa il semplice modello
        <quote>pooled</quote> (con tutte le osservazioni mescolate
        indistintamente) contro le principali alternative: il modello a effetti
        fissi e quello a effetti casuali.
      </para>

      <para>
        Il modello a effetti fissi permette all'intercetta della regressione di
        variare per ogni unità cross section. Viene eseguito un test
        <math>F</math> per l'ipotesi nulla che le intercette non
        differiscano tra loro.  Il modello a effetti casuali scompone la
        varianza dei residui in due parti: una specifica all'unità cross section
        e una specifica all'osservazione particolare (la stima può essere
        eseguita solo se il numero delle unità cross section nel dataset è
        maggiore del numero dei parametri da stimare). La statistica LM di
        Breusch&ndash;Pagan testa l'ipotesi nulla che il modello pooled OLS sia
        adeguato contro l'alternativo modello a effetti casuali.
      </para>

      <para>
	Può accadere che il modello pooled OLS sia rifiutato nei confronti
        di entrambe le alternative, a effetti fissi o casuali. A patto
        che gli errori specifici di unità o di gruppo siano non
        correlati con le variabili indipendenti, lo stimatore a effetti
        casuali è più efficiente dello stimatore a effetti fissi; nel
        caso contrario lo stimatore a effetti casuali non è consistente
	e deve essergli preferito lo stimatore a effetti fissi. L'ipotesi
        nulla per il test di Hausman è che l'errore specifico di gruppo non
        sia correlato con le variabili indipendenti (e quindi che il
        modello a effetti casuali sia preferibile). Un basso p-value per
        questo test suggerisce di rifiutare il modello a effetti casuali
        in favore del modello a effetti fissi.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/HAUSMAN - Diagnosi panel</menu-path>
    </gui-access>

  </command>


  <command name="hccme" section="Estimation" context="gui"
    label="Errori standard robusti">

    <description>
      <para>
	Sono disponibili vari modi di calcolare gli errori standard
        robusti in presenza di eteroschedasticità (e, nel caso dello
        stimatore HAC, di autocorrelazione).
      </para>

      <para>HC0 produce gli <quote>errori standard originali di
      White</quote>; HC1, HC2, HC3 e HC3a sono varianti che si ritiene
      producano risultati migliori (più affidabili). Per i dettagli
      sugli stimatori, si veda <cite key="mackinnon-white85">MacKinnon
      and White (Journal of Econometrics, 1985)</cite> o <cite
      key="davidson-mackinnon04">Davidson and MacKinnon, Econometric
      Theory and Methods (Oxford, 2004)</cite>. Le sigle usate sono
      quelle proposte da Davidson e MacKinnon. La variante
      <quote>HC3a</quote> è il <quote>jackknife</quote> descritto da
      MacKinnon e White (1985); HC3 è una sua vicina approssimazione.
      </para>

      <para>Se si usa lo stimatore HAC per serie storiche, è possibile calibrare
        la lunghezza dei ritardi usando il comando <cmd>set</cmd>. Si veda il
        manuale di gretl o i file di aiuto per i dettagli.</para>

      <para>Quando si stima un  modello OLS su dati panel, lo stimatore robusto
        predefinito per la matrice di covarianza è quello dato da Arellano.
        L'alternativa è lo stimatore PCSE (Panel Corrected Standard Errors) di
        Beck e Katz, che tiene conto dell'eteroschedasticità, ma non
        dell'autocorrelazione.
      </para>

      <para>Per i modelli GARCH sono disponibili due stimatori robusti della
        matrice di covarianza: QML è lo stimatore di quasi massima verosimiglianza,
        e BW è lo stimatore di Bollerslev-Wooldridge.
      </para>

    </description>

  </command>

  <command name="heckit" section="Estimation" context="cli"
    label="Modello di selezione di Heckman">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
	<argument separated="true">equazione di selezione</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
        <option>
	  <flag>--two-step</flag>
	  <effect>esegue la stima in due passi</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
	<option>
	  <flag>--opg</flag>
	  <effect>errori standard OPG</effect>
        </option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard QML</effect>
        </option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra risultati aggiuntivi</effect>
        </option>
      </options>      
      <examples>
        <example>heckit y 0 x1 x2 ; ys 0 x3 x4</example>
	<demos>
	  <demo>heckit.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
        Modello di selezione di tipo Heckman. Nella specificazione, la lista che
        precede il punto e virgola rappresenta l'equazione principale, mentre la
        seconda lista rappresenta l'equazione di selezione. La variabile
        dipendente nell'equazione di selezione (<lit>ys</lit>
        nell'esempio visto sopra) deve essere una variabile binaria.
      </para>

      <para>
	Per impostazione predefinita, i parametri sono stimati per massima
        verosimiglianza. La matrice di covarianza dei parametri è calcolata
        usando l'inversa negativa dell'Hessiana. Se si vuole usare la procedura
        di stima in due passi, basta usare l'opzione <lit>--two-step</lit>.
        In questo caso, la matrice di covarianza dei parametri dell'equazione
        principale è corretta nel modo descritto da Heckman (1979).
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Heckit</menu-path>
    </gui-access>

  </command>

  <command name="help" section="Utilities" label="Aiuto sui comandi" context="cli">

    <usage>
      <altforms>
        <altform><lit>help</lit></altform>
        <altform><lit>help functions</lit></altform>
        <altform><lit>help</lit> <repl>comando</repl></altform>
        <altform><lit>help</lit> <repl>funzione</repl></altform>
      </altforms>
      <options>
       <option>
         <flag>--func</flag>
         <effect>sceglie l'aiuto sulle funzioni</effect>
       </option>
      </options>
    </usage>

    <description>
      <para>
        Se non vengono indicati argomenti, mostra un elenco dei comandi disponibili.
        Indicando l'argomento <lit quote="true">functions</lit>, mostra un
        elenco delle funzioni disponibili (si veda <cmdref targ="genr"/>).
      </para> 
      <para> 
        <cmd>help</cmd> <repl>comando</repl> descrive il <repl>comando</repl>
        (ad es.  <cmd>help smpl</cmd>). <lit>help</lit> <repl>funzione</repl>
        descrive la <repl>funzione</repl> (ad es. <lit>help ldet</lit>).
        Alcune funzioni hanno lo stesso nome dei comandi relativi (ad esempio
        <lit>diff</lit>): in questo caso verrà mostrato l'aiuto relativo al
        comando, a meno che non si usi l'opzione <opt>func</opt>.
      </para> 
    </description>

    <gui-access>
      <menu-path>/Aiuto</menu-path>
    </gui-access>

  </command>

  <command name="hsk" section="Estimation"
    label="Stime corrette per l'eteroschedasticità">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Questo comando è utile in presenza di eteroschedasticità sotto forma di
        una funzione incognita dei regressori, che può essere approssimata da
        una relazione quadratica. In questo contesto, offre la possibilità di
        avere errori standard consistenti e stime dei parametri più efficienti,
        rispetto alla stima OLS.
      </para>
      <para>
        La procedura richiede: (a) la stima OLS del modello, (b) una regressione
        ausiliaria per generare la stima della varianza dell'errore e (c) la
        stima con minimi quadrati ponderati, usando come peso il reciproco della
        varianza stimata.
      </para>
      <para>
        Nella regressione ausiliaria (b) il logaritmo dei quadrati dei residui
        dalla prima regressione OLS viene regredito sui regressori originali e
        sui loro quadrati. La trasformazione logaritmica viene effettuata per
        assicurarsi che le varianze stimate siano non negative. Indicando con
        <math>u</math><sup>*</sup> i valori stimati da questa regressione, la
        serie dei pesi per la regressione con minimi quadrati ponderati è data
        da 1/exp(<math>u</math><sup>*</sup>).
     </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/HSK - WLS corretti per eteroschedasticità</menu-path>
    </gui-access>

  </command>

  <command name="hurst" section="Statistics"
    label="Esponente di Hurst">
  
    <usage>
      <arguments>
        <argument>nome-variabile</argument>
      </arguments>
    </usage>
  
    <description>
      <para>
       Calcola l'esponente di Hurst (una misura di persistenza, o di memoria
       lunga) per una serie storica con almeno 128 osservazioni.
      </para>
  
      <para>
       L'esponente di Hurst è discusso da Mandelbrot. In termini teorici è
       l'esponente <math>H</math> nella relazione
       <equation status="display"
         tex="\[\mathrm{RS}(x) = an^H\]"
         ascii="RS(x) = an^H"
         graphic="hurst"/>dove RS è l'<quote>intervallo riscalato</quote>
         della variabile <math>x</math> in un campione dell'ampiezza
       <math>n</math>, mentre <math>a</math> è una
       costante. L'intervallo riscalato è l'intervallo (valore massimo
       meno valore minimo) del valore cumulato, o somma parziale, di
       <math>x</math> sul periodo del campione (dopo aver sottratto la
       media campionaria), diviso per lo scarto quadratico medio campionario.
      </para>
  
      <para>
       Come punto di riferimento, se <math>x</math> è un rumore bianco
       (media zero, persistenza zero) l'intervallo dei suoi valori cumulati
       (che forma una passeggiata casuale), scalato per lo scarto quadratico medio,
       cresce come la radice quadrata dell'ampiezza campionaria, ossia ha un
       esponente di Hurst atteso pari a 0.5. Valori dell'esponente sensibilmente
       maggiori di 0.5 indicano persistenza della serie, mentre valori minori di
       0.5 indicano anti-persistenza (autocorrelazione negativa). In teoria
       l'esponente deve essere compreso tra 0 e 1, ma in campioni finiti è
       possibile ottenere delle stime per l'esponente maggiori di 1.
      </para>

      <para>
       In gretl, l'esponente è stimato usando il sotto-campionamento binario:
       si inizia dall'intero intervallo dei dati, quindi si usano le due metà
       dell'intervallo, poi i quattro quarti, e così via. Il valore RS è la
       media presa sui vari campioni. L'esponente è quindi stimato come il
       coefficiente di pendenza della regressione del logaritmo di RS sul
       logaritmo dell'ampiezza del campione.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Esponente di Hurst</menu-path>
    </gui-access>

  </command>


  <command name="if" section="Programming" label="Strutture di controllo" context="cli">

    <description>
      <para>
        Struttura di controllo per l'esecuzione dei comandi. Sono supportate le
        tre forme seguenti:
      </para>

      <code>
	# forma semplice
	if condition
	    commands
	endif

	# a due rami
	if condition
	    commands1
	else
	    commands2
        endif

	# a tre o più rami
	if condition1
	    commands1
	elif condition2
	    commands2
	else
	    commands3
	endif
      </code>
 
      <para>
        La <repl quote="true">condizione</repl> deve essere un'espressione
        Booleana, per la cui sintassi si veda <cmdref targ="genr"/>.
        Può essere incluso più di un blocco <cmd>elif</cmd>.
        Inoltre, i blocchi <lit>if</lit> &hellip;
	<lit>endif</lit> possono essere nidificati.
      </para>

    </description>

  </command>

  <command name="include" section="Programming" label="Include definizioni di
    funzioni" context="cli">

    <usage>
      <arguments>
        <argument>file-input</argument>
      </arguments>
    </usage>

    <description>
      <para>
        Da usare in uno script di comandi, principalmente per includere
        definizioni di funzioni. Esegue i comandi nel <repl>file-input</repl>
        e ripassa il controllo allo script principale. Per includere una funzione
        che fa parte di un pacchetto, occorre specificare anche l'estensione del
        file.
      </para>
      <para>
	Si veda anche il comando <cmdref targ="run"/>.
      </para>
    </description>

  </command>


  <command name="info" section="Dataset" label="Informazioni sul dataset" context="cli">

    <description>
      <para>
	Mostra le informazioni aggiuntive contenute nel file di dati
        attuale.
      </para>
    </description>

    <gui-access>
      <menu-path>/Dati/Visualizza descrizione</menu-path>
      <other-access>Finestre di esplorazione dei dati</other-access>
    </gui-access>

  </command>

  <command name="install" section="Utilities" context="cli">

    <usage>
      <arguments>
        <argument>nomepacchetto</argument>
      </arguments>
      <options>
        <option>
	  <flag>--local</flag>
	  <effect>installa da file in locale</effect>
        </option>
        <option>
	  <flag>--remove</flag>
	  <effect>vedi sotto</effect>
        </option>	
        <option>
	  <flag>--purge</flag>
	  <effect>vedi sotto</effect>
        </option>
      </options>
     <examples>
        <example>install armax</example>
        <example>install felogit.gfn</example>
	<example>install /path/to/myfile.gfn --local</example>
	<example>install http://foo.bar.net/gretl/myfile.gfn</example>
     </examples>
    </usage>    

    <description>
      <para>
	Comendo per installare e disinstallare pacchetti di funzioni
	(file <lit>gfn</lit> o <lit>zip</lit>).
      </para>
      <para>
	Se a questo comando viene dato il nome di un pacchetto senza
	opzioni (come nei primi due esempi), il pacchetto stesso verrà
	scaricato dal server di gretl e installato in locale. In
	questo caso, indicare l'estensione è superfluo.
      </para>
      <para>
	Se viene data l'opzione <opt>local</opt>, l'argomento
	<repl>nomepacchetto</repl> deve essere il percorso completo di
	un file di pacchetto sulla macchina locale, completo di
	estensione. L'azione conseguente al comando è di copiarlo (se
	<lit>gfn</lit>), o espanderlo (se <lit>zip</lit>) nel posto
	giusto, ossia dove il comando <cmdref targ="include"/> sia in
	grado poi di trovarlo.
      </para>
      <para>
	In assenza di opzioni, se <repl>nomepacchetto</repl> comincia
	con <lit>http://</lit>, l'effetto è di scaricare il pacchetto
	da un server specificato e poi installarlo localmente.
      </para>
      <para>
	L'operazione inversa (ossia, la disinstallazione) viene
	effettuata con le opzioni <opt>remove</opt> o
	<opt>purge</opt>. Con <opt>remove</opt> il pacchetto viene
	scaricato dalla memoria ed è rimosso dal menu GUI
	a cui sia eventualmente attaccato. L'opzione
	<opt>purge</opt> agisce come <opt>remove</opt>, ma cancella
	anche il file di pacchetto. (Se un pacchetto contiene una sua
	propria sottocartella, essa stessa viene completamente cancellata.)
      </para>      
    </description>

    <gui-access>
      <menu-path>/Strumenti/Pacchetti/Sul server</menu-path>
    </gui-access>

  </command>  

  <command name="intreg" section="Estimation" label="Modello di regressione per intervalli">

    <usage>
      <arguments>
        <argument></argument>
        <argument>var-min</argument>
        <argument>var-max</argument>
        <argument>var-indip</argument>
      </arguments>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
        <option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>	
      </options>
      <examples>
	<example>intreg lo hi const x1 x2</example>
	<demos>
	  <demo>wtp.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Stima un modello di regressione per intervallo. Questo modello è adatto
        al caso in cui la variabile dipendente è osservata in modo imperfetto
        per alcune osservazioni (o anche tutte). In altre parole, si ipotizza
        che il processo generatore dei dati sia
	<equation status="display"
	tex="\[y^*_t = x_t \beta+\epsilon_t\]" ascii="y* = x b + u"/> ma che
        solo
	<equation status="inline" tex="\[m_t \le
	y_t \le M_t\]" ascii="m &lt;= y* &lt;= M"/> sia osservato (l'intervallo
        può essere limitato a destra o a sinistra). Si noti che per alcune
        osservazioni <math>m</math> può essere uguale a <math>M</math>. Le variabili
        <repl>var-min</repl> e <repl>var-max</repl> devono contenere valori <lit>NA</lit>
        nel caso di osservazioni non limitate a sinistra o a destra.
      </para>

      <para context="gui">
	Nella finestra di specificazione del modello, <repl>var-min</repl> e
	<repl>var-max</repl> sono identificate come la variabile limite
        inferiore e la variabile limite superiore.
      </para>

      <para>
	Il modello è stimato per massima verosimiglianza, ipotizzando la
        normalità del termine di disturbo.
      </para>

      <para context="cli">
	Per impostazione predefinita, gli errori standard sono calcolati usando
        l'inversa dell'Hessiana. Se si usa l'opzione <opt>robust</opt>, vengono
        calcolati invece gli errori standard QML o Huber&ndash;White. In questo caso
        la matrice di covarianza stimata è un <quote>sandwich</quote>
        dell'inversa dell'Hessiana stimata e del prodotto esterno del gradiente.
      </para>
      <para context="gui">
	Per impostazione predefinita, gli errori standard sono calcolati usando
        l'inversa dell'Hessiana. Se si abilita la casella "Errori standard robusti", vengono
        calcolati invece gli errori standard QML o Huber&ndash;White. In questo caso
        la matrice di covarianza stimata è un <quote>sandwich</quote>
        dell'inversa dell'Hessiana stimata e del prodotto esterno del gradiente.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Regressione per intervalli</menu-path>
    </gui-access>

  </command>


  <command name="irfboot" section="Graphs" context="gui"
    label="Bootstrap impulso-risposta">

    <description>
      <para>Se si sceglie l'intervallo di confidenza bootstrap nella
      visualizzazione delle funzioni di impulso-risposta, gretl
      calcola un intervallo di confidenza al 95 per cento per le
      risposte usando il metodo bootstrap. Si effettua un
      campionamento (con reimmissione) dai residui del VAR (o VECM)
      originale, viene costruito un dataset artificiale usando le
      stime originali dei parametri e i residui ri-campionati, viene
      ri-stimato il sistema e vengono ri-calcolate le funzioni di
      impulso-risposta.  Questa procedura viene ripetuta 999 volte e
      vengono mostrati i quantili 0.025 e 0.975 per le risposte,
      insieme alle stime puntuali.  L'opzione bootstrap al momento non
      è disponibile per il VECM vincolati.
      </para>
      <para>
	Questo comando permette anche il riordinamento delle variabili per la
	scomposizione di Cholesky della matrice di covarianza degli errori
	delle diverse equazioni. Di default l'ordine adottato è quello con 
	il quale le variabili vengono elencate nella specificazione del modello,
	ma è possibile usare le frecce verso l'alto e verso il basso per spostare
	una variabile selezionata.
      </para>
    </description>

  </command>

  <command name="join" section="Dataset" label="Manage data sources" 
	   context="cli">

    <usage>
      <arguments>
        <argument>filename</argument>
	<argument>varname</argument>
      </arguments>
      <options>
	<option>
	  <flag>--data</flag>
	  <optparm>column-name</optparm>
	  <effect>v. oltre</effect>
	</option>
	<option>
	  <flag>--filter</flag>
	  <optparm>expression</optparm>
	  <effect>v. oltre</effect>
	</option>
	<option>
	  <flag>--ikey</flag>
	  <optparm>inner-key</optparm>
	  <effect>v. oltre</effect>
	</option>
	<option>
	  <flag>--okey</flag>
	  <optparm>outer-key</optparm>
	  <effect>v. oltre</effect>
	</option>
	<option>
	  <flag>--aggr</flag>
	  <optparm>method</optparm>
	  <effect>v. oltre</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Questo comando importa una serie di dati dal file di origine 
	<repl>filename</repl> (che deve essere un file di dati testuale 
	delimitato) assegnandoli alla variabile <repl>varname</repl>. 
	Per maggiori dettagli, si veda <guideref targ="chap:join"/>; 
	in questa sede ci limitiamo a ricordare brevemente le opzioni 
	disponibili.
      </para>
      <para>
	L'opzione <opt>data</opt> può essere usata per specificare 
	l'intestazione della colonna nel file di origine se quest'ultima 
	è diversa dal nome con il quale dovrebbero essere chiamati i dati 
	in gretl.
      </para>
      <para>
	L'opzione <opt>filter</opt> può essere usata per specificare un criterio
	da seguire per filtrare i dati di origine (in altre parole,
	per selezionare un osttoinsieme di osservazioni).
      </para> 
      <para>
	Le opzioni <opt>ikey</opt> e <opt>okey</opt> possono essere utilizzate
	per specificare una relazione fra le osservazioni nel dataset corrente
	e quelle nel file di origine (per esempio, gli individui possono essere 
	assegnati alla famiglia di appartenenza).
      </para>
      <para>
	L'opzione <opt>aggr</opt> viene usata quando la relazione fra
	osservazioni nel dataset corrente e nel file di oriogine non è
	biunivoca.
      </para>      
      <para>
	L'opzione <opt>tkey</opt> è applicabile solo quando il dataset
	corrente ha una struttura di serie storiche. Viene usato per
	specificare il nome di una colonna contenete le date da
	accoppiare al dataset e/o il formato in cui le date sono
	rappresentate in quella colonna.
      </para>     
      <para>
	V. anche <cmdref targ="append"/> per alcune semplici
	operazioni di unione di dataset.
      </para>
    </description>

  </command>

  <command name="kpss" section="Tests" label="Test KPSS di stazionarietà">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--trend</flag>
	  <effect>include un trend</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i risultati della regressione</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
	<option>
	  <flag>--difference</flag>
	  <effect>usa la differenza prima della variabile</effect>
	</option>
      </options>
      <examples>
	<example>kpss 8 y</example>
        <example>kpss 4 x1 --trend</example>
      </examples>
    </usage>

    <description>
      <para context="gui">
	Calcola il test KPSS (Kwiatkowski, Phillips, Schmidt e Shin,
	1992) per la stazionarietà di una variabile (o della sua
	differenza prima, se si usa l'opzione di
	differenziazione). L'ipotesi nulla è che la variabile in
	questione sia stazionaria, attorno a un valore fisso o, se è
	stata selezionata l'opzione <lit>includi un trend</lit>,
	attorno a un trend deterministico lineare.
      </para>

      <para context="cli">
	Si veda il paragrafo in fondo per l'uso di questo test su dati
	panel.
      </para>

      <para context="cli">
	Calcola il test KPSS <cite key="KPSS92" p="true">(Kwiatkowski
	et al, Journal of Econometrics, 1992)</cite> per la
	stazionarietà di ognuna delle variabili specificate (o della
	loro differenza prima, se si usa l'opzione
	<opt>difference</opt>. L'ipotesi nulla è che la variabile in
	questione sia stazionaria, attorno a un valore fisso o, se è
	stata usata l'opzione <opt>trend</opt>, attorno a un trend
	deterministico lineare.
      </para>

      <para context="gui">
	L'argomento ordine determina la dimensione della finestra usata per
        il livellamento di Bartlett.  Se si usa l'opzione <lit>Mostra i risultati
        della regressione</lit>, vengono mostrati anche i risultati della
        regressione ausiliaria, insieme alla varianza stimata della componente
        random walk della variabile.
      </para>

      <para context="cli">
	L'argomento ordine determina la dimensione della finestra usata per
        il livellamento di Bartlett.  Se si usa l'opzione <opt>verbose</opt>,
        vengono mostrati anche i risultati della regressione ausiliaria, insieme
        alla varianza stimata della componente random walk della variabile.
      </para>

      <para>
	Il valori critici riportati per questa statistica test sono
	basati sulle superfici di risposta stimati da <cite
	key="sephton95">Sephton (Economics Letters, 1995)</cite>, che
	per piccoli campioni sono più accurati di quelli forniti
	nell'articolo originale di KPSS. Quando la statistica test si
	trova fra i valori critici al 10 e all'1 per cento viene
	mostrato un p-value ottenuto per interpolazione lineare, che
	non dovrebbe essere accettato in maniera acritica.
      </para>

      <subhead context="cli">Dati panel</subhead>

      <para context="cli">
	Quando il comando <lit>kpss</lit> viene usato con dati panel
	per calcolare un test panel di radice unitaria, le opzioni
	applicabili e i risultati mostrati sono leggermente
	diversi. Mentre nel caso di serie storiche regolari potete
	fornire una lista di variabili da testare, con dati panel il
	comando può testare solo una variabile alla volta. L'opzione
	<opt>verbose</opt>, inoltre, ha un isgnificato diverso:
	produce un breve resoconto del test per ciascuna singola serie
	storica (di default viene mostrato solo il risultato
	complessivo).
      </para>

      <para context="cli">
	Se possibile, viene calcolato il test complessivo (ipotesi
	nulla: la ariabile in questione è stazionaria per tutte le
	unità panel) usando il metodo di <cite key="choi01">Choi
	(Journal of International Money and Finance,
	2001)</cite>. Questo calcolo non è sempre immediato perchè
	mentre il test di Choi è basato sui p-valu dei test sulle
	singole serie, attualmente non esiste un modo per calcolare i
	p-value della statistica test KPSS; dobbiamo perciò basarci su
	qualche valore critico.
      </para>

      <para context="cli">
	Se per una data variabile la statistica test cade fra i valori
	critici al 10 e all'1 per cento siamo in grado di interpolare
	un p-value. Ma se il test cade a sinistra del valore critico
	al 10 per cento, o supera quello all'1 per cento, non
	riusciamo a interpolare e tutto ciò che possiamo ottenere è un
	limite superiore al test globale di Choi. Se le singole
	statistiche test si trovano a sinistra del valore critico al
	10 per cento per alcune unità ma superano quello all'1 per
	cento per altre non è possibile neppure il calcolo del limite
	superiore del test globale.
     </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Test di radice unitaria/Test KPSS</menu-path>
    </gui-access>

  </command>
  <command name="labels" section="Dataset" label="Mostra etichette delle variabili" context="cli">

    <usage>
      <altforms>
	<altform><lit>labels [</lit> <repl>varlist</repl> <lit>]</lit></altform>	
	<altform><lit>labels --to-file=</lit><repl>filename</repl></altform>
	<altform><lit>labels --from-file=</lit><repl>filename</repl></altform>
	<altform><lit>labels --delete</lit></altform>
      </altforms>
    </usage>

    <description>
      <para>
	Nella sua prima forma mostra le etichette informative (se
	presenti) per le variabili in <repl>varlist</repl>, oppure per
	tutte le variabili nel dataset se <repl>varlist</repl> non è
	specificata.
      </para>
      <para>
	Con l'opzione <opt>to-file</opt>, scrive nel file indicato le
	etichette di tutte le variabili nel dataset, una per linea. Se
	non sono presenti etichette viene emesso un messaggio
	d'errore; se alcune variabili hanno etichette e altre no, per
	le seconde viene mostrata una linea vuota. Il file di output
	verrà scritto nella directory corrispondente al valore
	corrente di <cmdref targ="workdir"/>, a meno che il nome di file
	contenga un percorso completo.
      </para>
      <para>
	Con l'opzione <opt>from-file</opt>, legge il file specificato (che deve
	essere di testo) e assegna le etichette alle variabili nel dataset, leggendo
	un'etichetta per linea e interpretando linee vuote come etichette vuote.
      </para>
      <para>
	L'opzione <opt>delete</opt> da quello che vi attendete:
	rimuove dal dataset tutte le etichette di variabili.
      </para>      
    </description>

  </command>

  <command name="lad" section="Estimation"
    label="Stima con minime deviazioni assolute">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Calcola una regressione che minimizza la somma delle deviazioni
        assolute dei valori stimati dai valori effettivi della variabile
        dipendente. Le stime dei coefficienti sono derivate usando
        l'algoritmo del simplesso di Barrodale&ndash;Roberts; viene
        mostrato un messaggio di avvertimento se la soluzione non è
        unica.
      </para>
      <para>
	Gli errori standard sono derivati usando la procedura bootstrap
        con 500 estrazioni. La matrice di covarianza per le stime dei
        parametri, mostrata se si usa l'opzione <opt>vcv</opt>, si basa
        sulla stessa procedura.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Stima robusta/LAD - Minime deviazioni assolute</menu-path>
    </gui-access>

  </command>

  <command name="lags" section="Transformations" label="Crea ritardi" context="cli">

    <usage>
      <arguments>
        <argument optional="true" separated="true">ordine</argument>
	<argument>lista-variabilii</argument>
      </arguments>
      <examples>
       <example>lags x y</example>
       <example>lags 12 ; x y</example>
      </examples>
    </usage>

    <description>
      <para>
	Crea delle nuove variabili come valori ritardati di ognuna delle
	variabili nella <repl>lista-variabili</repl>. Il numero dei ritardi può
        essere indicato dal primo parametro opzionale, altrimenti sarà pari
        alla periodicità del dataset.  Ad esempio, se la periodicità è 4
        (trimestrale), il comando <cmd>lags x y</cmd> crea
      </para>
      <code>
       x_1 = x(t-1)
       x_2 = x(t-2)
       x_3 = x(t-3)
       x_4 = x(t-4)
      </code>
      <para>
        Il numero dei ritardi creati può essere indicato come primo parametro
        opzionale (se presente, deve essere seguito da un punto e virgola).
      </para>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Ritardi delle variabili selezionate</menu-path>
    </gui-access>

  </command>

  <command name="lags-dialog" section="Estimation" context="gui"
    label="Finestra di selezione dei ritardi">

    <description>
      <para>
	In questa finestra di dialogo è possibile selezionare l'ordine dei
        ritardi per le variabili indipendenti in un modello di serie storiche, e
        in alcuni casi anche per la variabile dipendente (ma si noti che
        l'ordine di ritardi comune per modelli vettoriali come i VAR e i VECM è
        gestito separatamente attraverso un selettore nella finestra di dialogo
        principale del modello).
      </para>

      <para>
	I selettori sulla sinistra permettono di selezionare un intervallo di
        ritardi consecutivi per ogni variabile. Per specificare ritardi non
        consecutivi, occorre selezionare la casella vicino al campo intitolato
	<quote>ritardi specifici</quote>. In questo modo si attiva il campo,
        all'interno del quale è possibile inserire una lista di ritardi separati
        da spazi.
      </para>

      <para>
        La riga denominata <quote>predefinito</quote> offre un modo veloce per
        impostare una specificazione di ritardi comune a tutte le variabili
        indipendenti: i valori inseriti in questa riga vengono copiati in tutte
        le righe successive (tranne quella della variabile dipendente, se
        esiste).
      </para>

      <para>
        La variabile dipendente è trattata in modo speciale: il ritardo di
        ordine zero indica che la variabile apparirà nel modello a sinistra del
        segno uguale, mentre ulteriori ordini di ritardo saranno aggiunti a
        destra dell'uguale, insieme alle variabili indipendenti.
      </para>

      <para>
	I valori selezionati in questa finestra di dialogo vengono ricordati per
        l'intera durata della sessione di lavoro con un certo dataset.
      </para>

    </description>

  </command>

  <command name="ldiff" section="Transformations" label="Differenze logaritmiche" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Calcola la differenza prima del logaritmo naturale di ogni
        variabile della <repl>lista-variabili</repl> e la salva in una
        nuova variabile con il prefisso <lit>ld_</lit>.  Così, <cmd>ldiff
	x y</cmd> crea le nuove variabili 
      </para>
      <code>
	ld_x = log(x) - log(x(-1))
	ld_y = log(y) - log(y(-1))
      </code>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Differenze logaritmiche</menu-path>
    </gui-access>

  </command>

  <command name="leverage" section="Tests" label="Osservazioni influenti">

    <usage>
      <options>
        <option>
	  <flag>--save</flag>
	  <effect>salva le variabili risultato</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Deve seguire immediatamente un comando <cmd>ols</cmd>. Calcola
	il <quote>leverage</quote> (<math>h</math>, compreso tra 0 e
	1) di ogni osservazione nel campione su cui è stato stimato il
	precedente modello. Mostra il residuo (<math>u</math>) per
	ogni osservazione assieme al leverage corrispondente e a una
	misura della sua influenza sulla stima: <equation
	status="inline" tex="$uh/(1 - h)$" ascii="u*h/(1-h)"
	graphic="influence"/>. I <quote>punti di leverage</quote> per
	cui il valore di <math>h</math> supera
	2<math>k</math>/<math>n</math> (dove <math>k</math> è il
	numero dei parametri stimati e <math>n</math> è l'ampiezza del
	campione) sono indicati con un asterisco. Per i dettagli sui
	concetti di leverage e influenza, si veda <cite
	key="davidson-mackinnon93">Davidson and MacKinnon
	(1993)</cite>, capitolo 2.
      </para>

      <para>
	Vengono mostrati anche i valori DFFITS: questi sono
	<quote>residui studentizzati</quote> (ossia i residui
	previsti, divisi per i propri errori standard) moltiplicati
	per <equation status="inline" tex="$\sqrt{h/(1 - h)}$"
	ascii="sqrt[h/(1 - h)]" graphic="dffit"/>. Per una discussione
	dei residui studentizzati e dei valori DFFITS si veda Maddala,
	<cite key="maddala92">Introduction to Econometrics</cite>,
	cap. 12, oppure <cite key="belsley-etal80">Belsley, Kuh and
	Welsch (1980)</cite>.
      </para>
      <para>
        In breve, i <quote>residui previsti</quote>
	sono la differenza tra il valore osservato e il valore stimato 
        della variabile dipendente all'osservazione
        <math>t</math>, ottenuti da una regressione in cui
        quell'osservazione è stata omessa (oppure in cui è stata
        aggiunta una variabile dummy che vale 1 solo per l'osservazione
	<math>t</math>); il residuo studentizzato si ottiene
        dividendo il residuo previsto per il proprio errore standard.
      </para>

      <para context="cli">Se si usa l'opzione <opt>save</opt>, il
      leverage, il valore di influenza e il valore DFFITS vengono
      aggiunti al dataset in uso. In questo contesto, l'opzione
      <opt>quiet</opt> evita che i risultati vengano stampati. I nomi
      di default delle serie prodotte sono rispettivamente
      <lit>lever</lit>, <lit>influ</lit> and <lit>dffits</lit>. Se
      però serie con questo nome già esistono, i nomi delle serie
      prodotte sarano ritoccati per assicurarne l'unicità; se così
      avvenisse, occuperanno i tre numeri di serie più alti nel
      dataset.
      </para>

      <para context="gui">
	L'icona "+" in cima alla finestra del test di leverage apre una
        finestra di dialogo che permette di salvare nel dataset in uso
        una o più delle variabili del test.</para>
      <para context="tex">
	Dopo l'esecuzione l'accessore <fncref targ="$test"/>
	restituisce il criterio di validazione incrociata, definito
	come \[ \sum_{i=1}^n (y_i - \hat{y}_{-i})^2 \] dove
	$\hat{y}_{-i}$ è l'errore di previsione per la $i$-esima
	osservazione, dopo che quest'ultima è stata esclusa dal
	campione. Di conseguenza, il criterio è la somma dei quadrati
	degli errori di previsione nella quale per prevedere la
	$i$-esima osservazione vengono usate tutte le altre $n-1$
	osservazioni (il cosiddetto stimatore
	<emphasis>leave-one-out</emphasis>). Per una discussione più
	approfondita del criterio di validazione incrociata,
	v. Davidson e MacKinnon's <book>Econometric Theory and
	Methods</book>, pag. 685--686, e i riferimenti bibliografici
	ivi citati.
      </para>
      <para context="notex">
	Dopo l'esecuzione, l'accessore <fncref targ="$test"/>
	restituisce il criterio di validazione incrociata, definito
	come la somma dei quadrati degli scarti fra la variabile
	dipendente e il suo valore previsto, calcolato a partire da un
	campione dal quale quell'osservazione è stata esclusa.
	(Questo stimatore è chiamato
	<emphasis>leave-one-out</emphasis>).  Per una discussione più
	approfondita del criterio di validazione incrociata,
	v. Davidson e MacKinnon's <book>Econometric Theory and
	Methods</book>, pag. 685&ndash;686, e i riferimenti
	bibliografici ivi citati.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/LEVERAGE - Osservazioni influenti</menu-path>
    </gui-access>

  </command>

  <command name="levinlin" section="Tests" label="Levin-Lin-Chu test">

    <usage>
      <arguments>
        <argument>order</argument>
        <argument>series</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>test senza costante</effect>
	</option>
	<option>
	  <flag>--ct</flag>
	  <effect>con costante e trend</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
      </options>
      <examples>
	<example>levinlin 0 y</example>
        <example>levinlin 2 y --ct</example>
        <example>levinlin {2,2,3,3,4,4} y</example>
      </examples>
    </usage>

    <description>
      <para>
	Calcola il test di radice unitaria per dati panel di <cite
	key="LLC2002">Levin, Lin and Chu (2002)</cite>. L'ipotesi
	nulla che tutte le singole serie storiche contengano una
	radica unitaria, mentre l'alternativa è che nessuna delle
	serie storiche ne contenga una.  (In altre parole, si assume
	un coefficiente AR(1) comune a tutte le serie, anche se altre
	proprietà statistiche delle serie possono variare da un'unità
	di osservazione all'altra.)
      </para>
	
      <para context="cli">
	Di default le regressioni dei test ADF contengono una costante;
	per eliminarla usate l'opzione <opt>nc</opt>; per aggiungere 
	un trend lineare usate l'opzione <opt>ct</opt>. 
	(V. il comando <cmdref targ="adf"/> per una spiegazione delle 
	regressioni ADF.)
      </para>

      <para context="cli">
	Il valore (non negativo) <repl>order</repl> del numero di ritardi
	della variabile dipendente da usare nel test può essere indicato
	in due modi diversi. Se si fornisce uno scalare, questo viene applicato
	a tutte le serie nel panel. In alternativa è possibile fornire
	una matrice che contiene un particolare ordine di ritardo per ogni
	serie. La matrice deve essere un vettore con numero di elementi
	pari a quello delle unità di osservazione nel sottoinsieme corrente
	del campione, e può essere indicata per nome o costruita usando
	parentesi graffe come illustrato nell'ultimo degli esempi precedenti.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variable/Unit root tests/Levin-Lin-Chu test</menu-path>
    </gui-access>

  </command>

  <command name="loess" section="Estimation" label="Loess" context="gui">
    <description>
      <para>
	Stima una regressione polinomiale locally-weighted e produce
	una serie che contiene i valori previsti della variabile
	dipendente in corrispondenza di tutti i valori non missing
	della variabile indipendente.  Il metodo applicato è quello
	descritto da <cite key="cleveland79">William Cleveland
	(1979)</cite>.
      </para>
      <para>
	I parametri vi permettono di specificare l'ordine del polinomio
	nella variabile indipendente e la percentuale di punti osservati
	da utilizzare in ciascuna regressione locale (l'ampiezza di banda).
	Valori più elevati di quest'ultima generato un risultato più liscio.
      </para>
      <para>
	Se viene selezionata l'opzione dei pesi robusti la procedura
	di regressione locale è ripetuta due volte, modificando i pesi 
	sulla base dei residui ottenuti all'iterazione precedente in modo
	da assegnare un'influenza minore alle osservazioni anomale.
      </para>
     </description>
  </command>

  <command name="logistic" section="Estimation"
    label="Regressione logistica">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--ymax</flag>
	  <optparm>value</optparm>
	  <effect>specifica il massimo della variabile dipendente</effect>
	</option>	
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
      </options>
      <examples>
        <example>logistic y const x</example>
        <example>logistic y const x --ymax=50</example>
      </examples>
    </usage>

    <description>
      <para>
	Regressione logistica: esegue una regressione OLS usando la
        trasformazione logistica sulla variabile dipendente:
	<equation status="display" 
	  tex="\[\log\left(\frac{y}{y^*-y}\right)\]"
	  ascii="log(y/(y* - y))"
	  graphic="logistic1"/>
      </para>

      <para context="cli">La variabile dipendente dev'essere
        strettamente positiva. Se è una frazione decimale, compresa tra
        0 e 1, il valore predefinito per <math>y</math><sup>*</sup>
        (il massimo asintotico della variabile dipendente) è 1.
        Se la variabile dipendente è una percentuale, compresa tra 0 e
        100, il valore predefinito di <math>y</math><sup>*</sup>
        è 100.
      </para>
        
      <para context="cli">
        È possibile indicare un valore diverso per il massimo, usando
        l'opzione <opt>ymax</opt>. Il valore fornito deve essere
        maggiore di tutti i valori osservati della variabile
        dipendente.
      </para>
        
      <para context="gui">
        Nella finestra di dialogo del comando, è possibile specificare
        un valore diverso per il massimo. Il valore fornito deve essere
        maggiore di tutti i valori osservati della variabile dipendente.
      </para>

      <para>I valori stimati e i residui della regressione sono
        trasformati automaticamente usando 	  
	<equation status="display" 
	  tex="\[y=\frac{y^*}{1+e^{-x}}\]"
	  ascii="y = y* / (1 + exp(-x))"
	  graphic="logistic2"/> dove <math>x</math> rappresenta
	un valore stimato oppure un residuo della regressione OLS,
        usando la variabile dipendente trasformata. I valori riportati
        sono dunque confrontabili con la variabile dipendente originale.
	</para>

      <para>Si noti che se la variabile dipendente è binaria, occorre
        usare il comando <cmdref targ="logit"/> invece di questo comando.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Logistico</menu-path>
    </gui-access>

  </command>

  <command name="logit" section="Estimation"
    label="Regressione logit">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
	</option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>errori standard clusterizzati</effect>
        </option>
	<option>
	  <flag>--multinomial</flag>
	  <effect>stima un logit multinomiale</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
          <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--p-values</flag>
	  <effect>mostra i p-value invece delle pendenze</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Se la variabile dipendente è binaria (i suoi valori sono 0 o 1),
        esegue una stima di massima verosimiglianza dei coefficienti
        per le <repl>variabili-indipendenti</repl> con il
        metodo BRMR (<quote>binary response model regression</quote>) descritto
        in Davidson e MacKinnon (2004). Visto che il modello è nonlineare, le pendenze
        dipendono dai valori delle variabili indipendenti: per impostazione
        predefinita, al posto dei p-value vengono mostrate le pendenze rispetto ad
        ognuna delle variabili indipendenti, calcolate in corrispondenza della
        media della variabile. Questo comportamento può essere soppresso usando
        l'opzione <lit>--p-values</lit>.  La statistica chi-quadro testa
        l'ipotesi nulla che tutti i coefficienti tranne la costante siano pari a
        zero.
      </para>
      <para context="cli">
        In modalità predefinita, gli errori standard sono calcolati con
        l'inversa negativa dell'Hessiana.  Se si usa l'opzione
        <opt>robust</opt>, verranno calcolati gli errori standard QML o quelli
        di Huber&ndash;White. In questo caso, la matrice di covarianza stimata è
        un <quote>sandwich</quote> dell'inversa dell'Hessiana stimata e del
        prodotto esterno del gradiente. Per i dettagli, si veda Davidson e
        MacKinnon 2004, cap. 10.
      </para>
      <para context="gui">
        In modalità predefinita, gli errori standard sono calcolati con
        l'inversa negativa dell'Hessiana.  Se si seleziona la casella "Errori
        standard robusti", verranno calcolati gli errori standard QML o quelli
        di Huber&ndash;White. In questo caso, la matrice di covarianza stimata è
        un <quote>sandwich</quote> dell'inversa dell'Hessiana stimata e del
        prodotto esterno del gradiente. Per i dettagli, si veda Davidson e
        MacKinnon 2004, cap. 10.
      </para>
      <para>
        Se la variabile dipendente non è binaria, ma è discreta, si
        ottengono stime Logit ordinate. Tuttavia, se viene fornita
        l'opzione <opt>multinomial</opt>, la variabile dipendente è
        interpretata come non ordinale, e vengono prodotte stime Logit
        Multinomiali. (In ambo i casi, verrà dato un errore se la
        dipendente non è discreta.) Nel caso multinomiale, l'accessore
        <fncref targ="$mnlprobs"/> sarà disponibile dopo la stima; esso
        conterrà una matrice con le probabilità stimate dei possibili
        valori della dipendente per ogni osservazione (osservazioni
        per riga, valori per colonna).
      </para>
      <para>
	Per condurre un'analisi delle proporzioni (dove la variabile
	dipendente è la proporzione dei casi che hanno una certa
        caratteristica in ogni osservazione, invece che una variabile
        binaria che indica se la caratteristica è presente o no), non
        bisogna usare il comando <cmd>logit</cmd>, ma occorre costruire
        la variabile logit come
      </para>
      <code>
	genr lgt_p = log(p/(1 - p))
      </code>
      <para>
        e usare questa come variabile dipendente in una regressione OLS.
        Si veda <cite key="ramanathan02">Ramanathan (2002)</cite>, capitolo 12.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Logit</menu-path>
    </gui-access>

  </command>

  <command name="logs" section="Transformations" label="Crea logaritmi" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Calcola il logaritmo naturale di ognuna delle variabili
        della <repl>lista-variabili</repl> e lo salva in una nuova
        variabile col prefisso <lit>l_</lit>, ossia una
        <quote>elle</quote> seguita da un trattino basso. Ad esempio
        <cmd>logs x y</cmd> crea le nuove variabili <lit>l_x</lit> =
        ln(<lit>x</lit>) e <lit>l_y</lit> = ln(<lit>y</lit>).
      </para>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Logaritmi delle variabili selezionate</menu-path>
    </gui-access>

  </command>

  <command name="loop" section="Programming" label="Apre un ciclo di comandi" context="cli">

    <usage>
      <arguments>
        <argument>controllo</argument>
      </arguments>
      <options>
	<option>
	  <flag>--progressive</flag>
	  <effect>abilita modalità speciali di alcuni comandi</effect>
	</option>
        <option>
          <flag>--verbose</flag>
          <effect>mostra i dettagli dei comandi genr</effect>
        </option>
        <option>
          <flag>--quiet</flag>
          <effect>non mostra il numero di iterazioni eseguite</effect>
        </option>
      </options>
      <examples>
        <example>loop 1000</example>
	<example>loop 1000 --progressive</example>
        <example>loop while essdiff > .00001</example>
        <example>loop i=1991..2000</example>
        <example>loop for (r=-.99; r&lt;=.99; r+=.01)</example>
        <example>loop foreach i xlist</example>
      </examples>
    </usage>

    <description>
      <para>
        Questo comando apre una modalità speciale, in cui il programma accetta
        comandi da eseguire più volte.  Si esce dalla modalità loop con
        l'istruzione <cmd>endloop</cmd>: solo a questo punto i comandi indicati
        vengono eseguiti.
      </para>
      <para>Il parametro <repl quote="true">controllo</repl> deve
        assumere uno dei cinque valori mostrati negli esempi: un numero di volte
        per cui ripetere i comandi all'interno del loop;
        <quote><lit>while</lit></quote> seguito da una condizione booleana;
        un intervallo di valori interi per una variabile indice;
        <quote><lit>for</lit></quote> seguito
        da tre espressioni tra parentesi, separate da punti e virgola
        (in modo simile all'istruzione <lit>for</lit> nel
        linguaggio di programmazione C); infine, 
	<quote><lit>foreach</lit></quote> seguito da una variabile indice e una
        lista.
      </para>
      <para>
        Si veda la <guideref targ="chap:looping"/> per altri dettagli ed esempi,
        oltre che per la spiegazione dell'opzione <opt>progressive</opt> (che
        è destinata ad essere usata nelle simulazioni Monte Carlo) e per
        l'elenco dei comandi di gretl che possono essere usati all'interno di un
        loop.
      </para>
    </description>

  </command>
  
  <command name="mahal" section="Statistics"
    label="Distanze di Mahalanobis">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra nulla</effect>
        </option>
       <option>
         <flag>--save</flag>
         <effect>salva le distanze nel dataset</effect>
       </option>
       <option>
         <flag>--vcv</flag>
         <effect>mostra la matrice di covarianza</effect>
       </option>
      </options>
    </usage>

    <description>
      <para>
       La distanza di Mahalanobis è la distanza tra due punti in uno spazio
       <math>k</math>-dimensionale, scalata rispetto alla variazione
       statistica in ogni dimensione dello spazio. Ad esempio, se
       <math>p</math> e <math>q</math> sono due osservazioni su
       un insieme di <math>k</math> variabili con matrice di covarianza
       <math>C</math>, la distanza di Mahalanobis tra le due osservazioni
       è data da
       <equation status="display"
        tex="\[\sqrt{(p-q)^{\prime}C^{-1}(p-q)}\]"
        ascii="sqrt((p - q)' * C-inversa * (p - q))"
          graphic="mahal"/> dove
       <equation status="inline" tex="$(p-q)$" ascii="(p - q)" graphic="mahal2"/> è un
       vettore a <math>k</math> dimensioni. Se la matrice di covarianza è
       la matrice identità, la distanza di Mahalanobis corrisponde alla distanza
       Euclidea.
      </para>

      <para>Lo spazio in cui vengono calcolate le distanze è definito dalle
      variabili selezionate; per ogni osservazione nell'intervallo attuale
      viene calcolata la distanza tra l'osservazione e il centroide delle
      variabili selezionate. La distanza è la controparte multidimensionale di uno
      <math>z</math>-score standard e può essere usata per giudicare se una certa
      osservazione <quote>appartiene</quote> a un gruppo di altre osservazioni.
      </para>

      <para context="cli">Se si usa l'opzione <opt>vcv</opt>, vengono mostrate
      la matrice di covarianza e la sua inversa. Se si usa l'opzione
      <opt>save</opt>, le distanze vengono salvate nel dataset con il nome
      <lit>mdist</lit> (o <lit>mdist1</lit>, <lit>mdist2</lit> e così via, se
      esiste già una variabile con quel nome).
      </para>

      <para context="gui">Se il numero delle variabili selezionate è minore o
       uguale a 4, vengono mostrate la matrice di covarianza e la sua inversa.
       Facendo clic sul pulsante "+" in cima alla finestra che mostra le
       distanze è possibile aggiungerle al dataset come nuova variabile.
      </para>

    </description>

    <gui-access>
      <menu-path>/Visualizza/Distanze di Mahalanobis</menu-path>
    </gui-access>

  </command>

  <command name="makepkg" section="Programming" context="cli"
    label="Make function package">

    <usage>
      <arguments>
        <argument>filename</argument>
      </arguments>
      <options>
        <option>
	  <flag>--index</flag>
	  <effect>crea un file ausiliario di indicizzazione</effect>
        </option>
        <option>
	  <flag>--translations</flag>
	  <effect>crea un file ausiliario di stringhe</effect>
        </option>
      </options>
    </usage>    

    <description>
      <para>
	Permette la creazione di un <quote>function package</quote> da
	linea di comando. Il nome di file indica il nome del pacchetto
	da creare e deve avere estensione <lit>.gfn</lit>. Si veda
	<guideref targ="chap:functions"/> per dettagli.
      </para>
      <para>
	Le opzioni consentono la scrittura di file ausiliari per l'uso
	con gli <quote>addon</quote> di gretl. Il file indice è un
	breve documento XML contenente alcune informazioni base sul
	pacchetto; ha lo stesso nome del pacchetto stesso ed
	estensione <lit>.xml</lit>. Il file di traduzioni contiene le
	stringhe da tradurre del pacchetto, in formato C; per il
	pacchetto <lit>pippo</lit> questo file deve chiamarsi
	<lit>pippo-i18n.c</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Tools/Function packages/New package</menu-path>
    </gui-access>

  </command>

  <command name="markers" section="Dataset" label="Aggiunta di marcatori" context="cli">

    <usage>
      <altforms>
	<altform><lit>markers --to-file=</lit><repl>nomefile</repl></altform>
	<altform><lit>markers --from-file=</lit><repl>nomefile</repl></altform>
	<altform><lit>markers --delete</lit></altform>
      </altforms>
    </usage>

    <description>
      <para>
	Con l'opzione <opt>to-file</opt>, scrive nel file indicato le
	stringhe marcatrici delle osservazioni presenti nel dataset
	corrente, una per ogni linea. Se il dataset non contiene
	stringhe viene emesso un messaggio d'errore. Il file di output
	verrà scritto nella directory corrispondente al valore
	corrente di <cmdref targ="workdir"/>, a meno che il nome di file
	contenga un percorso completo.
      </para>
      <para>
	Con l'opzione <opt>from-file</opt>, legge dal file specificato
	(che deve essere in formato testo) e assegna alle righe del
	dataset i marcatori di osservazione, leggendone uno per
	riga. In generale il file dovrebbe contenere tanti marcatori
	quante sono le osservazioni nel dataset, ma se quest'ultimo è
	un panel il numero di marcatori nel file potrebbe anche essere
	pari al numero di unità in cross-section (nel qual caso i
	marcatori sono ripetuti a ogni data).
      </para>
      <para>
	L'opzione <opt>delete</opt> fa quello che vi aspettate: 
	cancella le stringhe marcatrici delle osservazioni dal dataset.
      </para>      
    </description>
  </command>

  <command name="meantest" section="Tests" label="Differenza delle medie">

    <usage>
      <arguments>
        <argument>var1</argument>
        <argument>var2</argument>
      </arguments>
      <options>
        <option>
	  <flag>--unequal-vars</flag>
	  <effect>assume varianze diverse</effect>
        </option>
      </options>
    </usage>

    <description>
      <para context="cli">
	Calcola la statistica <math>t</math> per l'ipotesi
	nulla che le medie della popolazione siano uguali per le
        variabili <repl>var1</repl> e <repl>var2</repl>, mostrando il
        suo p-value.
      </para>
      <para>
        L'impostazione predefinita prevede di assumere che
        le varianze delle due variabili siano uguali, mentre usando
        l'opzione <lit>--unequal-vars</lit>, si assume che esse siano
        diverse. Questo è rilevante per la statistica test solo se le
        due variabili contengono un diverso numero di osservazioni
        valide (non mancanti).
      </para>
      <para context="gui">
        Calcola la statistica t per l'ipotesi nulla che le medie della
        popolazione siano uguali per due variabili selezionate,
        mostrando il suo p-value. Il comando può essere eseguito con o
        senza l'ipotesi che le varianze delle due variabili siano uguali
        (anche se questo è rilevante per la statistica test solo se le
        due variabili contengono un diverso numero di osservazioni
        valide).</para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli bivariati/Differenza delle medie</menu-path>
    </gui-access>

  </command>

  <command name="missing" section="Dataset" context="gui"
    label="Valori dati mancanti">

    <description>
      <para>Imposta un valore numerico che sarà interpretato come
	<quote>mancante</quote> o <quote>non disponibile</quote>, per
        una serie particolare (nel menù Variabile) o globalmente per
        l'intero dataset (nel menù Campione).</para> 

      <para>Gretl ha un codice interno per i valori mancanti, che non
      sempre può coincidere con quello usato dai dati importati. Ad
      esempio, se una serie usa il valore -1 col significato di
      <quote>non disponibile</quote>, è possibile selezionare
      <quote>Imposta codice valori mancanti</quote> nel menù
      Variabile e immettere il valore <quote>-1</quote> (senza le
      virgolette); gretl interpreterà quindi i valori -1 come osservazioni
      mancanti.</para>
    </description>
  </command>

  <command name="menu-attach" section="Programming" 
	   label="Menu attachment" context="gui">
    <description>
      <para>
	Questa finestra di dialogo permette di specificare a quale
	menu attaccare il pacchetto. A tal fine, bisogna riempire i
	tre campi previsti.
      </para>
      <subhead>Etichetta</subhead>
      <para>
	Una breve stringa, che apparirà nel menu.
      </para>
      <subhead>Finestra</subhead>
      <para>
	Selezionare <quote>finestra del modello</quote> per un
	pacchetto che fa qualcosa copn un modello stimato da gretl, e
	deve apparire nella barra del menu di un modello. In tutti gli
	altri casi, selezionare <quote>finestra principale</quote>.
      </para>
      <subhead>Albero del menu</subhead>
      <para>
	Selezionare la posizione nell'albero del menu (per la finestra
	principale o per la finestra del modello, come da scelta
	sopra) dove il pacchetto deve apparire.
      </para>
    </description>
  </command>

  <command name="mle" section="Estimation"
    label="Stima di massima verosimiglianza">

    <usage>
      <arguments>
        <argument>funzione di log-verosimiglianza</argument>
        <argument>derivate</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa il modello stimato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--hessian</flag>
	  <effect>calcola la matrice di covarianza a partire dall'Hessiana</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>matrice di covarianza QML</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--no-gradient-check</flag>
	  <effect>si veda sotto</effect>
	</option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa L-BFGS-B invece di BFGS</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>weibull.inp</demo>
	</demos>
      </examples>
    </usage>

    <description context="gui">

      <para>Esegue la stima di massima verosimiglianza (ML, Maximum
        Likelihood) usando l'algoritmo BFGS (Broyden, Fletcher, Goldfarb, Shanno).
        Occorre specificare la funzione di log-verosimiglianza, e se possibile è
        consigliabile indicare anche espressioni per le derivate di questa
        funzione, rispetto ad ognuno dei parametri.
      </para>

      <para>
        Esempio: si supponga di avere una serie <lit>X</lit> con
        valori 0 o 1 e di voler ottenere la stima di massima
        verosimiglianza della probabilità <lit>p</lit> che
        <lit>X</lit> valga 1 (è semplice intuire che la stima ML di
        <lit>p</lit> corrisponderà alla proporzione dei valori 1 nel
        campione).
      </para>

      <para>Occorre per prima cosa aggiungere <lit>p</lit> al dataset
      e assegnargli un valore iniziale, attraverso il comando
      <cmd>genr</cmd> o i comandi del menù.  È possibile scrivere
      delle istruzioni <quote>genr</quote> appropriate nella finestra
      di specificazione del comando di stima, prima di indicare la
      specificazione della funzione di log-verosimiglianza.
      </para>

      <para>Si scrivano i seguenti comandi nella finestra del comando:</para>

      <code>
	loglik = X*log(p) + (1-X)*log(1-p)
	deriv p = X/p - (1-X)/(1-p)
      </code>

      <para>
	La prima riga specifica la funzione di log-verosimiglianza, mentre
        la seconda indica la derivata della funzione rispetto a p. Se non si
        indicanto righe "deriv", viene calcolata un'approssimazione numerica
        delle derivate.
      </para>

      <para>
	Se non si era dichiarato in precedenza il parametro p, sarebbe stato
        necessario premettere alle righe precedenti la riga:
      </para>

      <code>
	genr p = 0.5
      </code>

      <para>
	Per impostazione predefinita, gli errori standard sono basati sul
        prodotto esterno del gradiente. Se si richiedono errori standard
        robusti, viene usato uno stimatore QML (ossia, un sandwich dell'inversa
        negativa dell'Hessiana e della matrice di covarianza del gradiente).
        L'Hessiana è approssimata numericamente.
      </para>

    </description>

    <description context="cli">

      <para>Esegue la stima di massima verosimiglianza (ML, Maximum
        Likelihood) usando l'algoritmo BFGS (Broyden, Fletcher, Goldfarb, Shanno).
        Occorre specificare la funzione di log-verosimiglianza e indicare dei
        valori iniziali per i parametri della funzione (utilizzando il comando
        <cmd>genr</cmd>.  Se possibile è consigliabile indicare anche
        espressioni per le derivate di questa funzione, rispetto ad ognuno dei
        parametri; se non si indicano le derivate analitiche, verrà calcolata
        un'approssimazione numerica.
      </para>

      <para>
        Esempio: si supponga di avere una serie <lit>X</lit> con
        valori 0 o 1 e di voler ottenere la stima di massima
        verosimiglianza della probabilità <lit>p</lit> che
        <lit>X</lit> valga 1 (è semplice intuire che la stima ML di
        <lit>p</lit> corrisponderà alla proporzione dei valori 1 nel
        campione).
      </para>

      <para>Occorre per prima cosa aggiungere <lit>p</lit> al dataset
      e assegnargli un valore iniziale; ad esempio, <lit>scalar p = 0.5</lit>.
	</para>

      <para>Quindi costruiamo il blocco di comandi per la stima di massima
      verosimiglianza:</para>

      <code>
       mle loglik = X*log(p) + (1-X)*log(1-p)
       deriv p = X/p - (1-X)/(1-p)
       end mle
      </code>

      <para>
        La prima riga specifica la funzione di log-verosimiglianza: inizia con
        la parola chiave <lit>mle</lit>, quindi contiene la variabile
        dipendente e una specificazione per la log-verosimiglianza usando la
        stessa sintassi del comando <cmd>genr</cmd>. La riga seguente (che è
        opzionale), inizia con la parola chiave <lit>deriv</lit> e fornisce
        la derivata della funzione di log-verosimiglianza rispetto al parametro
        <lit>p</lit>. Se non vengono indicate derivate, occorre includere una
        dichiarazione che identifica i parametri liberi (separati da spazi)
        utilizzando la parola chiave <lit>params</lit>. Ad esempio si
        sarebbe potuto scrivere:
      </para>
      <code>
       mle loglik = X*log(p) + (1-X)*log(1-p)
       params p
       end mle
      </code>
      <para>
       e in questo caso la derivata verrebbe calcolata numericamente.
      </para>
      <para>
       Si noti che eventuali opzioni vanno indicate nella riga finale del blocco
       MLE.
      </para>

      <para>
	Per impostazione predefinita, gli errori standard sono basati sul
        prodotto esterno del gradiente. Se si usa l'opzione
        <opt>hessian</opt>, vengono basati sull'inversa
        negativa dell'Hessiana (che è approssimata numericamente). Se si usa
        l'opzione <opt>robust</opt>, viene usato uno stimatore QML
        (ossia, un sandwich dell'inversa negativa dell'Hessiana e della matrice
        di covarianza del gradiente).
      </para>
      <para>
	Se vengono fornite derivate analitiche, per default gretl effettua un
	controllo numerico per valutarne l'attendibilità. Talvolta questo controllo
	può produrre dei falsi positivi; altre parole derivate corrette sembrano 
	essere errate e il comando si rifiuta di completare la stima. Per evitare
	questa possibilità o per realizzare un piccolo guadagno in termini
	di tempo è possibile ricorrere all'opzione 
	<opt>no-gradient-check</opt>. Naturalmente è opportuno ricorrere a questa opzione
	solo se si è convinti convinti della correttezza del gradiente specificato.
      </para>
      <para>
	Per una descrizione molto più approfondita di <cmd>mle</cmd>, per favore 
	consultate <guideref targ="chap:mle"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Massima verosimiglianza</menu-path>
    </gui-access>

  </command>

  <command name="modeltab" section="Utilities"
    label="Tabella modelli">

    <usage>
      <altforms>
        <altform><lit>modeltab add</lit></altform>
	<altform><lit>modeltab show</lit></altform>
	<altform><lit>modeltab free</lit></altform>
	<altform><lit>modeltab --output=</lit><repl>nomefile</repl></altform>
      </altforms>
    </usage>

    <description context="gui"> 
      <para>
	Nella ricerca econometrica si è soliti stimare vari modelli con una
        variabile dipendente comune, che differiscono tra loro per le variabili
        indipendenti o per lo stimatore usato.  In questa situazione è comodo
        poter rappresentare i risultati delle regressioni sotto forma di una
        tabella dove ogni colonna contiene i risultati (stime dei coefficienti
        e errori standard) per un dato modello e ogni riga contiene le stime
        per una certa variabile nei differenti modelli.</para>

      <para>Gretl dà la possibilità di costruire una tabella simile (e
      di esportarla in testo semplice, &latex; o RTF - Rich Text Format).
      Ecco come fare:</para>

      <nlist>
	<li><para>Stimare un modello che si vuole includere nella
            tabella e selezionare, nel menù File della finestra di
            visualizzazione del modello, <quote>Salva alla sessione come
            icona</quote> o <quote>Salva come icona e chiudi</quote>.</para>
	</li>

	<li><para>Ripetere il punto 1 per gli alri modelli da
        includere nella tabella (fino a un massimo di sei modelli).</para>
	</li>

	<li><para>Completata la stima dei modelli, aprire l'icona
        della sessione di gretl (selezionando <quote>Visualizza Icone</quote>
        nel menù Sessione della finestra principale di gretl, o facendo
        clic su <quote>Finestra icone</quote> sulla barra degli
        strumenti di gretl).</para>
	</li>

        <li><para>La finestra delle icone contiene un'icona chiamata
        <quote>Tabella Modelli</quote>. Per aggiungere alla tabella
        modelli il modello che deve apparire nella colonna più a
        sinistra della tabella, basta trascinare l'icona del modello
        sull'icona della Tabella Modelli, oppure fare clic col tasto
        destro sull'icona del modello e selezionare <quote>Aggiungi
        alla tabella modelli</quote> dal menù pop-up.</para>
	</li>

	<li><para>Ripetere il punto 4 per gli altri modelli da
        aggiungere alla tabella. Il secondo modello scelto apparirà
        nella seconda colonna da sinistra della tabella, e così via.
	</para>
	</li>

	<li><para>Ultimata la composizione della tabella, è possibile
        visualizzarla facendo doppio clic sulla sua icona. Per copiare
        la tabella negli appunti in uno dei formati supportati, basta
        fare clic sul menù Modifica della finestra in cui appare la
        tabella.</para>
	</li>

	<li><para>Se l'ordinamento dei modelli nella tabella non è
        quello voluto, fare clic col tasto destro sull'icona della
        tabella modelli e selezionare <quote>Pulisci</quote>, quindi
        tornare al punto 4.</para>
	</li>
      </nlist>
    </description>

    <description context="cli">
      <para>Manipola la <quote>tabella modelli</quote> di gretl. Si veda la
      	<guideref targ="chap:modes"/> per i dettagli. Le opzioni hanno i
        seguenti effetti: <cmd>add</cmd> aggiunge l'ultimo modello
        stimato alla tabella modelli, se possibile; <cmd>show</cmd>
	mostra la tabella modelli in una finestra; <cmd>free</cmd>
	pulisce la tabella.</para>
      <para>
	Per stampare la tabella del modello usate l'opzione
	<opt>output=</opt> seguita dal nome di un file. Se
	quest'ultimo ha il suffisso <quote><lit>.tex</lit></quote>,
	l'output sarà in formato &tex;; se il suffisso è
	<quote><lit>.rtf</lit></quote> l'output sarà RTF; in caso
	contrario sarà in formato di testo. Nel caso di output in
	formato &tex; per default verrà prodotto un
	<quote>frammento</quote> pronto per essere inserito in un
	documento; se invece si preferisce ottenere un documento
	completo, usate l'opzione <opt>complete</opt>; per esempio,
      </para>
      <code>
	modeltab --output="myfile.tex" --complete
      </code>

    </description>

    <gui-access>
      <menu-path>Finestra delle icone, Icona Tabella Modelli</menu-path>
    </gui-access>

  </command>

  <command name="modprint" section="Printing"
    label="Stampa un modello definito dall'utente" context="cli">

    <usage>
      <arguments>
        <argument>matcoeff</argument>
        <argument>nomi</argument>
	<argument optional="true">stat</argument>
      </arguments>
      <option>
	<flag>--output</flag>
	<optparm>filename</optparm>
	<effect>invia l'output al file specificato</effect>
      </option>
    </usage>

    <description>
      <para>
        Stampa la tabella dei coefficienti e le statistiche aggiuntive opzionali
        per un modello stimato <quote>a mano</quote>. Utile principalmente per
        le funzioni definite dall'utente.
      </para>
      <para>
	L'argomento <repl>matcoeff</repl> deve essere una matrice <math>k</math> per 2
	che contiene <math>k</math> coefficienti e <math>k</math> errori
        standard associati, mentre <repl>nomi</repl> deve essere una stringa che
        contiene almeno <math>k</math> nomi, separati da virgole, per i
        coefficienti.
      </para>
      <para>
	L'argomento opzionale <repl>stat</repl> è un vettore che contiene
	<math>p</math> statistiche aggiuntive da stampare sotto la tabella dei
        coefficienti. Se si usa questo argomento, <repl>nomi</repl> deve
        contenere <math>k + p</math> stringhe separate da virgola, di cui le
        ultime <math>p</math> sono associate alle statistiche aggiuntive.
      </para>
      <para>
	Per inviare l'output ad un file, usate l'opzione
	<opt>output=</opt> seguita dal nome di un file. Se
	quest'ultimo ha il suffisso <quote><lit>.tex</lit></quote>,
	l'output sarà in formato &tex;; se il suffisso è
	<quote><lit>.rtf</lit></quote> l'output sarà RTF; in caso
	contrario sarà in formato di testo. Nel caso di output in
	formato &tex; per default verrà prodotto un
	<quote>frammento</quote> pronto per essere inserito in un
	documento; se invece si preferisce ottenere un documento
	completo, usate l'opzione <opt>complete</opt>.
      </para>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo. 
      </para>
    </description>

  </command>

  <command name="modtest" section="Tests" label="Test LM">

    <usage>
      <arguments>
        <argument optional="true">ordine</argument>
      </arguments>
      <options>
        <option>
	  <flag>--normality</flag>
	  <effect>normalità dei residui</effect>
        </option>
        <option>
	  <flag>--logs</flag>
	  <effect>non-linearità, logaritmi</effect>
        </option>
        <option>
	  <flag>--autocorr</flag>
	  <effect>correlazione seriale</effect>
        </option>
        <option>
	  <flag>--arch</flag>
	  <effect>ARCH</effect>
        </option>
        <option>
	  <flag>--squares</flag>
	  <effect>non-linearità, quadrati</effect>
        </option>
        <option>
	  <flag>--white</flag>
	  <effect>eteroschedasticità, test di White</effect>
        </option>
        <option>
	  <flag>--white-nocross</flag>
	  <effect>eteroschedasticità, test di White (solo quadrati)</effect>
        </option>
        <option>
	  <flag>--breusch-pagan</flag>
	  <effect>eteroschedasticità, test di Breusch&ndash;Pagan</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>stima robusta della varianza per Breusch&ndash;Pagan</effect>
        </option>
        <option>
	  <flag>--panel</flag>
	  <effect>eteroschedasticità, a gruppi</effect>
        </option>
        <option>
	  <flag>--comfac</flag>
	  <effect>restrizione a fattore comune, (solo modelli AR1)</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra la regressione ausiliaria</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
        Deve seguire immediatamente un comando di stima. A seconda
        dell'opzione usata, il comando esegue uno dei test seguenti:
        test di Doornik&ndash;Hansen per la normalità del termine di
        errore; test dei moltiplicatori di Lagrange per la
        non-linearità (logaritmi o quadrati); test di White (con o
        senza i prodotti incrociati) o test di Breusch&ndash;Pagan per
        l'eteroschedasticità (<cite key="breusch-pagan79">Breusch and
        Pagan, 1979</cite>), test LMF per la correlazione seriale (si
        veda <cite key="kiviet86" p="true">(Kiviet, 1986)</cite>);
        test per il modello ARCH (Autoregressive Conditional
        Heteroskedasticity, si veda anche il comando <cmd>arch</cmd>);
        o restrizione a fattore comune, (solo modelli AR1). La maggior
        parte delle opzioni sono disponibili solo per modelli stimati
        con OLS, ma si veda oltre per alcuni dettagli riguardanti la
        stima con i minimi quadrati a due stadi.
      </para>
      <para>
	L'argomento opzionale <lit>ordine</lit> è rilevante solo nel caso si
        scelga l'opzione <opt>autocorr</opt> o l'opzione <opt>arch</opt>.
        Per impostazione predefinita, questi test sono eseguiti usando un ordine
        di ritardo pari alla periodicità dei dati, ma è possibile anche
        impostare un ordine di ritardo specifico.
      </para>
       <para>
	L'opzione <opt>robust</opt> ha effetto solo se viene scelto
	il test di Breusch&ndash;Pagan; l'effetto è quello di usare lo
	stimatore robusto per la varianza proposto da <cite
	key="koenker81">Koenker (1981)</cite>, rendendo il test meno
	sensibile all'ipotesi di normalità.
      </para>
      <para>
	L'opzione <opt>panel</opt> è disponibile solo se il modello viene
        stimato su dati panel: in questo caso viene eseguito un test per
        eteroschedasticità a gruppi (ossia per una varianza dell'errore diversa
        fra le unità cross section).
      </para>
      <para>
	L'opzione <opt>comfac</opt> è disponibile solo quando il modello è stimato
	usando un metodo AR(1), come quello di Hildreth&ndash;Lu. La regressione ausiliaria
	ha la struttura di un modello dinamico relativamente poco vincolato ed è usata
	per verificare il vincolo di fattori comuni implicito nella specificazione AR(1).
      </para>
      <para>
	Per impostazione predefinita, il programma mostra la regressione
        ausiliaria su cui si basa la statistica test, ma è possibile evitarlo
        usando l'opzione <opt>quiet</opt>. La statistica test e il suo p-value
        possono essere recuperati usando le variabili accessorie <fncref targ="$test"/>
        e <fncref targ="$pvalue"/>.
      </para>
      <para>
        Nel caso di modelli stimati col metodo dei minimi quadrati a due stadi
        (si veda <cmdref targ="tsls"/>), non è possibile usare il test LM, quindi
        gretl offre alcuni test equivalenti; in questo caso, l'opzione
        <flag>--autocorr</flag> calcola il test di Godfrey per
        l'autocorrelazione (si veda Godfrey 1994),
        mentre l'opzione <flag>--white</flag> produce il test HET1 per
        l'eteroschedasticità (si veda Pesaran e Taylor 1999).
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test</menu-path>
    </gui-access>

  </command>

  <command name="mpols" section="Estimation"
    label="Stima OLS a precisione multipla">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
	<option>
	  <flag>--simple-print</flag>
	  <effect>non mostra le statistiche ausiliarie</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Calcola le stime OLS per il modello indicato usando aritmetica
        in virgola mobile a precisione multipla. Questo comando è
        disponibile solo se <program>gretl</program> è compilato con il
        supporto per la libreria Gnu Multiple Precision (GMP). Per impostazione
        predefinita, vengono usati 256 bit di precisione nei calcoli, ma è
        possibile aumentare questo valore usando la variabile d'ambiente
        <lit>GRETL_MP_BITS</lit>.  Ad esempio, usando l'interprete dei comandi
        bash, è possibile aumentare la precisione a 1024 bit eseguendo il
        comando seguente prima di avviare gretl
      </para>
      <code>
	export GRETL_MP_BITS=1024
      </code>

      <para context="cli">
	Per questo comando è disponibile un'opzione abbastanza speciale (utile
        soprattutto a scopo di test): se la lista <repl>variabili-indipendenti</repl>
        è seguita da un punto e virgola, e da un'ulteriore lista di numeri,
        questi numeri vengono interpretati come potenze di <repl>x</repl> da aggiungere
        alla regressione, dove <repl>x</repl> è l'ultima variabile della lista
        <repl>variabili-indipendeti</repl>. Questi termini addizionali vengono
        calcolati e memorizzati in precisione multipla. Nell'esempio seguente,
	<lit>y</lit> è regredita su <lit>x</lit> e sulla seconda, terza e quarta
        potenza di <lit>x</lit>:
      </para>
      <code context="cli">
	mpols y 0 x ; 2 3 4
      </code>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/MPOLS - Minimi quadrati in alta precisione</menu-path>
    </gui-access>

  </command>

  <command name="nadarwat" section="Estimation" label="Nadaraya-Watson" 
	   context="gui">
    <description>
      <para>
	Calcola lo stimatore nonparametrico di Nadaraya&ndash;Watson
	per la media condizionale della variabile dipendente,
	<math>m(x)</math>, per ogni valore valido della variabile
	<math>x</math>.
      </para>
      <para>
	La funzione kernel <math>K</math> è data da <math>K =
	exp(-x</math><sup>2</sup><math> / 2h)</math> per <math>|x|
	&lt; T</math> e zero altrove.
      </para>
      <para>
	L'ampiezza di banda, che di solito è un numero piccolo,
	controlla quanto liscia debba essere la funzione
	<math>m(x)</math> (più è alto il valore, più liscia sarà la
	funzione); il valore di default è <math>n</math><sup>-0.2</sup>.
      </para>
      <para>
	Se viene spillata la casella <quote>escludine uno</quote>,
	verrà usata una variante dello stimatore in cui la
	<math>i</math>-esima osservazione non viene usata per
	calcolare <math>m(x</math><sub>i</sub><math>)</math>. Questo
	rende lo stimatore Nadaraya&ndash;Watson più robusto
	numericamente e il suo uso è, di norma, consigliabile quando
	lo stimatore è usato per l'inferenza.
      </para>
     </description>
  </command>

  <command name="negbin" section="Estimation"
    label="Negative Binomial regression">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
	<argument separated="true" optional="true">offset</argument>
      </arguments>
      <options>
	<option>
	  <flag>--model1</flag>
	  <effect>usa il modello NegBin 1</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>matrice di covarianza QML</effect>
	</option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>vedi <cmdref targ="logit"/> per una spegazione</effect>
        </option>
	<option>
	  <flag>--opg</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>stampa la matrice di covarianze</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
      </options>
    </usage>  

    <description>
      <para>
	Stima un modello Binomiale Negativo.  Il comando assume che la
	variabile dipendente rappresenti un conteggio del numero di
	volte in cui si è verificato un certo evento e deve assumere
	solo valori interi non negativi. Di default, viene usata la
	distribuzione NegBin 2, in cui la varianza condizionale è data
	da &mu;(1 + &alpha;&mu;), dove &mu; denota la media
	condizionale.  Tuttavia, se vien data l'opzione
	<opt>model1</opt> allora la varianza condizionale sarà data
	da &mu;(1 + &alpha;).
      </para>
      <para>
	L'argomento opzionale <lit>offset</lit> funziona come per il
	comando <cmdref targ="poisson"/>.  In effetti, il modello di
	Poisson è un caso particolare del binomiale negativo con
	&alpha; = 0.
      </para>
      <para>
	Di default, gli errori standard vengono calcolati unsando
	un'approssimazione numerica dell'Hessiana sul punto di
	massimo.  Con l'opzione <opt>opg</opt> la matrice di
	covarianze verrà invece calcolata tramite il prodotto esterno
	dei gradienti (OPG), o via QML con l'opzione <opt>robust</opt> usando un
	<quote>sandwich</quote> dell'hessiana inversa e dell'OPG.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Nonlinear models/Count data...</menu-path>
    </gui-access>
  </command>

  <command name="nls" section="Estimation" label="Minimi quadrati non-lineari">

    <usage>
      <arguments>
        <argument>funzione</argument>
        <argument optional="true">derivate</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa il modello stimato</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>wg_nls.inp</demo>
	</demos>
      </examples>
    </usage>

    <description context="gui">

      <para>
        Esegue una stima con minimi quadrati non-lineari (NLS:
        Nonlinear Least Squares) usando una versione modificata
        dell'algoritmo di Levenberg&ndash;Marquardt. Occorre fornire una
        specificazione di funzione e si raccomanda di specificare anche le
        espressioni per le derivate di questa funzione rispetto a ognuno
        dei parametri, se possibile. Se non si indicano le derivate, occorre
        fornire una lista dei parametri da stimare (separati da spazi o virgole),
        preceduta dalla parola chiave <lit>params</lit>.
      </para>

      <para>
        Esempio: si supponga di avere un dataset con le variabili
        <math>C</math> e <math>Y</math> (ad es.
        <lit>greene11_3.gdt</lit>) e di voler stimare una funzione di consumo
        non-lineare del tipo:
	<equation status="display"
	  tex="\[C = \alpha + \beta Y^{\gamma}\]"
	  ascii="C = alfa + beta * Y^gamma"
	  graphic="greene_Cfunc"/></para>

      <para>I parametri alfa, beta e gamma devono per prima cosa essere
      aggiunti al dataset, indicando un valore iniziale; è possibile
      farlo usando il comando genr o attraverso i menù. È possibile
      inserire i comandi <quote>genr</quote> appropriati nella finestra
      di dialogo della specificazione NLS prima di specificare la
      funzione.</para>

      <para>Nella finestra NLS si inseriranno le righe seguenti:</para>

      <code>
	C = alfa + beta * Y^gamma
	deriv alfa = 1
	deriv beta = Y^gamma
	deriv gamma = beta * Y^gamma * log(Y)
      </code>

      <para>La prima riga indica la specificazione della funzione, mentre
      le righe successive forniscono le derivate della funzione rispetto
      ad ognuno dei tre parametri. Se non vengono fornite le righe
      "deriv", viene calcolata un'approssimazione numerica del
      Jacobiano.</para>

      <para>Se i parametri alfa, beta e gamma non sono stati
      dichiarati in precedenza, è possibile premettere alle righe viste
      sopra le seguenti:</para>

      <code>
	genr alpha = 1
	genr beta = 1
	genr gamma = 1
      </code>

      <para>Per ulteriori dettagli sulla stima NLS si veda la
	<guideref targ="chap:nls"/>.</para>

    </description>

    <description context="cli">

      <para>
        Esegue una stima con minimi quadrati non-lineari (NLS: Nonlinear Least
        Squares) usando una versione modificata dell'algoritmo di
        Levenberg&ndash;Marquardt. Occorre fornire una specificazione di
        funzione e dichiarare i parametri della funzione (usando il comando
        <cmd>genr</cmd>) prima della stima.  Opzionalmente, è anche possibile
        specificare le espressioni per le derivate della funzione rispetto a
        ognuno dei parametri. Se non si indicano le derivate, occorre fornire
        una lista dei parametri da stimare (separati da spazi o virgole),
        preceduta dalla parola chiave <lit>params</lit>. In quest'ultimo caso,
        viene calcolata un'approssimazione numerica del Jacobiano.
      </para>

      <para>
	È più semplice mostrare il funzionamento con un esempio. Quello
        che segue è uno script completo per stimare la funzione di
        consumo non-lineare presentata in <book>Econometric
        Analysis</book> di William Greene (capitolo 11 della quarta
        edizione, o capitolo 9 della quinta). I numeri alla sinistra
        delle righe sono dei punti di riferimento e non fanno parte dei
        comandi. Si noti che le opzioni, come ad esempio <opt>vcv</opt> per mostrare la
	matrice di covarianza delle stime dei parametri, vanno aggiunte al
        comando finale <lit>end nls</lit>.
      </para>

      <code>
	1   open greene11_3.gdt
	2   ols C 0 Y
	3   genr a = $coeff(0)
	4   genr b = $coeff(Y)
	5   genr g = 1.0
	6   nls C = a + b * Y^g
	7   deriv a = 1
	8   deriv b = Y^g
	9   deriv g = b * Y^g * log(Y)
	10  end nls --vcv
      </code>

      <para>
	Spesso è comodo inizializzare i parametri con riferimento a un
        modello lineare collegato, come è mostrato nelle righe da 2 a 5.
	I parametri alfa, beta e gamma possono essere impostati a
        qualunque valore iniziale (non necessariamente sulla base di un
        modello stimato con OLS), ma la convergenza della procedura NLS
        non è garantita per qualunque punto di partenza.</para>

      <para>
	I veri comandi NLS occupano le righe da 6 a 10. Sulla riga 6
        viene dato il comando <cmd>nls</cmd>: viene specificata una
        variabile dipendente, seguita dal segno uguale, seguito da una
        specificazione di funzione. La sintassi per l'espressione a
        destra è la stessa usata per il comando <cmd>genr</cmd>. Le tre
        righe successive specificano le derivate della funzione di
        regressione rispetto a ognuno dei parametri. Ogni riga inizia
        con il comando <cmd>deriv</cmd>, indica il nome di un parametro,
        il segno di uguale e un'espressione che indica come calcolare la
        derivata (anche qui la sintassi è la stessa di <cmd>genr</cmd>).
        In alternativa, invece di fornire le derivate, è possibile sostituire
        le righe dalla 7 alla 9 con la seguente:
      </para>
      <code>
	params a b g
      </code>
      <para> 
        La riga 10, <cmd>end nls</cmd>, completa il comando ed esegue la stima.
      </para>

      <para>Per ulteriori dettagli sulla stima NLS si veda la
	<guideref targ="chap:nls"/>.</para>

    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/NLS - Minimi quadrati non lineari</menu-path>
    </gui-access>

  </command>
 
  <command name="normtest" section="Tests"
    label="Test di normalità">

    <usage>
      <arguments>
        <argument>series</argument>
      </arguments>
      <options>
	<option>
	  <flag>--dhansen</flag>
	  <effect>test Doornik&ndash;Hansen</effect>
        </option>
	<option>
	  <flag>--swilk</flag>
	  <effect>test di Shapiro&ndash;Wilk</effect>
        </option>
        <option>
         <flag>--lillie</flag>
         <effect>test di Lilliefors</effect>
        </option>
	<option>
	  <flag>--jbera</flag>
	  <effect>test di Jarque&ndash;Bera</effect>
        </option>
        <option>
         <flag>--all</flag>
         <effect>esegue tutti i test</effect>
        </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i dettagli dei risultati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Conduce un test di normalità per la <repl>serie</repl> specificata. Il
        tipo di test eseguito è determinato dalle opzioni del comando (se non ne
        viene usata alcuna, viene eseguito il test di Doornik&ndash;Hansen). Si
        noti che il test di Jarque&ndash;Bera test, sebbene semplice da
        calcolare, ha un'accuratezza relativamente bassa in campioni limitati,
        quindi se ne raccomanda l'uso principalmente a scopo di confronto.
      </para>
      <para>
	La statistica test e il suo p-value possono essere recuperati usando gli
        accessori <fncref targ="$test"/> e <fncref targ="$pvalue"/>. Se si usa l'opzione
        <opt>all</opt>, i risultati salvati saranno queslli del test di
        Doornik&ndash;Hansen.
      </para>
    </description>

  </command>

  <command name="nulldata" section="Dataset"
    label="Creazione di un dataset vuoto">

    <usage>
      <arguments>
        <argument>lunghezza_serie</argument>
      </arguments>
      <options>
	<option>
	  <flag>--preserve</flag>
	  <effect>preserva le matrici</effect>
        </option>
      </options>
      <examples>
        <example>nulldata 500</example>
      </examples>
    </usage>

    <description>
      <para>
	Crea un dataset <quote>vuoto</quote>, che contiene solo una
        costante e una variabile indice, con periodicità 1 e il numero
        indicato di osservazioni. Ad esempio, è possibile creare un dataset
        a scopo di simulazione usando alcuni comandi <cmd>genr</cmd> (come
        <cmd>genr uniform()</cmd> e <cmd>genr normal()</cmd>) per generare
        dati di prova. Questo comando può essere usato insieme a
        <cmd>loop</cmd>.  Si veda anche l'opzione <quote>seed</quote> del
        comando <cmdref targ="set"/>.
      </para>
      <para>
	Per impostazione predefinita, questo comando cancella tutti i dati
        presenti nell'ambiente di lavoro di gretl. Usando l'opzione
        <opt>preserve</opt>, verranno mantenute tutte le matrici attualmente
        definite.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Nuovo dataset</menu-path>
    </gui-access>

  </command>

  <command name="ols" section="Estimation"
    label="Minimi quadrati ordinari">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
         <option>
	  <flag>--jackknife</flag>
	  <effect>vedi sotto</effect>
        </option>
        <option>
	  <flag>--simple-print</flag>
	  <effect>non mostra le statistiche ausiliarie</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
         <option>
         <flag>--anova</flag>
         <effect>stampa una tabella ANOVA</effect>
        </option>
        <option>
	  <flag>--no-df-corr</flag>
	  <effect>sopprime la correzione per i gradi di libertà</effect>
        </option>
        <option>
	  <flag>--print-final</flag>
	  <effect>si veda sotto</effect>
        </option>
      </options>
      <examples>
        <example>ols 1 0 2 4 6 7</example>
	<example>ols y 0 x1 x2 x3 --vcv</example>
	<example>ols y 0 x1 x2 x3 --quiet</example>
      </examples>
    </usage>

    <description>
      <para context="gui">
        Calcola le stime minimi quadrati ordinari (OLS: Ordinary Least
        Squares) per il modello specificato.
      </para>

      <para context="cli">
        Calcola le stime minimi quadrati ordinari (OLS: Ordinary Least
        Squares) usando la <repl>variabile-dipendente</repl> e la lista
        di <repl>variabili-indipendenti</repl>, che possono essere 
        specificate per nome o numero. Il termine costante può essere
        indicato usando il numero 0.
      </para>

      <para>Oltre alle stime dei coefficienti e agli errori standard, il
        programma mostra i p-value per le statistiche <math>t</math>
	(a due code) e <math>F</math>.  Un p-value inferiore a
	0.01 indica significatività al livello dell'1 per cento ed è
        denotato con <lit>***</lit>. <lit>**</lit> indica invece la
        significatività tra l'1 e il 5 per cento, mentre <lit>*</lit>
	indica un livello di significatività tra il 5 e il 10 per cento.
	Vengono mostrate anche le statistiche di selezione del modello
        (il criterio di informazione di Akaike, AIC, e il criterio di
        informazione bayesiana di Schwarz, BIC). La formula usata per AIC
        è descritta in Akaike (1974), ossia meno due volte la log-verosimiglianza
        massimizzata più il doppio del numero di parametri stimati.</para>

      <para context="cli">Usando l'opzione <lit>--no-df-corr</lit> la correzione per i
	gradi di libertà non viene applicata nel calcolo della varianza
        stimata dell'errore (e quindi anche dell'errore standard delle
        stime dei parametri).</para>

      <para context="cli">L'opzione <lit>--print-final</lit> è utilizzabile solo nel contesto
	di un <cmdref targ="loop"/>. L'effetto è quello di eseguire la
        regressione in modo silenzioso per tutte le iterazioni del loop
        tranne l'ultima. Si veda la <guideref targ="chap:looping"/> per i dettagli.
      </para>

      <para context="cli">È possibile salvare alcune variabili
      interne generate durante la stima, usando il comando <cmdref
      targ="genr"/> subito dopo questo comando.
      </para>

      <para context="cli">La formula usata per generare gli errori
      standard robusti (quando viene usata l'opzione
      <opt>robust</opt>) può essere modificata con il comando <cmdref
      targ="set"/>.
      L'opzione <opt>jackknife</opt> equivale a impostare
      <lit>hc_version</lit> a <lit>3a</lit>, in modo da emulare il vecchio
      comando <lit>hccm</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/OLS - Minimi quadrati ordinari</menu-path>
      <other-access>Pulsante Beta-hat sulla barra degli strumenti</other-access>
    </gui-access>

  </command>

  <command name="omit" section="Tests" label="Omette variabili">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--wald</flag>
	  <effect>esegue un test di Wald invece che un test F</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le stime per il modello ridotto</effect>
	</option>
 	<option>
 	  <flag>--silent</flag>
 	  <effect>non mostra nulla</effect>
 	</option>
        <option>
         <flag>--auto</flag>
	 <optparm>alpha</optparm>
         <effect>eliminazione sequenziale, si veda oltre</effect>
       </option>
        <option>
          <flag>--inst</flag>
          <effect>omette come strumento, solo per TSLS</effect>
        </option>
        <option>
          <flag>--both</flag>
          <effect>omette come regressore e come strumento, solo per TSLS</effect>
        </option>
      </options>
      <examples>
        <example>omit 5 7 9</example>
        <example>omit seasonals --quiet</example>
        <example>omit --auto</example>
        <example>omit --auto=0.05</example>
      </examples>
    </usage>

    <description>
      <para context="gui">
	Questo comando stima di nuovo il modello dato, dopo aver omesso
	le variabili specificate o dopo aver omesso sequenzialmente le variabili
        non significative, se è stata selezionata l'apposita casella.
        Oltre ai consueti risultati della stima del modello, viene fornita una
        statistica test per la significatività congiunta delle variabili omesse:
        l'ipotesi nulla è che i coefficienti di tutte le variabili omesse siano
        pari a zero.
      </para>
      <para context="gui">
        Se il modello originale è stato stimato con OLS, la statistica test è un
        valore <math>F</math>, basato sulle somme dei quadrati dei residui
        del modello vincolato e di quello originale. Per stimatori diversi da OLS,
        o se si usa l'opzione Wald, la statistica è un valore chi-quadro di Wald
        asintotico basato sulla matrice di covarianza del modello originale.
      </para>
      <para context="gui">
        L'eliminazione sequenziale funziona nel modo seguente: ad ogni passo
        viene omessa la variabile con il p-value più alto, fino a che tutte le
        variabili restanti hanno un p-value inferiore a una certa soglia. La
        soglia predefinita è del 10 per cento (con due code), che può essere
        modificata usando l'apposito pulsante.
      </para>
      <para context="cli">
        Questo comando deve seguire un comando di stima e calcola un test per la
        significatività congiunta delle variabili nella
        <repl>lista-variabili</repl>, che deve essere un sottoinsieme delle
        variabili indipendenti del modello stimato in precedenza. In
        alternativa, se si usa l'opzione <opt>auto</opt> viene attivata la
        procedura di eliminazione sequenziale: ad ogni passo
        viene omessa la variabile con il p-value più alto, fino a che tutte le
        variabili restanti hanno un p-value inferiore a una certa soglia. La
        soglia predefinita è del 10 per cento (con due code), che può essere
        modificata aggiungendo <quote><lit>=</lit></quote> e un valore tra 0 e 1
        (senza spazi), come nel quarto esempio mostrato sopra.
      </para>
      <para context="cli">
	Se il modello originale è stato stimato con OLS, la statistica test è
        un valore <math>F</math>, basato sulle somme dei quadrati dei
        residui del modello vincolato e di quello originale, a meno che
        quest'ultimo sia stato stimato usando errori standard robusti.
	In questo caso, il valore <math>F</math> viene calcolato delle
        stime robuste della matrice di covarianza del modello originale (è la
        versione <math>F</math> di un test di Wald).
      </para>
      <para context="cli">
	Per gli stimatori diversi da OLS, o se si usa l'opzione <opt>wald</opt>,
        la statistica usata è un valore chi-quadro asintotico di Wald, basato
        sulla matrice di covarianza del modello originale.
      </para>
      <para context="cli">
        Per impostazione predefinita, viene stimato il modello vincolato,
        vengono mostrate le stime e il modello vincolato rimpiazza quello
        originale come <quote>modello attuale</quote> nel caso si voglia,
        ad esempio, recuperare i residui con <fncref targ="$uhat"/> (o eseguire
        test ulteriori, come <cmd>add</cmd> o <cmd>omit</cmd>).  
      </para>
      <para>
	Usando l'opzione Wald, il modello vincolato
        non viene stimato (quindi il modello attuale non viene rimpiazzato).
        L'opzione <opt>quiet</opt> sopprime la stampa dei risultati del
        modello vincolato (se esso viene stimato): viene mostrato solo il
        risultato del test. Se il modello vincolato viene stimato e ne viene
        chiesta la stampa, l'opzione <opt>vcv</opt> ha l'effetto di
        mostrare la matrice di covarianza dei coefficienti del modello
        vincolato, altrimenti quest'opzione è ignorata.
      </para>
      <para context="cli">
	Se si usa l'opzione <opt>silent</opt>, non viene mostrato
        alcun risultato; tuttavia, i risultati del test possono essere
        recuperati usando le variabili speciali
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>.
      </para>
      <para context="cli">
       Se il modello originale è stato stimato con i minimi quadrati a due
       stadi, può sorgere un'ambiguità: le nuove variabili vanno omesse come
       regressori, come strumenti o con entrambe le funzioni? Per risolvere
       l'ambiguità, nella modalità predefinita le variabili sono omesse
       dall'elenco dei regressori, se si usa l'opzione <opt>inst</opt> sono
       omesse dall'elenco degli strumenti, mentre se si usa l'opzione
       <opt>both</opt> sono rimosse totalmente dal modello. Queste due opzioni
       sono incompatibili con l'opzione <opt>wald</opt>; se uno o più strumenti
       vengono omessi, il modello va ri-stimato.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/OMIT - Ometti variabili</menu-path>
    </gui-access>

  </command>

  <command name="online" section="Dataset" context="gui"
    label="Accesso ai database online">

    <description>
      <para>
	Gretl può accedere ai database della Wake Forest University
	(se il proprio computer è connesso a internet).</para>

      <para>Dal menù <quote>File, Database</quote>, selezionare
	<quote>Sul server di gretl</quote>: apparirà una finestra che
        mostra i database disponibili alla Wake Forest (a seconda della
        località e della velocità della connessione internet,
        l'operazione può richiedere alcuni secondi). Oltre al nome del
        database e a una breve descrizione, apparirà un campo
        <quote>Stato</quote>, che mostra se il database è stato
        installato localmente (sul disco del computer), e, in caso
        positivo, se la versione installata è aggiornata a quella
        disponibile sul server.</para>

      <para>Se un database è stato installato localmente ed è
      aggiornato, non c'è nessun vantaggio nell'accedervi attraverso il
      server, mentre per un database non installato o non aggiornato, può essere
      utile scaricare un elenco delle serie di dati, facendo clic su
      <quote>Scarica l'elenco delle serie</quote>. Apparirà una nuova
      finestra da cui è possibile visualizzare i valori di una serie
      scelta, vederne il grafico o importarle in gretl. È possibile
      effettuare queste operazioni usando il menù <quote>Serie</quote>,
      o attraverso il menù pop-up che appare facendo clic col tasto
      destro su una serie. È anche possibile cercare nell'elenco una
      variabile in particolare, usando il comando <quote>Trova</quote>
      del menù.</para>

      <para>Per poter accedere a un database anche offline, basta selezionare la
      riga del database desiderato nella prima finestra e premere il pulsante 
      <quote>Installa</quote>. Il database verrà scaricato in formato
      compresso, verrà decompresso e installato sul proprio disco fisso,
      in modo da poter essere caricato usando il menù <quote>File,
      Database, Gretl</quote>.</para>

    </description>
  </command>

  <command name="open" section="Dataset" label="Apre un dataset" context="cli">

    <usage>
      <arguments>
        <argument>file-dati</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampare la lista di serie</effect>
	</option>
	<option>
	  <flag>--preserve</flag>
	  <effect>mantieni in memoria le variabili non-serie</effect>
	</option>
	<option>
	  <flag>--frompkg</flag>
	  <optparm>pkgname</optparm>
	  <effect>vedi sotto</effect>
	</option>	
	<option>
	  <flag>--www</flag>
	  <effect>usa un database sul server di gretl</effect>
	</option>
	<option>
	  <note>Si veda oltre per le opzioni specifiche per i fogli elettronici</note>
	</option>
      </options>
      <examples>
        <example>open data4-1</example>
        <example>open voter.dta</example>
	<example>open fedbog --www</example>
      </examples>
    </usage>

    <description>
      <para>
        Apre un file di dati. Se è già stato aperto un file di dati,
        esso viene sostituito da quello selezionato.
      </para>
      <para>
	Se non si specifica un percorso completo, il programma
	cercherà automaticamente il file in alcuni percorsi
	predefiniti, a partire dal valore attuale di
	<cmdref targ="workdir"/>. Se non si specifica un'estensione per il
	file, come nel primo degli esempi, gretl assume che si tratti
	di un file di dati standard, con estensione <lit>.gdt</lit>. A
	seconda del nome del file e di alcune sue caratteristiche,
	gretl cerca di indovinare il formato dei dati (standard, testo
	semplice, CSV, MS Excel, Stata, ecc).
      </para>
      <para>
	If the <opt>frompkg</opt> option is used, gretl will look for
	the specified data file in the subdirectory associated with
	the function package specified by <repl>pkgname</repl>.
      </para>
      <para>
	If the <repl>filename</repl> argument takes the form of a
	URI starting with <lit>http://</lit>, then gretl will attempt
	to download the indicated data file before opening it.
      </para>
      <para>
	By default, opening a new data file clears the current gretl
	session, which includes deletion of all named variables,
	including matrices, scalars and strings.  If you wish to keep
	your currently defined variables (other than series, which are
	necessarily cleared out), use the <opt>preserve</opt>
	option.
      </para>
      <para>
	Questo comando può essere usato anche per aprire un database (gretl,
	RATS 4.0 o PcGive) per la lettura. In questo caso, dev'essere seguito dal comando
        <cmdref targ="data"/> per estrarre una particolare serie dal database.
        Se si usa l'opzione <lit>www</lit>, il programma cercherà di accedere al
        database specificato sul server di gretl &mdash; ad esempio il database
        "Federal Reserve interest rates" nel terzo degli esempi visti sopra.
      </para>
      <para>
	Quando si apre un file di un foglio elettronico (Gnumeric, Open Document o XLS),
        è possibile fornire fino a tre parametri aggiuntivi, oltre al nome del
        file. Per prima cosa, è possibile selezionare un particolare foglio di
        lavoro all'interno del file, indicando il suo numero con la
        sintassi <lit>--sheet=2</lit>, oppure indicando il suo nome tra
        virgolette doppie, usando la sintassi <lit>--sheet="MacroData"</lit>.
        L'impostazione predefinita consiste nel leggere il primo foglio di
        lavoro del file. È anche possibile specificare la riga/colonna da cui
        iniziare a leggere, usando la sintassi
      </para>
      <code>
	--coloffset=3 --rowoffset=2
      </code>
      <para>
	che indica a gretl di ignorare le prime 3 colonne e le prime 2 righe.
        L'impostazione predefinita consiste nel leggere tutte le celle del
        foglio, a partire dalla prima in alto a sinistra.
      </para>
      <para>
	With plain text files, gretl generally expects to find the data
	columns delimited in some standard manner.  But there is also a
	special facility for reading <quote>fixed format</quote> files, in
	which there are no delimiters but there is a known specification of
	the form, &eg;, <quote>variable <math>k</math> occupies 8 columns
	starting at column 24</quote>.  To read such files, you should append
	a string <opt>fixed-cols=</opt><repl>colspec</repl>, where
	<repl>colspec</repl> is composed of comma-separated integers.  These
	integers are interpreted as a set of pairs.  The first element of each
	pair denotes a starting column, measured in bytes from the beginning
	of the line with 1 indicating the first byte; and the second element
	indicates how many bytes should be read for the given field.  So, for
	example, if you say
      </para>
      <code>
	open fixed.txt --fixed-cols=1,6,20,3
      </code>
      <para>
	then for variable 1 gretl will read 6 bytes starting at column 1; and
	for variable 2, 3 bytes starting at column 20.  Lines that are blank,
	or that begin with <lit>#</lit>, are ignored, but otherwise the
	column-reading template is applied, and if anything other than a valid
	numerical value is found an error is flagged.  If the data are read
	successfully, the variables will be named <lit>v1</lit>,
	<lit>v2</lit>, etc.  It's up to the user to provide meaningful names
	and/or descriptions using the commands <cmdref targ="rename"/> and/or 
	<cmdref targ="setinfo"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Apri dati</menu-path>
      <other-access>Trascinare un file di dati in gretl (MS Windows o Gnome)</other-access>
    </gui-access>

  </command>

  <command name="orthdev" section="Transformations" 
    label="Deviazioni ortogonali" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
    </usage>

    <description>
      <para>
        Utilizzabile solo con dati panel. Per ognuna delle variabili nella
        <repl>lista-variabili</repl> viene generata una serie di deviazioni
        ortogonali in avanti, salvata col nome della variabile prefissata da
	<lit>o_</lit>. Quindi, <cmd>orthdev x y</cmd> crea le nuove variabili
        <lit>o_x</lit> e <lit>o_y</lit>.
      </para>
      <para>
	I valori sono salvati con un periodo di ritardo rispetto alla loro
        collocazione temporale (ossia, <lit>o_x</lit> all'osservazione <math>t</math>
        contiene la deviazione che, in senso stretto, corrisponde al periodo
        <math>t</math> &minus; 1). Questo comportamento è coerente con quello
        delle differenze prime: viene persa la prima osservazione di ogni serie,
        non l'ultima.
      </para>
    </description>

  </command>

  <command name="outfile" section="Printing" label="Stampa diretta su file" context="cli">

    <usage>
      <arguments>
        <argument>file-output</argument>
        <argument>opzione</argument>
      </arguments>
      <options>
        <option>
	  <flag>--append</flag>
	  <effect>aggiunge al file</effect>
        </option>
        <option>
	  <flag>--close</flag>
	  <effect>chiude il file</effect>
        </option>
        <option>
	  <flag>--write</flag>
	  <effect>sovrascrive il file</effect>
        </option>
      </options>
      <examples>
        <example>outfile --write regress.txt</example>
        <example>outfile --close</example>
      </examples>
    </usage>

    <description>
      <para>
        Scrive i risultati sul <repl>file-output</repl>, fino a nuovo
        ordine. Usando l'opzione <opt>append</opt>, i risultati
        vengono aggiunti a un file esistente, mentre <opt>write</opt>
        apre un nuovo file (o ne sovrascrive uno esistente).
        L'opzione <opt>close</opt> può essere usata per chiudere un
        file di output aperto in precedenza, tornando a scrivere i
        risultati sul canale predefinito. Si noti che solo un file di
        output può essere aperto in un dato momento (ma vedi sotto),
        cosicché con l'opzione <opt>close</opt> un serve l'argomento
        <repl>file-output</repl>.
      </para>
      <para>
	Il file di output verrà creato nella directory data dal valore
	corrente di <cmdref targ="workdir"/>, a meno che la stringa
	<repl>file-output</repl> non contenga essa stessa una
	specifica completa di percorso.
      </para>
      <para>
        Nel primo degli esempi precedenti viene aperto il file
	<filename>regress.txt</filename>, mentre nel secondo viene
        chiuso. Se prima del comando <opt>close</opt> fosse
        eseguito un comando <cmd>ols</cmd>, i risultati della
        regressione verrebbero scritti su
        <filename>regress.txt</filename> invece che sullo schermo.
      </para>
      <para>
        Ci sono tre varianti: se si usa la parola chiave
        <lit>null</lit> al posto di un nome di file insieme
        all'opzione <opt>write</opt>, l'effetto è quello di sopprimere
        la stampa dei risultati fino alla successiva istruzione
        <lit>outfile --close</lit>. Inoltre, se una delle parole
        chiave <lit>stdout</lit> o <lit>stderr</lit> vengono usate al
        posto del nome di file, l'effetto è di ridirigere l'output
        rispettivamente sullo standard output o sullo standard error.
      </para>
      <para>
	L'opzione <opt>quiet</opt> si usa con <opt>write</opt>
	o <opt>append</opt>: ha l'effetto di annullare la stampa
	dei comandi e dei messaggi ausiliari fino alla chiusura del
	file. È equivalente a
      </para>
      <code>
	set echo off
	set messages off
      </code>
      <para>
	se non per il fatto che al termine della ridirezione i valori
	originali di <lit>echo</lit> e <lit>messages</lit> vengono
	ripristinati.
      </para>
      <para>
	In un dato punto del codice, ci può essere solo un file aperto
	con questa tecnica; quindi, le chiamate a questo comando non
	possono essere annidate. Ciononostante, questo comando è
	consentito nelle funzioni scritte dall'utente (purché il file
	di output venga chuso nella stessa funzione), cosicché
	l'output può essere ridiretto tempraneamente e poi riassegnato
	al file di output originale. Ad esempio, il codice
      </para>
      <code>
	function void f(string s)
	    outfile inner.txt --write
	    print s
	    outfile --close
	end function

	outfile outer.txt --write --quiet
	print "Fuori"
	f("Dentro")
	print "Ancora fuori"
	outfile --close
      </code>
      produrrà un file di nome <quote>outer.txt</quote> contenente le
      due linee
      <code>
	Fuori
	Ancora fuori
      </code>
      e un file di nome <quote>inner.txt</quote> contenente la linea
      <code>
	Dentro
      </code>
    </description>

  </command>

  <command name="panel" section="Estimation" label="Modelli panel">

    <usage>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
        <option>
	  <flag>--fixed-effects</flag>
	  <effect>stima con effetti di gruppo fissi</effect>
        </option>
 	<option>
	  <flag>--random-effects</flag>
	  <effect>effetti casuali o modello GLS</effect>
	</option>
	<option>
	  <flag>--between</flag>
	  <effect>stima il modello tra i gruppi</effect>
        </option>
        <option>
	  <flag>--time-dummies</flag>
	  <effect>include variabili dummy temporali</effect>
        </option>
        <option>
	  <flag>--unit-weights</flag>
	  <effect>minimi quadrati ponderati</effect>
	</option>
	<option>
	  <flag>--iterate</flag>
	  <effect>stima iterativa</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>mostra meno risultati</effect>
        </option>
        <option>
	  <flag>--verbose</flag>
	  <effect>mostra più risultati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
        Stima un modello panel, per impostazione predefinita usando lo stimatore
        a effetti fissi; la stima è implementata sottraendo le
        medie di gruppo o delle unità dai dati originali.
      </para>
      <para context="cli">
        Se si usa l'opzione <lit>--random-effects</lit>, viene usato il modello
        GLS a effetti casuali, usando il metodo di Swamy e Arora.
      </para>
      <para context="cli">
        In alternativa, con l'opzione <lit>--unit-weights</lit>, il modello viene
        stimato con i minimi quadrati ponderati, con i pesi costruiti a partire
        dalla varianza residua per le rispettive unità cross section nel
        campione. Solo in questo caso, è possibile usare l'opzione
        <opt>iterate</opt> per produrre stime iterative: nel caso di
        convergenza, le stime sono di massima verosimiglianza.
      </para>
      <para context="cli">
        Come ulteriore alternativa, se si usa l'opzione <opt>between</opt>,
        viene stimato il modello tra i gruppi, ossia una regressione OLS usando
        le medie dei gruppi.
      </para>
      <para context="gui">
        Se si seleziona la casella "Effetti casuali", vengono calcolate stime a
        effetti casuali, usando il metodo di Swamy e Arora.
      </para>
      <para>
	Per maggiori dettagli sulla stima panel, si veda la <guideref targ="chap:panel"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Panel</menu-path>
    </gui-access>

  </command>

  <command name="panel-between" section="Estimation" context="gui"
    label="Modello panel tra i gruppi">

    <description>
      <para>
        Questa finestra di dialogo permette di immettere la specificazione per
        un modello panel <quote>tra i gruppi</quote>, ossia una regressione che
        usa le medie di gruppo dei dati, ignorando quindi la variazione
        all'interno dei gruppi. Questo modello di solito non è di grande
        interesse in sé, ma può essere utile a scopo di confronto, ad esempio
        rispetto al modello a effetti fissi.
      </para>
    </description>

  </command>    
  
  <command name="panel-mode" section="Dataset" context="gui"
    label="Organizzazione dei dati panel">

    <description>
      <para>
	Questa finestra di dialogo offre tre opzioni per definire un dataset
        come panel. Le prime due opzioni richiedono che il dataset sia già
        organizzato in un formato panel (anche se gretl può non essersi accorto
        di ciò). La terza opzione richiede che il dataset contenga variabili che
        rappresentano la struttura panel.
      </para>
      <para>
        <emphasis>Pila di serie storiche</emphasis>: date <repl>N </repl> unità
        cross section nel dataset e <repl>T</repl> osservazioni temporali per
        ogni unità, selezionando questa opzione si indica a gretl che il dataset
        attuale è composto da <repl>N</repl> blocchi consecutivi di
        <repl>T</repl> osservazioni ciascuno. Il passo successivo consiste nello
        specificare il valore di <repl>N</repl>.
      </para>
      <para>
        <emphasis>Pila di dati cross section</emphasis>: si indica a gretl che
        il dataset è composto da <repl>T</repl> blocchi consecutivi di
        <repl>N</repl> osservazioni cross section ciascuno, uno per per ogni
        periodo. Il passo successivo consiste nello specificare il
        valore di <repl>N</repl>.
      </para>
      <para>
        Se il numero di osservazioni del dataset è un numero primo, le due
        opzioni precedenti non sono disponibili.
      </para>
      <para>
	<emphasis>Usa variabili indice</emphasis>: si indica che il dataset è organizzato in modo
        qualsiasi, ma contiene due variabili che indicizzano le unità cross
        section e quelle temporali. Il passo successivo consiste nell'indicare
        queste due variabili. Le variabili indice per i panel possono assumere solo valori
        interi e non negativi e non devono avere valori mancanti. Se il dataset
        non contiene variabili di questo tipo, questa opzione non è disponibile.
       </para>
     </description>
 
  </command>

  <command name="panel-wls" section="Estimation" context="gui"
    label="Minimi quadrati ponderati a gruppi">

    <description>
      <para>
        Minimi quadrati ponderati a gruppi per dati panel. Calcola le stime WLS
	con i pesi basati sulle varianze stimate degli errori per le rispettive
        unità cross section nel campione.
      </para>
      <para>
	Selezionando l'opzione di iterazione, la procedura viene iterata: ad
        ogni passo, i residui vengono ricalcolati usando le stime WLS
        disponibili per i parametri, fornendo così un nuovo insieme di stime per
        le varianze degli errori, e quindi un nuovo insieme di pesi.
	Le iterazioni si arrestano quando la massima differenza nelle stime dei
        parametri tra un passo e l'altro scende sotto 0.0001, oppure se il
        numero di iterazioni supera 20. Se la procedura converge, le stime
        risultanti sono di massima verosimiglianza.
      </para>
    </description>

  </command>

  <command name="pca" section="Statistics"
    label="Analisi delle componenti principali">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
         <option>
	  <flag>--covariance</flag>
	  <effect>usa la matrice di covarianza</effect>
        </option>	
        <option>
	  <flag>--save</flag>
	  <effect>salva le componenti principali</effect>
        </option>
        <option>
	  <flag>--save-all</flag>
	  <effect>salva tutte le componenti</effect>
        </option>
      </options>
    </usage>

    <description context="gui">
      <para>
        Analisi delle componenti principali. Mostra gli autovalori
        della matrice di correlazione (o della matrice di covarianza, se si usa
        la casella opportuna) per le variabili selezionate, insieme alla
        proporzione della varianza comune spiegata da ogni componente. Mostra
        anche i corrispondenti autovettori (o <quote>pesi della
        componente</quote>).
      </para>
      <para>
	Nella finestra che mostra i risultati è possibile salvare le componenti
        principali come serie nel dataset.
      </para> 
    </description>

    <description context="cli">
      <para>
        Analisi delle componenti principali. Mostra gli autovalori
        della matrice di correlazione (o della matrice di covarianza, se si
        usa l'opzione <flag>--covariance</flag>) per le variabili nella
	<repl>lista-variabili</repl>, insieme alla proporzione della
        varianza comune spiegata da ogni componente. Mostra anche i
        corrispondenti autovettori (o <quote>pesi della componente</quote>).
      </para>  
      <para>
        Usando l'opzione <opt>save</opt>, le componenti con autovalori
        maggiori di 1.0 vengono salvati nel dataset come variabili, con i nomi
        <lit>PC1</lit>, <lit>PC2</lit> e così via.  Queste variabili artificiali
        sono definite come la somma del peso della componente moltiplicato per
        <lit>Xi</lit> standardizzato, dove <lit>Xi</lit> denota la
        <math>i</math>-esima variabile nella <repl>lista-variabili</repl>.
      </para>
      <para>
        Usando l'opzione <lit>--save-all</lit>, vengono salvate
        tutte le componenti, come descritto sopra.
      </para> 
    </description>

    <gui-access>
      <menu-path>/Visualizza/Componenti principali</menu-path>
      <other-access>Pop-up nella finestra principale (selezione multipla)</other-access>
    </gui-access>

  </command>

  <command name="pergm" section="Statistics"
    label="Periodogramma">

    <usage>
      <arguments>
        <argument>nome-variabile</argument>
        <argument optional="true">banda</argument>
      </arguments>
      <options>
        <option>
	  <flag>--bartlett</flag>
	  <effect>usa la finestra di Bartlett</effect>
        </option>
        <option>
	  <flag>--log</flag>
	  <effect>usa una scala logaritmica</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Calcola e mostra (graficamente se non si è in modalità batch)
        lo spettro della variabile specificata.  Per impostazione predefinita
        viene mostrato il periodogramma nel campione, mentre usando  l'opzione
	<opt>bartlett</opt>, lo spettro viene stimato usando una
        finestra di Bartlett per i ritardi (si veda ad esempio <book>Econometric
        Analysis</book> di Greene per una discussione su questo argomento).
        L'ampiezza predefinita della fiestra di Bartlett è pari a due volte la
        radice quadrata dell'ampiezza campionaria, ma questo valore può essere
        impostato manualmente usando il parametro <repl>banda</repl>, fino a un
        massimo pari a metà dell'ampiezza campionaria. Usando l'opzione <opt>log</opt>,
        lo spettro viene rappresentato su una scala logaritmica.
      </para>
      <para>
        Quando viene mostrato il periodogramma del campione, vengono mostrati
        anche due test per l'integrazione frazionale (<quote>memoria
        lunga</quote>) della serie, ossia il test di Geweke e Porter-Hudak
        (GPH), e lo stimatore locale di Whittle. L'ipotesi nulla in entrambi
        i casi è che l'ordine di integrazione sia zero. Per impostazione
        predefinita, l'ordine per questi test è il valore minore tra
        <math>T</math>/2 e <math>T</math><sup>0.6</sup>; anche
        questo valore può essere modificato con il parametro di banda.
       </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Spettro</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
    </gui-access>

  </command>

  <command name="polyweights" section="Transformations" context="gui"
    label="Trend polinomiale">

    <description>
      <para>
	Quando si usa un trend polinomiale per approssimare una serie
	storica, si può voler dare più peso alle osservazioni
	all'inizio e alla fine del campione. (I punti in mezzo hanno
	dei vicini su ambo il lati che, probabilmente, portano il
	polinomio nella stessa direzione.)
      </para>
      <para>
	Gli schemi di ponderazione offerti qui (quadratico, a coseno e
	a gradini) possono essere usati allo scopo. Selezionando uno
	di essi, bisogna poi scegliere il valore per due settaggi
	aggiuntivi: primo, il massimo peso da usare (il minimo è
	1.0). Secondo, la frazione di campione centrale a qui dare un
	peso uniforme (minimale).
      </para>
      <para>
	Supponiamo, ad esempio, di scegliere un peso massimo pari a
	3.0 e una frazione centrale di 0.4. Ciò implica che il 40%
	centrale dei dati riceverà una ponderazione di
	1.0. Selezionando la ponderazione a gradini, il primo e
	l'ultimo 30% delle osservazioni riceve un peso pari a 3.0;
	altrimenti, il peso per il primo 30% delle osservazioni
	decresce gradualmente da 3.0 to 1.0, e per l'ultimo 30% delle
	osservazioni cresce gradualmente da 1.0 to 3.0.
      </para>
    </description>

  </command>

  <command name="poisson" section="Estimation" label="Stima Poisson">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
        <argument separated="true" optional="true">offset</argument>
      </arguments>
      <options>
        <option>
          <flag>--vcv</flag>
          <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
          <flag>--verbose</flag>
          <effect>mostra i dettagli delle iterazioni</effect>
        </option>
      </options>
      <examples>
        <example>poisson y 0 x1 x2</example>
       <example>poisson y 0 x1 x2 ; S</example>
      </examples>
    </usage>

    <description>
      <para>Stima una regressione di Poisson, in cui la variabile dipendente
      rappresenta le occorrenze di un qualche tipo di evento e può assumere solo
      valori interi non negativi.
      </para>

      <para>Se una variabile casuale discreta <math>Y</math> segue la
      distribuzione di Poisson, 
        <equation status="display"
          tex="\[\mathrm{Pr}(Y = y) = \frac{e^{-v} v^y}{y!}\]"
          ascii="Pr(Y = y) = exp(-v) * v^y / y!"
          graphic="poisson1"/>
      per <math>y</math> = 0, 1,
      2,&hellip;.  La media e la varianza della distribuzione sono entrambe uguali a
      <math>v</math>. Nel modello di regressione di Poisson, il parametro
      <math>v</math> è rappresentato da una funzione di una o più varabili
      indipendenti. La versione più comune del modello (e l'unica supportata da
      gretl) ha
        <equation status="display"
          tex="\[v = \mathrm{exp}(\beta_0+\beta_1 x_1+\beta_2 x_2 + \cdots)\]"
          ascii="v = exp(b0 + b1*x1 + b2*x2 + ...)"
          graphic="poisson2"/>
      ossia il logaritmo di
      <math>v</math> è una funzione lineare delle variabili indipendenti.
      </para>

      <para>Opzionalmente è possibile aggiungere una variabile
      <quote>offset</quote> alla specificazione, ossia una variabile
      di scala, il cui logaritmo viene aggiunto alla funzione di
      regressione lineare (con un coefficiente implicito di 1.0). Ciò
      ha senso se si ipotizza che il numero di occorrenze dell'evento
      in questione sia proporzionale a qualche fattore noto, a parità
      di altre condizioni. Ad esempio, il numero di incidenti stradali
      può essere ipotizzato proporzionale al volume del traffico, che
      potrebbe essere specificato come una variabile di
      <quote>offset</quote> in un modello di Poisson per il tasso di
      incidenti.  La variabile di offset dev'essere strettamente
      positiva.
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Poisson</menu-path>
    </gui-access>

  </command>

  <command name="print" section="Printing" label="Stampa dati o stringhe" context="cli">

    <usage>
      <arguments>
	<argument>lista-variabili</argument>
	<argument alternate="true">stringa-letterale</argument>
      </arguments>
      <options>
	<option>
	  <flag>--byobs</flag>
	  <effect>per osservazione</effect>
	</option>
 	<option>
 	  <flag>--no-dates</flag>
 	  <effect>usa i numeri delle osservazioni</effect>
 	</option>
      </options>
      <examples>
	<example>print x1 x2 --byobs</example>
	<example>print "Questa è una stringa"</example>
      </examples>
    </usage>

    <description>
      <para>
	Se viene indicata una <repl>lista-variabili</repl>, stampa i
        valori delle variabili specificate, altrimenti stampa i valori
        di tutte le variabili nel dataset in uso. Usando l'opzione
	<opt>byobs</opt> i dati vengono stampati per osservazione,
        altrimenti sono stampati per variabile.
      </para>

      <para>
 	Se si usa l'opzione <opt>byobs</opt> e i dati sono mostrati per
        osservazione, il comportamento predefinito è quello di mostrare la data
        (per serie storiche) o il marcatore (se esiste) all'inizio di ogni riga.
 	L'opzione <lit>--no-dates</lit> sopprime la visualizzazione delle date o
        dei marcatori: viene mostrato solo un semplice numero di osservazione.
      </para>
 
      <para>
	Se l'argomento di <cmd>print</cmd> è una stringa letterale (che
        deve iniziare con le virgolette doppie <lit>"</lit>), la stringa
        viene stampata così come è stata indicata. Si veda anche <cmdref
          targ="printf"/>.
      </para>
      
      <para>
        Nota: c'è un <quote>trucco</quote> con questo comando, usando
        l'opzione <opt>byobs</opt>, che può essere utile quando si
        lavora su un dataset con valori mancanti. Se si fornisce una
        lista di variabili seguite da un punto e virgola e da una
        variabile finale, la variabile finale non viene mostrata, ma
        viene usata per selezionare le osservazioni da mostrare. Le
        osservazioni per cui la variabile finale assume valore 0 non
        verranno mostrate. Ad esempio, si supponga di avere la serie
        giornaliera <lit>x</lit> e di volere la lista delle date per
        cui <lit>x</lit> ha valori mancanti. Si può procedere nel modo
        seguente:
      </para>
      <code>
	genr filt = missing(x)
	print x ; filt --byobs
      </code>

    </description>

    <gui-access>
      <menu-path>/Dati/Mostra valori</menu-path>
    </gui-access>

  </command>

  <command name="printf" section="Printing" label="Stampa formattata" context="cli">

    <usage>
      <arguments>
        <argument>formato</argument>
	<argpunct>, </argpunct>
        <argument>argomenti</argument>
      </arguments>
    </usage>

    <description>
      <para>
        Stampa valori scalari, serie, matrici o stringhe formattandoli secondo le indicazioni
        di una stringa di formato (che supporta un piccolo sottoinsieme del
        comando <lit>printf()</lit> del linguaggio di programmazione C). I
        formati numerici riconosciuti sono <lit>%e</lit>, <lit>%E</lit>,
        <lit>%f</lit>, <lit>%g</lit>, <lit>%G</lit> e <lit>%d</lit>, con i
        vari modificatori disponibili in C. Esempi: la stringa di formato
        <lit>%.10g</lit> stampa un valore con 10 cifre significative;
        <lit>%12.6f</lit> stampa un valore con 6 cifre decimali e una larghezza
        di 12 caratteri. Per formattare le stringhe occorre usare la stringa
        di formato <lit>%s</lit>.
      </para>  

      <para>
        La stringa di formato deve essere racchiusa tra virgolette
        doppie, i valori da stampare devono seguire la stringa di
        formato, separati da virgole. I valori possono avere tre forme:
	a) nomi di variabili; b) espressioni valide per
        il comando <cmd>genr</cmd>; c) le funzioni speciali <lit>varname()</lit>
        o <lit>date()</lit>. L'esempio seguente stampa i valori
        di due variabili e quello di un'espressione calcolata:
      </para>

      <code>
	ols 1 0 2 3
	genr b = $coeff(2)
	genr se_b = $stderr(2)
	printf "b = %.8g, standard error %.8g, t = %.4f\n", b, se_b, b/se_b
      </code>

      <para>
 	Le prossime righe mostrano l'uso delle funzioni varname e date, che
        rispettivamente mostrano il nome di una variabile dato il suo numero
        identificativo, e una stringa data, dato un numero di osservazione.
      </para>
       <code>
 	printf "Il nome della variabile %d è %s\n", i, varname(i)
 	printf "La data dell'osservazione %d è %s\n", j, date(j)
      </code>
      <para>
	Se si usa un argomento matrice insieme a un formato numerico, l'intera
        matrice verrà stampata usando per ogni elemento il formato numerico
        indicato. La stessa cosa vale per le serie, tranne per il fatto che
        l'intervallo di valori stampato è controllato dall'impostazione del
        campione corrente.
      </para>
      <para>
	La lunghezza massima di una stringa di formato è di 127
        caratteri. Vengono riconosciute le sequenze di escape
	<lit>\n</lit> (newline), <lit>\t</lit> (tab),
	<lit>\v</lit> (tab verticale) e <lit>\\</lit> (barra inversa).
        Per stampare un segno di percentuale, si usi <lit>%%</lit>.
      </para>
      <para>
	Come in C, i valori numerici che fanno parte del formato (larghezza e
        precisione) possono essere dati direttamente come numeri, come in
	<lit>%10.4f</lit>, o come variabili. Nell'ultimo caso, si inseriscono
        asterischi nella stringa di formato e si forniscono nell'ordine gli
        argomenti corrispondenti. Ad esempio:
      </para>
      <code>
	scalar larghezza = 12
	scalar precisione = 6
	printf "x = %*.*f\n", larghezza, precisione, x
      </code>
    </description>

  </command>

  <command name="probit" section="Estimation"
    label="Stima probit">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
          <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--p-values</flag>
	  <effect>mostra i p-value invece degli effetti
	  marginali</effect>
	</option>
	<option>
	  <flag>--random-effects</flag>
	  <effect>stima un modello panel a effetti casuali (RE)</effect>
	</option>
	<option>
	  <flag>--quadpoints</flag>
	  <optparm>k</optparm>
	  <effect>numero di punti di quadratura per la stima RE</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Se la variabile dipendente è binaria (tutti i suoi valori sono
        0 o 1), esegue una stima di massima verosimiglianza dei
        coefficienti delle <repl>variabili-indipendenti</repl> con il
        metodo Newton-Raphson. Visto che il modello è nonlineare, gli
        effetti marginali (pendenze) dipendono dai valori delle
        variabili indipendenti: per impostazione predefinita, al posto
        dei p-value vengono mostrate le pendenze rispetto ad ognuna
        delle variabili indipendenti, calcolate in corrispondenza
        della media della variabile. Questo comportamento può essere
        soppresso usando l'opzione <lit>--p-values</lit>.  La
        statistica chi-quadro testa l'ipotesi nulla che tutti i
        coefficienti tranne la costante siano pari a zero.
      </para>
      <para context="cli">
        In modalità predefinita, gli errori standard sono calcolati
        tramite l'Hessiana.  Se si usa l'opzione <opt>robust</opt>,
        verranno calcolati gli errori standard QML
        (Huber&ndash;White). In questo caso, la matrice di covarianza
        stimata è un <quote>sandwich</quote> dell'inversa
        dell'Hessiana stimata e del prodotto esterno del
        gradiente. Per i dettagli, si veda Davidson e MacKinnon 2004,
        cap. 10.
      </para>
      <para context="gui">
        In modalità predefinita, gli errori standard sono calcolati
        tramite l'Hessiana.  Se si seleziona la casella "Errori
        standard robusti", verranno calcolati gli errori standard QML
        (Huber&ndash;White). In questo caso, la matrice di covarianza
        stimata è un <quote>sandwich</quote> dell'inversa
        dell'Hessiana stimata e del prodotto esterno del
        gradiente. Per i dettagli, si veda Davidson e MacKinnon 2004,
        cap. 10.
      </para>
      <para>
	Con l'opzione <opt>random-effects</opt>, il termine di errore è
	composto per ipotesi da due componenti gaussiane: una,
	specifica per l'unità cross-sezionale e invariante nel tempo
	(nota come <quote>effetto individuale</quote>) e l'altra
	specifica per quella particolare osservazione.
      </para>
      <para>
	Il calcolo della log-verosimiglianza per questo modello viene
	effettuato tramite la quadratura di Gauss-Hermite per
	approssimare il valore di valori attesi di funzioni di
	variabili casuali normali. Il numero di punti di quadratura
	usati si può scegliere tramite l'opzione
	<opt>quadpoints</opt> (il default è 32). Un numero elevato
	di questi aumenta l'accuratezza dei risultati, ma al costo di
	tempi di calcolo più lunghi; in questo caso la stima può
	richiedere molto tempo con dataset grandi.
      </para>
      <para>
	Oltre ai parametri standard (e statistiche associate) relativi
	alle variabili esplicative, dopo la stima di questo tipo di
	modello vengono presentati alcuni risultati aggiuntivi:
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>lnsigma2</lit>: la stima ML del logaritmo della
	    varianza dell'effetto individuale;
	  </para>
	</li>
	<li>
	  <para>
	    <lit>sigma_u</lit>: la stima dell'errore quadratico medio
	    dell'effetto individuale;
	  </para>
	</li>
	<li>
	  <para>
	    <lit>rho</lit>: la quota stima dell'effetto individuale
	    sulla varianza totale del termine di errore composito
	    (anche nota come correlazione intra-classe).
	  </para>
	</li>
      </ilist>
      <para>
	Il test LR per l'ipotesi <lit>rho</lit>=0 consente di
	stabilire se la specificazione a effetti random è in effetti
	necessaria. Sotto la nulla, una semplice specificazione probit
	è del tutto adeguata.
      </para>
      <para>
        Se la variabile dipendente non è binaria, ma è discreta, si
        ottengono stime Probit ordinali. Se la variabile scelta come
        dipendente non è discreta, viene emesso un messaggio di
        errore.
      </para>
      <para>
	Il probit per l'analisi delle proporzioni non è ancora stato
        implementato in	<program>gretl</program>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Probit</menu-path>
    </gui-access>

  </command>

  <command name="pvalue" section="Utilities" label="Calcola p-value" context="cli">

    <usage>
      <arguments>
        <argument>distribuzione</argument>
        <argument optional="true">parametri</argument>
	<argument>valore-x</argument>
      </arguments>
      <examples>
        <example>pvalue z zscore</example>
	<example>pvalue t 25 3.0</example>
	<example>pvalue X 3 5.6</example>
	<example>pvalue F 4 58 fval</example>
	<example>pvalue G forma scala x</example>
        <example>pvalue B bprob 10 6</example>
	<example>pvalue P lambda x</example>
	<example>pvalue W shape scale x</example>
      </examples>
    </usage>

    <description>
      <para>
	Calcola l'area alla destra del <repl>valore-x</repl> nella
        distribuzione indicata (<lit>z</lit> per la Gaussiana,
	<lit>t</lit> per la <math>t</math> di Student, <lit>X</lit>
	per la chi-quadro, <lit>F</lit> per la <math>F</math>,
	<lit>G</lit> per la gamma, <lit>B</lit> per la binomiale,
        <lit>P</lit> per la Poisson e <lit>W</lit> for Weibull).
      </para>
      <para>
	A seconda della distribuzione, occorre fornire le seguenti informazioni,
        prima del <repl>valore-x</repl>: per le distribuzioni <math>t</math>
        e chi-quadro occorre indicare i gradi di libertà; per la
        <math>F</math> sono richiesti i gradi di libertà al numeratore e
        al denominatore; per la gamma sono richiesti il parametro di forma e
        quello di scala; per la binomiale sono richieste la probabilità di
        <quote>successo</quote> e il numero di prove; per la distribuzione di
        Poisson va indicato il parametro &lgr; (che rappresenta sia la media che
        la varianza); per la distribuzione Weibull, i parametri di forma e scala.
        Come si vede dagli esempi precedenti, gli argomenti
        numerici possono essere indicati sotto forma di numero o come nomi di
        variabili.
      </para>
      <para>
        Si noti che talvolta la distribuzione gamma viene
        caratterizzata dai parametri di media e varianza, invece che
        da quelli di forma e scala.  La media è il prodotto di forma e
        scala, mentre la varianza è il prodotto tra la forma e il
        quadrato della scala. Quindi la scala si può ottenere come la
        varianza divisa per la media, mentre la forma come la media
        divisa per la scala.
      </para>
    </description>

    <gui-access>
      <menu-path>/Strumenti/Calcola p-value</menu-path>
    </gui-access>

  </command>
  
  <command name="qlrtest" section="Tests" label="Test del rapporto di verosimiglianza di Quandt">

    <usage>
      <options>
	<option>
	  <flag>--limit-to</flag>
	  <optparm>lista</optparm>
	  <effect>limita il test a una parte delle variabili esplicative</effect>
	</option>
	<option>
	  <flag>--plot</flag>
	  <optparm>mode-or-filename</optparm>
	  <effect>si veda sotto</effect>
	</option>
      </options>      
    </usage>

    <description>
      <para>
        Per un modello stimato con OLS su serie storiche, esegue il
        test del rapporto di verosimiglianza di Quandt (QLR) per un
        break strutturale in un punto incognito del campione,
        escludendo il 15% delle osservazioni all'inizio e ella fine
        del campione.
      </para>
      <para>
      	Per ogni possibile punto di rottura compreso nel 70% centrale
      	delle osservazioni, viene eseguito un test di Chow (si veda
      	<cmdref targ="chow"/>); come per il test di Chow vero e
      	proprio, questo è un test di Wald robusto se il modello
      	originale è stato stimato con l'opzione <opt>robust</opt>. La
      	statistica del test QLR è il massimo dei valori <math>F</math>
      	di questi test e segue una distribuzione non standard.
      </para>
      <para>
      	Il p-value asintotico è ottenuto usando il metodo di <cite
      	key="hansen97">Bruce Hansen (1997)</cite>.
      </para>
      <para context="cli">
      	L'opzione <opt>limit-to</opt> serve a limitare le interazioni
      	con la dummy di divisione del campione nei test di Chow a un
      	sottoinsieme dei regressori originali. Il parametro dev'essere
      	una lista predefinita, che non puà contenere la costante, gli
      	elementi della quale devono essere tutti scelti fra i
      	regressori originali.
      </para>
      <para>
      	Quando questo comando viene eseguito interattivamente, di
      	default verrà mostrato un grafico delle statistiche del test
      	di Chow.  Questo comportamento si può modificare con l'opzione
      	<opt>plot</opt>. Parametri consentiti sono <lit>none</lit>
      	(per fare a meno del grafico); <lit>display</lit> (per
      	mostrare il grafico anche quando non si è in modo
      	interattivo), oppure un nome di file. Per la descrizione
      	dell'effetto di quest'ultima scelta, si veda l'opzione
      	<opt>output</opt> del comando <cmdref targ="gnuplot"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/QLR</menu-path>
    </gui-access>

  </command>

  <command name="qqplot" section="Graphs" label="Q-Q plot">

    <usage>
      <altforms>
	<altform><lit>qqplot</lit> <repl>y</repl></altform>
	<altform><lit>qqplot</lit> <repl>y</repl> <repl>x</repl></altform>
      </altforms>
      <options>
	<option>
	  <flag>--z-scores</flag>
	  <effect>v. oltre</effect>
        </option>
        <option>
	  <flag>--raw</flag>
	  <effect>v. oltre</effect>
        </option>
      </options>
    </usage>

    <description>
      <para context="gui">
	Con una sola serie selezionata, mostra un grafico della
	distribuzione empirica della serie stessa contro i quantili
	della normale. La serie deve includere almeno 20 valori validi
	nel campione selezionato al momento. Per impostazione
	predefinita, i quantili empirici vengono disegnati contro
	quelli della normale avente media e varianza uguali a quelli
	campionari della serie, ma sono disponibili due alternative: i
	dati possono essere standardizzati prima, oppure i quantili
	empirici possono essere disegnati contro quelli della normale
	standardizzata.
      </para>
      <para context="cli">
	Con una sola serie come argomento, mostra un grafico della
	distribuzione empirica della serie stessa (indicata col nome o
	con il suo numero ID) contro i quantili della normale. La
	serie deve includere almeno 20 valori validi nel campione
	selezionato al momento. Per impostazione predefinita, i
	quantili empirici vengono disegnati contro quelli della
	normale avente media e varianza uguali a quelli campionari
	della serie, ma sono disponibili due alternative: con
	l'opzione <opt>z-scores</opt>, i dati vengono standardizzati
	prima, oppure, con l'opzione <opt>raw</opt>, i quantili
	empirici possono essere disegnati contro quelli della normale
	standardizzata.
      </para>
      <para>
	Tramite l'opzione <opt>output</opt> si invia il grafico al
	file desiderato; usare <quote>display</quote> per forzare l'output
	allo schermo, ad esempio nel contesto di un loop.
      </para>
      <para>
	Con due argomenti, <repl>y</repl> and <repl>x</repl>, mostra
	un grafico dei quantili empirici di <repl>y</repl> contro
	quelli di <repl>x</repl>. I dati non vengono standardizzati.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Q-Q normale</menu-path>
      <menu-path>/Visualizza/Grafico/Q-Q</menu-path>
    </gui-access>

  </command>

  <command name="quantreg" section="Estimation" 
    label="Regressione quantile">

    <usage>
      <arguments>
	<argument>tau</argument>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
        <option>
	  <flag>--intervals</flag>
	  <optparm>level</optparm>
	  <effect>calcola gli intervalli di confidenza</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
      </options>
      <examples>
	<example>quantreg 0.25 y 0 xlist</example>
	<example>quantreg 0.5 y 0 xlist --intervals</example>
	<example>quantreg 0.5 y 0 xlist --intervals=.95</example>
	<example>quantreg tauvec y 0 xlist --robust</example>
	<demos>
	  <demo>mrw_qr.inp</demo>
	</demos>
      </examples>
    </usage>

    <description context="gui">
      <para>
        Regressione quantile. Per impostazione predefinita, gli errori standard
        sono calcolati con la formula asintotica di Koenker e Bassett
        (<book>Econometrica</book>, 1978), ma se si attiva la casella
        <quote>robusto</quote>, verrà usata la variante robusta per
        l'eteroschedasticità di Koenker e Zhao (<book>Journal of Nonparametric
        Statistics</book>, 1994).
      </para>
      <para>
	Se si abilita l'opzione <quote>Calcola intervalli di confidenza</quote>,
	gretl calcolerà gli intervalli di confidenza invece degli errori
        standard. La casella <quote>robust</quote> mantiene il suo effetto: se
        non è selezionata, gli intervalli sono calcolati nell'ipotesi di errori
        IID, altrimenti gretl usa lo stimatore robusto sviluppato da
	Koenker e Machado (<book>Journal of the American
	Statistical Association</book>, 1999).  Si noti che questi intervalli
        non sono calcolati semplicemente aggiungendo e sottraendo un certo numero
        di errori standard: in generale sono asimmetrici rispetto alle stime
        puntuali dei parametri.
      </para>	
      <para>
	È possibile indicare un elenco di quantili (il menù a discesa contiene
        alcune possibilità predefinite), e in tal caso gretl calcolerà stime
        quantili ed errori standard o intervalli di confidenza per ognuno dei
        valori specificati.
      </para>
      <para>
	Per un approfondimento, si veda la <guideref targ="chap:quantreg"/>.
      </para>
    </description>

    <description context="cli">
      <para>
        Regressione quantile. Il primo argomento, <repl>tau</repl>, è il
        quantile condizionale per cui si desiderano le stime. Può essere un
        valore numerico o il nome di una variabile scalare predefinita; il
        valore deve essere compreso nell'intervallo da 0.01 a 0.99 (in
        alternativa, può essere indicato un vettore di valori, si veda sotto per
        i dettagli). Gli argomenti dal secondo in poi compongono un elenco di
        regressori sul modello di quello usato in <cmdref targ="ols"/>.
      </para>
      <para>
        Senza l'opzione <opt>intervals</opt>, vengono mostrati gli errori
        standard per le stime quantili; questi sono calcolati con la formula
        asintotica di Koenker e Bassett (1978), ma se si usa l'opzione
        <opt>robust</opt>, verrà usata la variante robusta per
        l'eteroschedasticità di Koenker e Zhao (1994).
      </para>
      <para>
        Se si usa l'opzione <opt>intervals</opt>, gretl calcolerà gli
        intervalli di confidenza invece degli errori standard.  Questi
        intervalli sono calcolati col metodo dell'inversione del rango e in
        generale sono asimmetrici rispetto alle stime puntuali dei parametri.
        Se non si usa l'opzione <quote>--robust</quote>, gli intervalli sono
        calcolati nell'ipotesi di errori IID (Koenker, 1994), mentre se viene
        indicata, sono calcolati con lo stimatore robusto sviluppato da Koenker
        e Machado (1999).
      </para>
      <para>
	Per impostazione predefinita vengono prodotti intervalli di confidenza
        al 90%. È possibile specificare un altro livello di confidenza (sotto
        forma di frazione decimale), aggiungendolo all'opzione, come in
	<lit>--intervals=0.95</lit>.
      </para>
      <para>
        Invece di indicare <repl>tau</repl> come uno scalare, è possibile usare
        un vettore, indicando il nome di una matrice predefinita. In questo
        caso le stime vengono eseguite per tutti i valori di <repl>tau</repl>, e
        i risultati mostrano la sequenza delle stime quantili per ognuno dei
        regressori.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Stima robusta/Regressione quantile</menu-path>
    </gui-access>

  </command>

  <command name="quit" section="Utilities" label="Esce dal programma" context="cli">

    <description>
      <para>
	Esce dal programma, dando la possibilità di salvare i
        risultati della sessione.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Esci</menu-path>
    </gui-access>

  </command>

  <command name="rename" section="Dataset" label="Rinomina variabili" context="cli">

    <usage>
      <altforms>
	<altform><lit>rename</lit> <repl>numero-var</repl>
	<repl>nuovo-nome</repl></altform>
	<altform><lit>rename</lit> <repl>nome-var</repl>
	<repl>nuovo-nome</repl></altform>
      </altforms>
    </usage>

    <description>
      <para>Modifica il nome di una variabile con numero
      identificativo <repl>numero-var</repl> o nome
      <repl>nome-var</repl> in <repl>nuovo-nome</repl>. Il
      <repl>numero-var</repl> deve essere compreso tra 1 e il numero
      di variabili nel dataset. Il nuovo nome deve essere lungo al
      massimo 15 caratteri, deve iniziare con una lettera e deve
      essere composto di sole lettere, numeri e il carattere trattino
      basso.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Modifica attributi</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione
      singola)</other-access>
    </gui-access>

  </command>

  <command name="reprobit" section="Estimation" label="Random effects probit"
	   context="gui">

    <description>
      <para>
	Lo stimatore a effetti random consente di stimare un modello
	proit binario in dataset di tipo panel. Il termine di errore è
	composto per ipotesi da due componenti gaussiane: una,
	specifica per l'unità cross-sezionale e invariante nel tempo
	(nota come <quote>effetto individuale</quote>) e l'altra
	specifica per quella particolare osservazione.
      </para>
      <para>
	Il calcolo della log-verosimiglianza per questo modello viene
	effettuato tramite la quadratura di Gauss-Hermite per
	approssimare il valore di valori attesi di funzioni di
	variabili casuali normali.  In questa finestra di dialogo è
	possibile scegliere il numero di punti di quadratura usati. Un
	numero elevato di questi aumenta l'accuratezza dei risultati,
	ma al costo di tempi di calcolo più lunghi; in questo caso la
	stima può richiedere molto tempo con dataset grandi.
      </para>
      <para>
	Oltre ai parametri standard (e statistiche associate) relativi
	alle variabili esplicative, dopo la stima di questo tipo di
	modello vengono presentati alcuni risultati aggiuntivi:
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>lnsigma2</lit>: la stima ML del logaritmo della
	    varianza dell'effetto individuale;
	  </para>
	</li>
	<li>
	  <para>
	    <lit>sigma_u</lit>: la stima dell'errore quadratico medio
	    dell'effetto individuale;
	  </para>
	</li>
	<li>
	  <para>
	    <lit>rho</lit>: la quota stima dell'effetto individuale
	    sulla varianza totale del termine di errore composito
	    (anche nota come correlazione intra-classe).
	  </para>
	</li>
      </ilist>
      <para>
	Il test LR per l'ipotesi <lit>rho</lit>=0 consente di
	stabilire se la specificazione a effetti random è in effetti
	necessaria. Sotto la nulla, una semplice specificazione probit
	è del tutto adeguata.
      </para>
      <para>
	In modalità scripting, il modello probit a effetti random si
	ottiene usando il comando <lit>probit</lit> con l'opzione
	<opt>random-effects</opt>.
      </para>
    </description>

  </command>

  <command name="reset" section="Tests" label="Test RESET di Ramsey">

    <usage>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra la regressione ausiliaria</effect>
	</option>
	<option>
	  <flag>--squares-only</flag>
	  <effect>calcola il test coi soli quadrati</effect>
	</option>
	<option>
	  <flag>--cubes-only</flag>
	  <effect>calcola il test coi soli cubi</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello via OLS. Esegue il test
	RESET di Ramsey per la specificazione del modello
        (non-linearità), aggiungendo alla regressione il quadrato e/o il
        cubo dei valori stimati (a meno che non siano specificate le
	opzioni <lit>--squares-only</lit> o
	<lit>--cubes-only</lit>) e calcolando la statistica
        <math>F</math> per l'ipotesi nulla che i coefficienti dei due
        termini aggiunti siano pari a zero.
      </para>
      <para context="cli">
        Vengono aggiunti sia i quadrati che i cubi, a meno che siano usate le
        opzioni <lit>--squares-only</lit> o <lit>--cubes-only</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/RESET - Ramsey</menu-path>
    </gui-access>

  </command>

  <command name="restrict" section="Tests" context="cli" label="Vincoli lineari">

    <description>
      <para>
	Impone un insieme di vincoli lineari sull'ultimo modello
        stimato o su un sistema di equazioni definito in precedenza.
        La sintassi del comando è leggermente diversa in ognuno dei due casi.
      </para>
        
      <para>
        In entrambi i casi, l'insieme di vincoli deve essere racchiuso tra i
        comandi <quote>restrict</quote> e <quote>end restrict</quote>. Nel caso
        della singola equazione, i vincoli sono applicati implicitamente
        all'ultimo modello e vengono valutati appena viene terminato il comando
        <quote>restrict</quote>. Nel caso del sistema, il comando iniziale
        <quote>restrict</quote> deve essere seguito immediatamente dal nome di
        un sistema di equazioni definito in precedenza (si veda <cmdref targ="system"/>).
        I vincoli vengono valutati nella successiva stima del sistema effettuata
        con il comando <cmdref targ="estimate"/>.
      </para>

      <para>Ogni vincolo nell'insieme va indicato sotto forma di equazione
	con una combinazione lineare dei parametri al primo membro e un
        valore numerico al secondo. Nel caso della singola equazione, i
        parametri sono indicati con la sintassi <lit>b[</lit><repl>i</repl><lit>]</lit>,
        dove <repl>i</repl> rappresenta la posizione nella lista dei regressori, a
        partire da uno, oppure con <lit>b[</lit><repl>variabile</repl><lit>]</lit>, dove
        <repl>variabile</repl> è il nome del regressore in questione.
        estion. Nel caso del sistema, i parametri vengono indicati
        con la sintassi <lit>b</lit> seguita da due numeri tra parentesi quadre.
        Il primo numero rappresenta la posizione dell'equazione all'interno del
        sistema, mentre il secondo indica la posizione nella lista dei regressori.
        Ad esempio <lit>b[2,1]</lit> indica il primo parametro della seconda
        equazione, mentre <lit>b[3,2]</lit> il secondo parametro della terza
        equazione.
      </para>

      <para>I termini <lit>b</lit> nell'equazione che rappresenta un vincolo
      possono essere prefissati da un moltiplicatore numerico, usando il segno
      <lit>*</lit> per indicare la moltiplicazione, ad esempio
      <lit>3.5*b[4]</lit>.
      </para>

      <para>
	Ecco un esempio di un insieme di vincoli per un modello
	stimato in precedenza:
      </para>

      <code>
	restrict
	 b[1] = 0
	 b[2] - b[3] = 0
	 b[4] + 2*b[5] = 1
	end restrict
      </code>

      <para>
	Ed ecco un esempio di un insieme di vincoli da applicare a un
	sistema (se il nome del sistema non contiene spazi, è
	possibile tralasciare le virgolette).
      </para>

      <code>
	restrict "Sistema 1"
	 b[1,1] = 0
	 b[1,2] - b[2,2] = 0
	 b[3,4] + 2*b[3,5] = 1
	end restrict
      </code>

      <para>
        Nel caso dell'equazione singola, i vincoli sono valutati attraverso un
        test <math>F</math> di Wald, usando la matrice di covarianza dei
        coefficienti del modello in questione. In modalità predefinita vengono
        mostrate le stime dei coefficienti vincolati; se si desidera solo la
        statistica test, basta aggiungere l'opzione <opt>quiet</opt> al
        comando <lit>restrict</lit> iniziale.
      </para>
      <para>
        Nel caso del sistema, la statistica test dipende dallo stimatore scelto:
        un test del rapporto di verosimiglianza nel caso di un sistema stimato
        con un metodo di massima verosimiglianza, o un test
        <math>F</math> asintotico negli altri casi.
      </para>

    </description>

    <gui-access>
      <menu-path>Modello, /Test/Vincoli lineari</menu-path>
    </gui-access>

  </command>
  
  <command name="restrict-model" section="Tests" context="gui"
    label="Vincoli su un modello">

    <description>

      <para>
	Ognuno dei vincoli da imporre a un modello deve essere
	espresso sotto forma di equazione con una combinazione lineare
	dei parametri al primo membro e un valore numerico al
	secondo. Nel caso della singola equazione, i parametri sono
	indicati con la sintassi
	<lit>b[</lit><repl>i</repl><lit>]</lit>, dove <repl>i</repl>
	rappresenta la posizione nella lista dei regressori, a partire
	da uno, oppure
	<lit>b[</lit><repl>variabile</repl><lit>]</lit>, dove
	<repl>variabile</repl> è il nome del regressore in questione.
      </para>

      <para>I termini <lit>b</lit> nell'equazione che rappresenta un vincolo
        possono essere prefissati con un moltiplicatore numerico usando il
        carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
        <lit>3.5*b[4]</lit>.
      </para>

      <para>Ecco ad esempio un insieme di vincoli:</para>

      <code>
	b[1] = 0
	b[2] - b[3] = 0
	b[4] + 2*b[5] = 1
      </code>

    </description>

  </command>

  <command name="restrict-system" section="Tests" context="gui"
    label="Vincoli su un sistema di equazioni">

    <description>

      <para>Ognuno dei vincoli da imporre a un sistema deve essere espresso
        sotto forma di equazione con una combinazione lineare dei parametri al
        primo membro e un valore numerico al secondo. 
        I parametri vengono indicati con la sintassi <lit>b</lit> seguita da due
        numeri tra parentesi quadre.  Il primo numero rappresenta la posizione
        dell'equazione all'interno del sistema, mentre il secondo indica la
        posizione nella lista dei regressori, entrambi contati a partire da uno.
        Ad esempio <lit>b[2,1]</lit> indica il primo parametro della seconda
        equazione, mentre <lit>b[3,2]</lit> il secondo parametro della terza
        equazione.
      </para>

      <para>I termini <lit>b</lit> nell'equazione che rappresenta un vincolo
        possono essere prefissati con un moltiplicatore numerico usando il
        carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
        <lit>3.5*b[1,4]</lit>.
      </para>

      <para>Ecco ad esempio un insieme di vincoli:</para>

      <code>
	b[1,1] = 0
	b[1,2] - b[2,2] = 0
	b[3,4] + 2*b[3,5] = 1
      </code>

    </description>

  </command>

  <command name="restrict-vecm" section="Tests" context="gui"
    label="Vincoli su un VECM">

    <description>

      <para>
	Questo comando impone restrizioni lineari sulle relazioni
        di cointegrazione (beta) e/o sui coefficienti di aggiustamento (alfa)
        in un modello vettoriale a correzione d'errore (VECM).
      </para>

      <para>Ognuno dei vincoli deve essere espresso sotto forma di equazione,
        con una combinazione lineare dei parametri al primo membro e un valore
        numerico al secondo membro. Le restrizioni su beta possono essere non
        omogenee (valore diverso da zero al secondo membro), ma quelle su alfa
        devono essere omogenee (valore zero al secondo membro).
      </para>

      <para>Se il VECM è di rango 1, è possibile esprimere gli elementi di beta nella
        forma <lit>b[</lit><repl>i</repl><lit>]</lit>,  dove <repl>i</repl>
        rappresenta la posizione nel vettore di correzione dell'errore, a
        partire da uno. Ad esempio, <lit>b[2]</lit> indica il secondo elemento
        di beta. Se il rango è maggiore di 1, è possibile esprimere i parametri
        usando <lit>b</lit> seguito da due numeri tra parentesi quadre. Ad
        esempio <lit>b[2,1]</lit> rappresenta il primo elemento nel secondo
        vettore di cointegrazione.
      </para>

      <para>
	Per riferirisi agli elementi di alfa, basta usare <lit>a</lit> al posto di
	<lit>b</lit>.
      </para>

      <para>Gli identificatori dei parametri nell'equazione che rappresenta un vincolo
        possono essere prefissati con un moltiplicatore numerico usando il
        carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
        <lit>3.5*b[4]</lit>.
      </para>

      <para>Ecco ad esempio un insieme di vincoli su un VECM di rango 1.
      </para>

      <code>
	b[1] + b[2] = 0
	b[1] + b[3] = 0
      </code>

      <para>
	Si veda anche la <guideref targ="chap:vecm"/>.
      </para>

    </description>

  </command>

  <command name="rmplot" section="Graphs"
    label="Grafici range-mean">

    <usage>
      <arguments>
        <argument>nome-variabile</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Grafici Range&ndash;mean: questo comando crea un semplice
        grafico che aiuta a capire se una serie storica
	<math>y</math>(t) ha varianza costante o no. L'intero
        campione t=1,...,T viene diviso in piccoli sotto-campioni di
        dimensione arbitraria <math>k</math>. Il primo
        sotto-campione è formato da
        <math>y</math>(1), ... ,<math>y</math>(k), il secondo
        da <math>y</math>(k+1), ... , <math>y</math>(2k), e
        così via.  Per ogni sotto-campione, vengono calcolati la media e
        il campo di variazione (range: il valore massimo meno quello
        minimo) e viene costruito un grafico con le medie sull'asse
        orizzontale e i campi di variazione su quello verticale, in modo
        che ogni sotto-campione sia rappresentato da un punto sul piano.
	Se la varianza della serie è costante, ci si aspetta che il
        campo di variazione del sotto-campione sia indipendente dalla
        media del sotto-campione; se i punti si dispongono su una linea
        crescente, la varianza della serie cresce al crescere della
        media, viceversa se i punti si dispongono su una linea
        decrescente.
      </para>

      <para>
	Oltre al grafico, gretl mostra anche le medie e i campi di
	variazione per ogni sotto-campione, insieme al coefficiente di
	pendenza della regressione OLS del campo di variazione sulla
	media e il p-value per l'ipotesi nulla che la pendenza sia
	zero.  Se il coefficiente di pendenza è significativo al
	livello del 10 per cento, viene mostrata sul grafico la linea
	stimata della regressione del campo di variazione sulla media.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Grafico range-mean</menu-path>
    </gui-access>

  </command>

  <command name="run" section="Programming" label="Esegue uno script di comandi" context="cli">

    <usage>
      <arguments>
        <argument>file-input</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Esegue i comandi nel <repl>file-input</repl> e restituisce il
	controllo al prompt interattivo. Questo comando si intende
	usato con il programma a riga di comando gretlcli, o con il
	<quote>terminale di gretl</quote> nel programma con
	interfaccia grafica.
      </para>
      <para>
	Si veda anche <cmdref targ="include"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>Icona Esegui nella finestra comandi</menu-path>
    </gui-access>

  </command>

  <command name="runs" section="Tests" label="Test delle successioni">

    <usage>
      <arguments>
        <argument>nome-variabile</argument>
      </arguments>
      <options>
       <option>
         <flag>--difference</flag>
         <effect>usa la differenza prima della variabile</effect>
       </option>
	<option>
	  <flag>--equal</flag>
	  <effect>i valori positivi e negativi sono equiprobabili</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Esegue il test non parametrico <quote>delle successioni</quote>
        per la casualità della variabile specificata, dove le successioni
        sono definite come sequenze di valori consecutivi positivi o negativi.
        Ad esempio, per testare la casualità delle deviazioni dalla mediana per
        una variabile chiamata <lit>x1</lit>, con una mediana diversa da zero,
        eseguire i comandi seguenti:
      </para>
      <code>
	genr signx1 = x1 - median(x1)
	runs signx1
      </code>
      <para>
       Se si usa l'opzione <opt>difference</opt>, la variabile viene differenziata
       prima dell'analisi, quindi le successioni sono interpretabili come
       sequenze di incrementi o decrementi consecutivi nel valore della
       variabile.
      </para>
      <para>
        Se si usa l'opzione <opt>equal</opt>, l'ipotesi nulla incorpora
        l'assunzione che i valori positivi e negativi siano equiprobabili,
        altrimenti la statistica test è invariante rispetto
        all'<quote>equilibrio</quote> del processo che genera la sequenza,
        focalizzandosi solo sull'indipendenza.
      </para>
    </description>

    <gui-access>
      <menu-path>/Strumenti/Test non parametrici</menu-path>
    </gui-access>

  </command>

  <command name="sampling" section="Dataset" context="gui"
    label="Impostazione del campione">

    <description>
      <para>Il menù Campione offre vari modi di selezionare un
      sotto-campione dal dataset in uso.</para>

      <para>
	Scegliendo <quote>Campione/Imposta in base a dummy...</quote>,
	viene chiesto di scegliere una variabile dummy (indicatrice),
        che può assumere solo valori 0 o 1 per ogni osservazione. Il
        campione verrà limitato alle osservazioni per cui la variabile
        dummy vale 1.</para>

      <para>Scegliendo <quote>Campione/Imposta in base a
	  condizione...</quote>, viene chiesto di inserire un'espressione
	Booleana (logica), dello stesso tipo di quella che si userebbe per
	definire una variabile dummy. Ad esempio, l'espressione
	<quote>sqft > 1400</quote> selezionerà solo le osservazioni per
	cui la variabile sqft ha un valore maggiore di 1400. Le condizioni
	possono essere concatenate con gli operatori logici
	<quote>&amp;&amp;</quote> (AND) e <quote>||</quote> (OR) e possono
	essere negate usando <quote>!</quote> (NOT).
      </para>

      <para>Il comando <quote>Campione/Scarta valori mancanti</quote>
      ridefinisce il campione in modo da escludere tutte le osservazioni
      per cui i valori di una o più variabili sono mancanti (lasciando
      nel campione solo i casi completi).</para>  

      <para>Per selezionare le osservazioni per cui solo una particolare
      variabile non ha valori mancanti, occorre usare
      <quote>Campione/Imposta in base a condizione...</quote> e inserire
      la condizione Booleana <quote>!missing(nome-variabile)</quote>
      (sostituire <quote>nome-variabile</quote> con il nome della
      variabile che si intende usare).</para>  

      <para>Se sono state associate etichette alle osservazioni, è possibile
      escludere una particolare osservazione dal campione impostando una
      condizione del tipo obs!="Francia". L'etichetta dell'osservazione deve
      essere racchiuso tra virgolette doppie.</para>

      <para>Occore tenere presente che ridefinendo il campione basandosi
      su una variabile dummy, un'espressione Booleana o sul criterio
      delle osservazioni mancanti, tutte le informazioni
      <quote>strutturali</quote> contenute nel file con la descrizione
      dei dati (riguardanti la struttura di serie storiche o di panel
      dei dati) vengono perse. È possibile reimpostare la struttura
      originale con <quote>Campione/Imposta frequenza e inizio...</quote>.</para>

      <para>Si veda la <guideref targ="chap:sampling"/> per maggiori dettagli.</para>

    </description>
  </command>

  <command name="save-labels" section="Utilities" 
    label="Save or remove series labels" context="gui">
    <description>
      <para>
	Se scegliete Export, gretl scriverà un file contenente le etichette
	descrittive di tutte le variabili nel dataset corrente dotate di etichetta.
	Il file sarà in formato testo con una linea per ogni variabile.
	La linea di una variabile priva di etichetta verrà lasciata vuota.
      </para>
      <para>
	Se scegliete Remove, verranno cancellate le etichette
	descrittive di tutte le variabili dotate di etichetta. Una scelta di questo tipo
	è appropriata solo se le etichette correnti sono state aggiunte per errore.
      </para>
    </description>
  </command>

  <command name="add-labels" section="Utilities" 
    label="Add series labels" context="gui">
    <description>
      <para>
	Se scegliete Sì, vi apparirà la finestra di dialogo usata per
	aprire un file di testo contenente le etichette descrittive
	per le variabili nel dataset corrente. Il file deve contenere
	un'etichetta per ogni linea; una linea vuota significa nessuna
	etichetta. Gretl tenterà di leggere un numero di etichette
	pari a quello delle variabili nel dataset, esclusa la
	costante.
      </para>
    </description>
  </command>

  <command name="save-script" section="Utilities" 
    label="Save commands?" context="gui">
    <description>
      <para>
	Se scegliete Sì gretl trascriverà su un file una registrazione
	dei comandi eseguiti nel corso della sessione corrente. La
	maggior parte dei comandi che scegliete di eseguire usando un
	<quote>point and click</quote> hanno uno <quote>script</quote>
	equivalente, ed è questo script che verrà trascritto.  Il file
	così generato può servire come punto di partenza per la
	stesura di uno script di comandi di gretl.
      </para>
      <para>
	Se non vi interessa la possibilità che in uscita venga salvata una registrazione
	dei comandi, deselezionate la casella nella finestra di dialogo salva comandi.
      </para>
    </description>
  </command>

  <command name="save-session" section="Utilities" 
    label="Save this gretl session?" context="gui">
    <description>
      <para>
	Se scegliete Sì, gretl scriverà un file contenente
	una<quote>fotografia</quote> della sessione corrente, compresa
	una copia del dataset corrente e di tutti i modelli, grafici o
	altri oggetti che avete salvato <quote>come icone</quote>.  In
	seguito potete riaprire questo file per ricreare lo stato di
	gretl al momento in cui è stata abbandonata la sessione (v. il
	menu <quote>File/Sessioni</quote>).
      </para>
      <para>
	Se siete interessati prevalentemente a lavorare con gretl
	usando script di comandi (un modo di procedere che consigliamo
	caldamente per svolgere analisi econometriche
	<quote>serie</quote>), probabilmente non vi interessa salvare
	la sessione, ma dovete essere sicuri di salvare nello script
	tutte le modifiche che vi interessa conservare. Potreste anche
	voler salvare le modifiche effettuate al dataset, a meno che
	non siano facilmente ricreabili eseguendo uno script.
      </para>
      <para>
	Se lavorate con script e non vi interessa la possibilità di
	salvare la sessione in uscita, deselezionate la casella nella
	finestra di dialogo salva sessione.
      </para>
    </description>
  </command>

  <command name="scatters" section="Graphs"
    label="Grafici multipli per coppie di variabili">

    <usage>
      <arguments>
        <argument>variabile-y</argument>
        <argument separated="true">lista-variabili-x</argument>
	<argument alternate="true">lista-variabili-y ; variabile-x</argument>
      </arguments>
      <options>
	<option>
	  <flag>--with-lines</flag>
	  <effect>crea grafici lineari</effect>
	</option>
      </options>
      <examples>
        <example>scatters 1 ; 2 3 4 5</example>
        <example>scatters 1 2 3 4 5 6 ; 7</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
        Produce grafici della <repl>variabile-y</repl> rispetto ad ognuna delle
        variabili nella <repl>lista-variabili-x</repl>, oppure di tutte le
        variabili nella <repl>lista-variabili-y</repl> rispetto alla
        <repl>variabile-x</repl>.  Il primo esempio visto sopra assegna
        la variabile 1 all'asse <math>y</math> e produce quattro
        grafici, il primo con la variabile 2 sull'asse
	<math>x</math>, il secondo con la variabile 3 sull'asse
	<math>x</math>, e così via. Il secondo esempio rappresenta
	ognuna delle variabili da 1 a 6 rispetto alla variabile 7
        sull'asse <math>x</math>. Questi gruppi di grafici sono
        utili nell'analisi esplorativa dei dati. È possibile creare fino
        a sei grafici alla volta, eventuali variabili in sovrappiù
        saranno ignorate.
      </para>
      <para context="cli">
        Per impostazione predefinita vengono prodotti dei classici grafici a
        dispersione, ma se si usa l'opzione <lit>--with-lines</lit> vengono
        mostrate anche le linee di collegamento tra i punti del grafico.
      </para>
      <para context="gui">
	Produce grafici a dispersione della <quote>Variabile asse
        Y</quote> selezionata rispetto ad ognuna delle <quote>Variabili
        asse X</quote> selezionate (ma è possibile fare anche viceversa). Questi
        gruppi di grafici sono utili nell'analisi esplorativa dei dati. È
        possibile creare fino a sei grafici alla volta, eventuali variabili in
        sovrappiù saranno ignorate.
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Grafici multipli</menu-path>
    </gui-access>

  </command>

  <command name="sdiff" section="Transformations" label="Differenziazione stagionale" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
    </usage>

    <description>
      <para>
       Calcola la differenza stagionale di ogni variabile della
       <repl>lista-variabili</repl> e salva il risultato in una nuova
       variabile con il prefisso <lit>sd_</lit>. Il comando è
       disponibile solo per serie storiche stagionali.
      </para>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Differenze stagionali</menu-path>
    </gui-access>

  </command>

  <command name="set" section="Programming" label="Imposta parametri del programma" context="cli">

    <usage>
      <arguments>
        <argument>variabile</argument>
        <argument>valore</argument>
      </arguments>
      <examples>
        <example>set svd on</example>
        <example>set csv_delim tab</example>
	<example>set horizon 10</example>
      </examples>    
    </usage>

    <description>
      <para>
	Imposta i valori di vari parametri del programma. Il valore
        impostato rimane in vigore per la durata della sessione di
        gretl, a meno di non essere modificato da un ulteriore
        esecuzione del comando <cmd>set</cmd>. I parametri che possono
        essere impostati in questo modo sono elencati di seguito.
        Si noti che le impostazioni di <lit>hac_lag</lit>, <lit>hc_version</lit>
        e <lit>hac_kernel</lit> sono usate quando viene data l'opzione
        <opt>robust</opt> a un comando di stima.
      </para>
      <para>
        Un uso speciale di questo comando è <cmd>set stopwatch</cmd>. In questo
        modo viene avviata la misurazione del tempo della CPU, che viene fermata
        la prima volta che viene usata la variabile accessoria
        <fncref targ="$stopwatch"/>, ad esempio assegnandola a un'altra variabile,
        oppure stampandola. <fncref targ="$stopwatch"/> conterrà il numero di secondi
        usati dalla CPU, dal momento in cui è stato dato il comando
        <lit>set stopwatch</lit>.
      </para>
      <para>
        Se il comando <cmd>set</cmd> è usato senza parametri, vengono
        mostrate le impostazioni attuali per tutti i parametri rilevanti.
      </para>
      <para>
	Le impostazioni disponibili sono raggruppate in sei categorie:
        interazione col programma, metodi numerici, generazione di numeri
        casuali, stima robusta, filtri e stima di modelli per serie storiche.
      </para>

      <para>
	<emphasis>Interazione con il programma</emphasis>
      </para>
      <para>
	Queste impostazioni servono per controllare vari aspetti del modo in cui
        gretl interagisce con l'utente.
      </para>
      <ilist>
	<li>
	  <para><lit>csv_delim</lit>:
	  <lit>comma</lit> (virgola, valore predefinito), <lit>space</lit>
            (spazio), o <lit>tab</lit>. Imposta il delimitatore di colonna usato nel
            salvataggio di dati su file in formato CSV.
	  </para>
	</li>
	<li>
	  <para><lit>echo</lit>:
	  <lit>off</lit> o <lit>on</lit> (valore predefinito).
	    Sopprime o ripristina l'indicazione dei comandi eseguiti nell'output
            dei risultati.</para>
	</li>
	<li>
	  <para><lit>force_decpoint</lit>: <lit>on</lit> o <lit>off</lit>
	    (valore predefinito).  Forza gretl a usare il carattere punto come
            separatore decimale, in un ambiente in cui il separatore standard è
            un'altro carattere (tipicamente la virgola).
	  </para>
	</li>
	<li>
	  <para><lit>halt_on_error</lit>: <lit>off</lit> o
	  <lit>on</lit> (valore predefinito). Quando è attivo, se si verifica un
          errore all'interno di un loop, questo si interromperà. Se si usa il
          client a riga di comando, il programma terminerà.
	  </para>
	</li>
        <li>
          <para><lit>loop_maxiter</lit>: un valore intero non
          negativo.  Imposta il numero massimo di iterazioni
          consentite prima che un loop di tipo <lit>while</lit> si
          fermi (si veda <cmdref targ="loop"/>).  Si noti che questa
          impostazione riguarda solo la variante <lit>while</lit>,
          visto che lo scopo è quello di interrompere possibili cicli
          infiniti. Il valore speciale 0 viene usato per rendere tali
          cicli potenzialmente infiniti, visto che non viene fatto
          alcun controllo sul numero di iterazioni. Usare con cautela.
         </para>
        </li>
	<li>
	  <para><lit>max_verbose</lit>: <lit>on</lit> o
	  <lit>off</lit> (valore predefinito). Attiva l'output aggiuntivo per la
          funzione <lit>BFGSmax</lit> (si veda la Guida all'uso per i dettagli).
	  </para>
	</li>
 	<li>
	  <para><lit>messages</lit>: <lit>off</lit> o <lit>on</lit> (valore
            predefinito). Sopprime o ripristina l'indicazione dei messaggi
            informativi associati a vari comandi, ad esempio quando viene
            generata una nuova variabile o viene modificato l'intervallo del
            campione.
         </para>
	</li>
 	<li>
	  <para><lit>debug</lit>: <lit>1</lit>, <lit>2</lit> o <lit>0</lit>
	    (valore predefinito). Da usare per le funzioni definite dall'utente.
	    Impostare <lit>debug</lit> a 1 equivale a impostare
	    <lit>messages</lit> in tutte queste funzioni; impostando la
            variabile a <lit>2</lit> ha l'effetto aggiuntivo di impostare
	    <lit>max_verbose</lit> in tutte le funzioni.
	  </para>
	</li>
	<li>
	  <para><lit>shell_ok</lit>: <lit>on</lit> o <lit>off</lit>
	  (valore predefinito). Abilita l'esecuzione di programmi esterni da
          gretl attraverso la shell di sistema. Per motivi di sicurezza, la
          funzione è disabilitata per impostazione predefinita; inoltre è
          possibile abilitarla solo tramite l'interfaccia grafica
          (Strumenti/Preferenze/Generali). Una volta abilitata, l'impostazione
          rimarrà attiva per le successive sessioni, fino a che non sarà
          disabilitata esplicitamente.
	  </para>
	</li>
	<li>
	  <para><lit>shelldir</lit>: <repl>percorso</repl>. Imposta la directory
           di lavoro attuale per i comandi shell.
         </para>
	</li>
	<li>
	  <para><lit>use_cwd</lit>: <lit>on</lit> o <lit>off</lit>
	  (valore predefinito). Questa impostazione modifica il comportamento
          dei comandi <cmdref targ="outfile"/> e <cmdref targ="store"/>, che
          scrivono su file esterni. Normalmente, il file verrà scritto nella
          directory dati predefinita dell'utente: se si imposta
	  <lit>use_cwd</lit> a <lit>on</lit>, al contrario, il file verrà creato
          nella directory di lavoro da cui gretl è stato eseguito.
	  </para>
	</li>
      </ilist>

      <para>
	<emphasis>Metodi numerici</emphasis>
      </para>
      <para>
	Queste impostazioni vengono usate per controllare gli algoritmi numerici
        usati da gretl per la stima.
      </para>
      <ilist>
	<li>	
	<para><lit>bhhh_maxiter</lit>: un intero. Imposta il massimo numero di
          iterazioni per la routine BHHH, che è usata dal comando
          <cmd>arma</cmd>. Se non viene raggiunta la convergenza dopo
          <lit>bhhh_maxiter</lit>, il programma segnala un errore. Il valore
          predefinito è 500.
	  </para>
	</li>	  
	<li>	  
	  <para><lit>bhhh_toler</lit>: un valore a virgola mobile, oppure la
            stringa <lit>default</lit>. Viene usato dalla routine BHHH di gretl
            per controllare se viene raggiunta la convergenza. L'algoritmo di
            calcolo ferma le iterazioni non appena l'incremento nella
            log-verosimiglianza tra le iterazioni è minore di <lit>bhhh_toler</lit>.
            Il valore predefinito è 1.0E&minus;06; questo valore può essere reimpostato
            usando la stringa <lit>default</lit> invece di un valore numerico.
	  </para>
	</li>
	<li>
	  <para><lit>bfgs_maxiter</lit>: un valore intero. Rappresenta il
            massimo numero di iterazioni per la routine BFGS di gretl,
            usata da <cmd>mle</cmd>, <cmd>gmm</cmd> e altri stimatori.
            Se non si raggiunge la convergenza nel numero specificato di
            iterazioni, il programma produce un messaggio di errore. Il valore
            predefinito dipende dal contesto, ma tipicamente è nell'ordine delle
            500 iterazioni.
	  </para>
	</li>	  
	<li>	  
	  <para><lit>bfgs_toler</lit>: un valore in virgola mobile, o la stringa
	    <lit>default</lit>. Viene usato nella routine BFGS di gretl per
            controllare se si è raggiunta la convergenza. L'algoritmo si ferma
            appena l'incremento relativo nella funzione obiettivo tra
            un'iterazione e l'altra è minore di
	    <lit>bfgs_toler</lit>.  Il valore predefinito è pari alla precisione
            della macchina elevata alla potenza 3/4; questo valore può essere
            re-impostato usando la stringa <lit>default</lit> invece di un valore numerico.
 	  </para>
	</li>	  
	<li>	  
          <para><lit>initvals</lit>: una matrice pre-specificata. Permette di
            impostare manualmente le stime dei parametri ARMA. Per i dettagli,
            si veda la <guideref targ="chap:timeseries"/>.
	  </para>
	</li>
	<li>
          <para><lit>lbfgs</lit>: <lit>on</lit> o <lit>off</lit> (valore
          predefinito). Usa la versione a memoria limitata di BFGS, al posto
          dell'algoritmo standard. Può essere vantaggioso quando la funzione da
          massimizzare non è globalmente concava.
	  </para>
	</li>
        <li>
	<para>
	  <lit>nls_toler</lit>: un valore in virgola mobile (il valore
          predefinito è pari alla precisione della macchina elevata alla potenza
          3/4). Imposta la tolleranza usata per stabilire se è stata raggiunta
          la convergenza nelle procedure iterative di stima con i minimi
          quadrati non lineari usate dal comando <cmdref targ="nls"/>.
	</para>
        </li>
	<li>
	  <para><lit>svd</lit>:
	  <lit>on</lit> o <lit>off</lit> (valore predefinito).
	    Usa la decomposizione SVD invece di quella di Cholesky o della QR nel
            calcolo delle stime OLS. Questa opzione si applica alla funzione
            <lit>mols</lit> e a vari altri calcoli eseguiti internamente, ma non
            al comando <cmdref targ="ols"/>.
          </para>
	</li>
	<li>
          <para><lit>fcp</lit>: <lit>on</lit> o <lit>off</lit> (valore
          predefinito). Usa l'algoritmo di Fiorentini, Calzolari e Panattoni
          al posto del codice interno di gretl per  calcolare le stime GARCH.
	  </para>
	</li>
	<li>
	  <para><lit>gmm_maxiter</lit>: un intero, il numero massimo
	  di iterazioni per il comando <cmdref targ="gmm"/> con
	  l'opzione <opt>iterate</opt>. Il default è 250.
	  </para>
	</li>
	<li>
	  <para><lit>nadarwat_trim</lit>: un intero, il parametro di
	  taglio usato dalla funzione <fncref targ="nadarwat"/>.
	  </para>
	</li>
	<li>
	  <para><lit>fdjac_quality</lit>: un intero fra 0 e 2,
	  corrsipondente all'algoritmo usato nella funzione <fncref
	  targ="fdjac"/>.
	  </para>
	</li>
      </ilist>

      <para>
	<emphasis>Generazione di numeri casuali</emphasis>
      </para>

      <ilist>
        <li>
          <para><lit>seed</lit>: un intero senza segno. Imposta il seme per il
            generatore di numeri pseudo-casuali. Di solito il seme viene
            impostato a partire dall'ora di sistema, ma se si intende
            generare sequenze ripetibili di numeri casuali occorre impostare
            il seme manualmente.
          </para>
        </li>
      </ilist>

      <para>
	<emphasis>Stima robusta</emphasis>
      </para>

      <ilist>
	<li>
	  <para><lit>bootrep</lit>: un intero. Imposta il numero di replicazioni
          per il comando <cmdref targ="restrict"/> con l'opzione <opt>bootstrap</opt>.
          </para>
	</li>
	<li>
	  <para><lit>garch_vcv</lit>:
	  <lit>unset</lit>, <lit>hessian</lit>,
	    <lit>im</lit> (matrice di informazione) , <lit>op</lit>
            (matrice dei prodotti esterni), <lit>qml</lit> (stimatore QML),
	    <lit>bw</lit> (Bollerslev&ndash;Wooldridge). Specifica la
            variante da usare per stimare la matrice di covarianza dei
            coefficienti nei modelli GARCH.  Se si usa <lit>unset</lit>
	    (valore predefinito), viene usata l'Hessiana, a meno di
            usare l'opzione <quote>robust</quote> col comando garch, nel
            qual caso viene usato QML.
          </para>
	</li>
	<li>
	  <para><lit>arma_vcv</lit>: <lit>hessian</lit> (predefinito) o
	    <lit>op</lit> (prodotto esterno). Specifica la variante
	    da usare per calcolare la matrice di covarianza per i modelli ARIMA.
	  </para>
 	</li>
	<li>
	  <para><lit>force_hc</lit>: <lit>off</lit> (predefinito) o
	  <lit>on</lit>. Lo stimatore HAC viene usato in modo
	  predefinito con dati serie storiche e quando si usa
	  l'opzione <opt>robust</opt> di <lit>ols</lit>. Impostando
	  invece <lit>force_hc</lit> a <quote>on</quote>, si forza
	  l'uso della matrice di covarianza coerente con
	  l'eteroschedasticità (che non tiene conto
	  dell'autocorrelazione).
	  </para>
	</li>
	<li>
	  <para><lit>hac_lag</lit>:
	  <lit>nw1</lit> (valore predefinito), <lit>nw2</lit>,
	    <lit>nw3</lit>, o un intero.  Imposta il massimo valore di
            ritardo, o la larghezza di banda, <math>p</math>, usato nel calcolo degli
            errori standard HAC (Heteroskedasticity and Autocorrelation Consistent)
	    con l'approccio Newey-West, per le serie storiche.
            <lit>nw1</lit> e <lit>nw2</lit> rappresentano due varianti
            di calcolo automatico basate sulla dimensione del campione,
	    <math>T</math>: per nw1, 
            <equation status="inline"
              tex="$p = 0.75 \times T^{1/3}$"
              ascii="p = 0.75 * T^(1/3)"
              graphic="nw1"/>,
              e per nw2, 
            <equation status="inline"
              tex="$p = 4 \times (T/100)^{2/9}$"
              ascii="p = 4 * (T/100)^(2/9)"
              graphic="nw2"/>.
            <lit>nw3</lit> permette di selezionare la larghezza di banda
            basandosi sui dati.  Si veda anche <lit>qs_bandwidth</lit> e
            <lit>hac_prewhiten</lit>.
	  </para>
	</li>
	<li>
	  <para><lit>hac_kernel</lit>: <lit>bartlett</lit> (valore predefinito),
	    <lit>parzen</lit>, o <lit>qs</lit> (Quadratic Spectral). Imposta il
            kernel, o struttura di pesi, usato nel calcolo degli errori standard
            HAC.
	  </para>
	</li>
	<li>
	  <para><lit>hac_prewhiten</lit>: <lit>on</lit> o <lit>off</lit>
	    (valore predefinito). Usa le procedure di <quote>prewhitening</quote> e
            <quote>re-coloring</quote> di Andrews-Monahan nel calcolo degli
            errori standard HAC. Questo comporta anche la selezione della
            larghezza di banda basata sui dati.
	  </para>
	</li>
	<li>
	  <para><lit>hc_version</lit>:
	  0 (valore predefinito), 1, 2, 3 o 3a. Imposta la
          variante da usare nel calcolo degli errori standard HAC
          (Heteroskedasticity and Autocorrelation Consistent) con dati
          di tipo cross section. Le prime 4 opzioni corrispondono alle HC0, HC1,
          HC2 e HC3 discusse da Davidson e MacKinnon nel capitolo 5 di
          <book>Econometric Theory and Methods</book>.  HC0 produce
          quelli che di solito vengono chiamati <quote>errori standard di
          White</quote>. La variante 3a è la procedura <quote>jackknife</quote>
          di MacKinnon&ndash;White.
          </para>
        </li>
	<li>
	  <para><lit>pcse</lit>: <lit>off</lit> (impostazione predefinita) o
	    <lit>on</lit>.  Di solito, quando si stima un modello con pooled OLS
            su dati panel usando l'opzione <opt>robust</opt>, viene usato lo
            stimatore di Arellano per la matrice di covarianza. Se si imposta
            <lit>pcse</lit> a <quote>on</quote>, verranno usati i Panel
            Corrected Standard Errors (PCSE) di Beck e Katz, che non tengono
            conto dell'autocorrelazione.
	  </para>
	</li>
	<li>
	  <para><lit>qs_bandwidth</lit>: larghezza di banda per la stima HAC
            nel caso in cui si scelga il kernel "Quadratic Spectral" (a differenza
            dei kernel Bartlett e Parzen, la larghezza di banda QS non deve essere
            necessariamente un intero).
	  </para>
	</li>
      </ilist>

      <para>
	<emphasis>Filtri</emphasis>
      </para>

      <ilist>
	<li>
	  <para><lit>hp_lambda</lit>:
	  <lit>auto</lit> (valore predefinito), o un
          valore numerico. Imposta il parametro di livellamento per
          il filtro di Hodrick&ndash;Prescott (si veda la funzione
          <lit>hpfilt</lit> sotto il comando <lit>genr</lit>). Il valore
          predefinito è 100 volte il quadrato della periodicità, ossia
          100 per i dati annuali, 1600 per i dati trimestrali e così
          via.</para>
	</li>
        <li>
          <para><lit>bkbp_limits</lit>:
          due interi, il secondo maggiore del primo
           (i valori predefiniti sono 8 e 32). Imposta i limiti di
           frequenza per il filtro passa-banda di Baxter&ndash;King
           (si veda la funzione <lit>bkfilt</lit> nel comando <lit>genr</lit>).
         </para>
        </li>
        <li>
          <para><lit>bkbp_k</lit>:
          un intero (il valore predefinito è 8). Imposta
            l'ordine di approssimazione per il filtro passa-banda di
            Baxter&ndash;King.
          </para>
        </li>
      </ilist>

      <para>
	<emphasis>Serie storiche</emphasis>
      </para>
      
      <ilist>
	<li>
	  <para><lit>horizon</lit>: un intero (il valore predefinito
	  dipende dalla frequenza dei dati). Imposta l'orizzonte per
	  le funzioni impulso-risposta e per la decomposizione della
	  varianza nel contesto delle autoregressioni vettoriali.
	  </para>
	</li>
	<li>
	  <para><lit>vecm_norm</lit>: <lit>phillips</lit> (valore
	  predefinito), <lit>diag</lit>, <lit>first</lit> o
	  <lit>none</lit>. Usato nel contesto della stima VECM,
	  attraverso il comando <cmdref targ="vecm"/> per identificare
	  i vettori di cointegrazione. Si veda la Guida all'uso per i
	  dettagli.
	  </para>
	</li>
      </ilist>

    </description>
  </command>
  
  <command name="setinfo" section="Dataset" label="Modifica degli attributi di una variabile">

    <usage>
      <arguments>
        <argument>nome-variabile</argument>
        <argument flag="-d ">descrizione</argument>
        <argument flag="-n ">nome-grafici</argument>
      </arguments>
      <options>
	<option>
	  <flag>--discrete</flag>
	  <effect>marca la variabile come discreta</effect>
	</option>
	<option>
	  <flag>--continuous</flag>
	  <effect>marca la variabile come continua</effect>
	</option>
      </options>
      <examples>
        <example>setinfo x1 -d "Descrizione di x1" -n "Nome nei grafici"</example>
	<example>setinfo z --discrete</example>
      </examples>
    </usage>

    <description context="cli">
      <para>
        Imposta fino a tre attributi di una variabile, nel modo seguente.
      </para>
      <para>
        Usando l'opzione <lit>-d</lit> seguita da una stringa tra
        virgolette doppie, la stringa verrà usata come etichetta descrittiva per
        la variabile indicata, che viene mostrata dal comando <cmdref
        targ="labels"/> e anche nella finestra principale del programma.
      </para>
      <para>
        Usando l'opzione <lit>-n</lit> seguita da una stringa tra
        virgolette doppie, la stringa verrà usata nei grafici al posto del nome
        della variabile.
      </para>
      <para>
        Usando una delle opzioni <opt>discrete</opt> o
        <opt>continuous</opt>, viene impostato il carattere numerico della
        variabile.  In modalità predefinita, tutte le variabili sono considerate come
        continue; marcando una variabile come discreta, essa viene trattata in
        modo speciale nei diagrammi di frequenza.
      </para>
    </description>

    <description context="gui">

      <para>
	In questa finestra di dialogo è possibile:</para>

      <para>* Rinominare una variabile.</para>

      <para>* Aggiungere o modificare una descrizione della variabile,
        che appare accanto al nome della variabile nella finestra
        principale di gretl.</para>

      <para>* Aggiungere o modificare il "nome per i grafici" della
        variabile (se la variabile è una serie e non uno scalare).
        Questa stringa (lunga al massimo 19 caratteri) viene
        usata al posto del nome della variabile quando questa compare in
        un grafico. Così, ad esempio, è possibile associare una stringa
        più comprensibile come "Tariffe telefoniche" a un nome criptico
        come "tartel".</para>

      <para>* Impostare (se i dati sono serie storiche) il
        metodo di compattamento per la variabile, che verrà usato se si
        decide di ridurre la frequenza del dataset, o se si importa la
        variabile da un dataset che ha una frequenza maggiore di quella
        del dataset in uso.
      </para>

      <para>* Marcare una variabile come discreta (per serie che contengono
        solo valori discreti). In questo modo, essa viene
        trattata in modo speciale nei diagrammi di frequenza.
      </para>

      <para>* Impostare il valore di una variabile (per variabili discrete).
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Modifica attributi</menu-path>
      <other-access>Menù pop-up nella finestra principale</other-access>
    </gui-access>

  </command>

  <command name="setmiss" section="Dataset"
    label="Codice dei valori mancanti">

    <usage>
      <arguments>
        <argument>valore</argument>
        <argument optional="true">lista-variabili</argument>
      </arguments>
      <examples>
        <example>setmiss -1</example>
        <example>setmiss 100 x2</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Imposta il programma in modo da interpretare un dato valore
        numerico (il primo parametro indicato al comando) come codice
        per i <quote>valori mancanti</quote> nei dati importati. Se
        questo valore è l'unico parametro fornito, come nel primo degli
        esempi precedenti, l'interpretazione verrà applicata a tutte le
        serie del dataset. Se <repl quote="true">valore</repl> è seguito
        da una lista di variabili, indicate per nome o numero,
        l'interpretazione è limitata solo alle variabili specificate.
        Così, nel secondo esempio, il valore 100 è interpretato come
        codice per <quote>mancante</quote>, ma solo per la variabile
        <lit>x2</lit>.
      </para>
      
      <para context="gui">
	Imposta un valore numerico che verrà interpretato come
        "mancante" o "non applicabile", per una particolare serie (sotto
        il menù Variabile) o globalmente per l'intero dataset (sotto il
        menù Campione).</para> 
      
      <para context="gui">
      Gretl ha un codice interno per i valori mancanti, che non sempre
      può coincidere con quello usato dai dati importati. Ad esempio, se
      una serie usa il valore -1 col significato di "non disponibile", è
      possibile selezionare "Imposta codice valori mancanti" nel menù
      Variabile e immettere il valore "-1" (senza le virgolette); gretl
      interpreterà quindi i valori -1 come osservazioni mancanti.</para>

    </description>

    <gui-access>
      <menu-path>/Campione/Imposta codice valori mancanti</menu-path>
    </gui-access>

  </command>

  <command name="setobs" section="Dataset" context="cli"
    label="Frequenza e osservazione iniziale">

    <usage>
      <altforms>
        <altform>setobs <repl>periodicità</repl> <repl>oss-iniziale</repl></altform>
	<altform>setobs <repl>variabile-unità</repl> <repl>variabile-periodi</repl></altform>
      </altforms>
      <options>
        <option>
	  <flag>--cross-section</flag>
	  <effect>interpreta come cross section</effect>
        </option>
        <option>
	  <flag>--time-series</flag>
	  <effect>interpreta come serie storiche</effect>
        </option>
        <option>
	  <flag>--special-time-series</flag>
	  <effect>vedi sotto</effect>
        </option>	
        <option>
	  <flag>--stacked-cross-section</flag>
	  <effect>interpreta come panel</effect>
        </option>
        <option>
	  <flag>--stacked-time-series</flag>
	  <effect>interpreta come panel</effect>
        </option>
        <option>
	  <flag>--panel-vars</flag>
	  <effect>usa variabili indice (si veda oltre)</effect>
        </option>
      </options>
      <examples>
        <example>setobs 4 1990:1 --time-series</example>
        <example>setobs 12 1978:03</example>
	<example>setobs 1 1 --cross-section</example>
        <example>setobs 20 1:1 --stacked-time-series</example>
	<example>setobs unita anno --panel-vars</example>
      </examples>
    </usage>

    <description>
      <para>
	Forza il programma a interpretare il dataset in uso secondo la
        struttura specificata.
      </para>
      <para>
        Nella prima forma del comando, la <repl>periodicità</repl>, che deve
        essere un valore intero, nel caso delle serie storiche rappresenta la
        frequenza delle osservazioni (1 = annuale; 4 = trimestrale; 12 =
        mensile; 52 = settimanale; 5, 6, o 7 = giornaliera; 24 = oraria). Nel
        caso di dati panel, la periodicità è il numero di righe per ogni blocco
        di dati, ossia il numero di unità cross section se i dati sono
        organizzati come pila di dati cross section, o il numero di periodi se i
        dati sono organizzati come pila di serie storiche. Nel caso di semplici
        dati cross section, la periodicità dev'essere impostata a 1.
      </para>
      <para>
	L'osservazione iniziale rappresenta la data iniziale nel caso
        delle serie storiche. Gli anni possono essere indicati con due
        o quattro cifre, mentre i sotto-periodi (ad esempio i trimestri
        o i mesi) devono essere separati dagli anni con un carattere "due punti".
	Nel caso di dati panel, l'osservazione iniziale va indicata come
	1:1, mentre nel caso di dati cross section come 1. L'osservazione
        iniziale per i dati giornalieri o settimanali va indicata nella forma
	AA/MM/GG o AAAA/MM/GG (oppure semplicemente 1 per i dati non datati).
      </para>
      <para>
	Alcune periodicità temporali hanno interpretazioni
	convenzionali; ad esempio, 12 = mensile e 4 = trimestrale. Se
	questa interpretazione non si applica alle vostre serie
	storiche,si può usare l'opzione
	<opt>special-time-series</opt>. In tal caso, gretl
	si asterrà dall'indicare come (ad esempio) mensile una
	periodicità pari a 12.
      </para>
      <para>
	Se non viene data alcuna opzione esplicita per indicare la
	struttura dei dati, il programma tenterà di desumerla dalle
	informazioni in suo possesso.
      </para>
     <para>
        La seconda forma del comando (che richiede l'uso dell'opzione
	<lit>--panel-vars</lit>) può essere usata per imporre un'interpretazione
        panel dei dati, quando il dataset contiene variabili che identificano in
        modo univoco le unità cross section e i periodi. Il dataset verrà
        ordinato come pila di serie storiche, per valori crescenti della
        variabile che rappresenta le unità, <repl>variabile-unità</repl>.
      </para>
      <subhead>Opzioni specifiche per dati panel</subhead>
      <para>
	Le opzioni <opt>panel-time</opt> e <opt>panel-groups</opt>
	possono essere usate solo con dataset già impostati come panel.
      </para>
      <para>
	La funzione di <opt>panel-time</opt> è di stabilire
	informazioni extra sulla dimesnione temporale del panel. Essa
	deve essere indicata sul modello della proma forma di 
	<lit>setobs</lit> (vedi sopra). Ad esempio, il compando
	seguente indica che la dimensione temporale del panel è
	trimestrale, e comincia nel primo trimestre 1990.
      </para>
      <code>
	setobs 4 1990:1 --panel-time
      </code>
      <para>
	La funzione di <opt>panel-groups</opt> è di creare una serie
	con valori stringa contentent i nomi delle unità longitudinal
	inel panel. (Quest'informazione verrà, eventualmente, usata
	nei grafici.) Con quest'opzione vanno indicati uno o due
	argomenti, come segue.
      </para>
      <para>
	Caso uno: l'unico argomento è il nome di una serie a valori
	stringa. Se il numero di stringhe diverse eguaglia il numero
	di unità nel panel, allora questi vengono usati come nomi dei
	gruppi. Se necessario, il contenuto numerico della serie sarà
	aggiustato per far sì che i valori siano tutti 1 per la prima
	unità, 2 per la seconda eccetera. Se il numero di valori
	stringa non corrisponde a quello delle unità, il programma
	segnala un errore.
      </para>
      <para>
	Caso due: il primo argomento è il nome di una serie e il
	secondo è una stringa (o il nome di una variabile stringa) con
	etichette per ciascuna unità. Se la serie non esiste, verrà
	creata al momento. Nel secondo argomento, i nomi delle unità
	vanno separati da spazi; se il nome stesso include degli
	spazi, allora va racchiuso fra <lit>\"</lit>. Se no, il
	secondo argomento può essere un array di stringhe.
      </para>
      <para>
	Ad esempio, il codice seguente creerò una serie di nome
	<lit>paese</lit> in cui i nomi <lit>npaesi</lit> sono ripetuti
	ognuno <math>T</math> volte, dove <math>T</math> è l'ampiezza
	temporale del panel.
      </para>
      <code>
	string npaesi = sprintf("Francia Germania Italia \"Regno Unito\"")
	setobs paese npaesi --panel-groups
      </code>
    </description>

    <gui-access>
      <menu-path>Dati/Struttura dataset</menu-path>
    </gui-access>

  </command>

  <command name="shell" section="Utilities" label="Esegue comandi shell" context="cli">

    <usage>
      <arguments>
        <argument>comando-shell</argument>
      </arguments>
      <examples>
        <example>! ls -al</example>
	<example>! notepad</example>
	<example>launch notepad</example>
      </examples>
    </usage>

    <description>
      <para>
        Un <cmd>!</cmd>, o la parola chiave <cmd>launch</cmd>, all'inizio di una
        riga di comando è interpretato come passaggio all'interprete di comandi
        (shell) usato dall'utente nel sistema operativo. In questo modo è
        possibile eseguire comandi shell arbitrari dall'interno di
	<program>gretl</program>. Quando si usa <cmd>!</cmd>, il comando esterno
        viene eseguito in modalità sincrona, ossia <program>gretl</program> aspetta
        il termine della sua esecuzione prima di procedere. Se invece si vuole
        avviare un altro programma da dentro <program>gretl</program> senza
        aspettare che abbia completato la sua esecuzione (modalità asincrona),
        occorre usare <cmd>launch</cmd>.
      </para>
      
      <para>
        Per motivi di sicurezza, questa funzionalità è disabilitata in modalità
        predefinita. Per attivarla, occorre selezionare la casella
        <quote>Abilita comandi shell</quote> nel menù File, Preferenze. In
        questo modo si renderanno disponibili i comandi shell anche nella
        modalità a riga di comando di <program>gretl</program> (questo è l'unico
        modo per farlo).
      </para>
    </description>

  </command>

  <command name="smpl" section="Dataset" label="Imposta l'intervallo del campione" context="cli">

    <!-- don't break the lines below or the text version will get messed
    up -->

    <usage>
      <altforms>
	<altform><lit>smpl</lit> <repl>oss-iniziale oss-finale</repl></altform>
	<altform><lit>smpl</lit> <repl>+i -j</repl></altform>
	<altform><lit>smpl</lit> <repl>variabile-dummy</repl> <opt>dummy</opt></altform>
	<altform><lit>smpl</lit> <repl>condizione</repl> <opt>restrict</opt></altform>
	<altform><lit>smpl</lit> <lit>--no-missing [ </lit><repl>lista-variabili</repl> <lit>]</lit></altform>
 	<altform><lit>smpl</lit> <repl>n</repl> <opt>random</opt></altform>
	<altform><lit>smpl full</lit></altform>
      </altforms>
      <examples>
        <example>smpl 3 10</example>
	<example>smpl 1960:2 1982:4</example>
	<example>smpl +1 -1</example>
	<example>smpl x > 3000 --restrict</example>
	<example>smpl y > 3000 --restrict --replace</example>
	<example>smpl 100 --random</example>
      </examples>
    </usage>

    <description>
      <para>
	Reimposta l'intervallo del campione. Il nuovo intervallo può
        essere definito in vari modi. Nel primo modo (corrispondente ai
        primi due esempi precedenti) <repl>oss-iniziale</repl> e
        <repl>oss-finale</repl> devono essere coerenti con la
        periodicità dei dati. Una delle due può essere sostituita da un
        punto e virgola per lasciare intatto il valore attuale. Nel
        secondo modo, gli interi <repl>i</repl> e <repl>j</repl> (che
        possono essere positivi o negativi e vanno indicati con il
        segno) sono presi come spostamenti relativi ai punti iniziale e
        finale del campione in uso. Nel terzo modo,
        <repl>variabile-dummy</repl> deve essere una variabile
        indicatrice che assume solo valori 0 o 1 e il campione verrà
        ristretto alle osservazioni per cui la variabile dummy vale 1.
	Il quarto modo, che usa <opt>restrict</opt>, limita il
        campione alle osservazioni che soddisfano la condizione Booleana
	specificata secondo la sintassi del comando <cmdref
        targ="genr"/>.</para>

      <para>Con la forma <lit>--no-missing</lit>, se viene specificata
      una <repl>lista-variabili</repl>, vengono selezionate le osservazioni
      per cui tutte le variabili nella <repl>lista-variabili</repl>
      hanno valori validi in corrispondenza dell'osservazione; altrimenti, se
      non viene indicata alcuna <repl>lista-variabili</repl>, vengono
      selezionate le osservazioni per cui <emphasis>tutte</emphasis> le
      variabili hanno valori validi (non mancanti).</para>

      <para>Con la forma <opt>random</opt>, viene estratto casualmente dal
      dataset il numero indicato di osservazioni. Per essere in grado di
      replicare questa selezione, occorre per prima cosa impostare il seme
      del generatore di numeri casuali (si veda il comando
	<cmdref targ="set"/>).</para>
 
      <para>La forma finale, <lit>smpl full</lit>, ripristina
      l'intervallo completo del campione.
      </para>
 
      <para>Si noti che i vincoli sul campione di solito sono
      cumulativi: il valore di riferimento di ogni comando
      <lit>smpl</lit> è il campione attuale, così che ogni vincolo si
      aggiunge a quelli già impostati. Se si vuole che il comando
      funzioni sostituendo i vincoli esistenti, occorre usare
      l'opzione <opt>replace</opt> alla fine del comando.</para>

      <para>La variabile interna <lit>obs</lit> può essere usata con la
      forma <opt>restrict</opt> di <lit>smpl</lit> per escludere
      particolari osservazioni dal campione. Ad esempio,</para>

      <code>
	smpl obs!=4 --restrict
      </code>
        
      <para>scarterà la quarta osservazione. Se le osservazioni sono
        identificate da etichette,</para>
        
      <code>
        smpl obs!="USA" --restrict
      </code>
        
        <para>scarterà l'osservazione a cui è associata l'etichetta
        <quote>USA</quote>.
        </para>

      <para>Per le forme <opt>dummy</opt>, <opt>restrict</opt> e
      <lit>--no-missing</lit> di <lit>smpl</lit>, occore tenere presente
      che tutte le informazioni <quote>strutturali</quote> contenute nel
      file dei dati (a proposito della struttura di serie storiche o di
      panel dei dati) vengono perse. È possibile reimpostare la
      struttura originale con il comando <cmdref targ="setobs"/>.
      </para>

      <para>Si veda la <guideref targ="chap:sampling"/> per ulteriori dettagli.</para>
    
    </description>

    <gui-access>
      <menu-path>/Campione</menu-path>
    </gui-access>

  </command>

  <command name="spearman" section="Statistics"
    label="Correlazione di rango di Spearman">

    <usage>
      <arguments>
        <argument>x</argument>
        <argument>y</argument>
      </arguments>
      <options>
        <option>
	  <flag>--verbose</flag>
	  <effect>mostra i dati ordinati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para context="cli">
	Mostra il coefficiente di correlazione di rango di Spearman per
        le variabili <math>x</math> e <math>y</math>. Le
        variabili non devono essere state ordinate manualmente in
        precedenza, se ne occupa la funzione.
      </para>

      <para context="gui">
	Mostra il coefficiente di correlazione di rango di Spearman 
        per una coppia di variabili.  Le variabili non devono essere
        state ordinate manualmente in precedenza, se ne occupa la
        funzione.</para>

      <para>
	L'ordinamento automatico è dal massimo al minimo (ossia il
        valore massimo nei dati assume il rango 1). Se occorre invertire
        l'ordinamento, creare una variabile che è il negativo della
        variabile originale, ad esempio:
      </para>

      <code>
	genr altx = -x
	spearman altx y
      </code>
    </description>

    <gui-access>
      <menu-path>/Modello/Stima robusta/SPEARMAN - Correlazione di rango</menu-path>
    </gui-access>

  </command>

  <command name="sprintf" section="Printing" 
    label="Stampa su una stringa" context="cli">

    <usage>
      <arguments>
	<argument>var-stringa</argument>
        <argument>formato</argument>
	<argpunct>, </argpunct>
        <argument>argomenti</argument>
      </arguments>
    </usage>

    <description>
      <para>
	Questo comando funziona esattamente come il comando <cmdref
	targ="printf"/>, stampando gli argomenti nel modo controllato
	dalla stringa di formato, tranne per il fatto che il risultato
	è scritto nella stringa specificata, <repl>var-stringa</repl>.
      </para>
      <para>
	Per stampare la variabile stringa, basta usare il suo nome preceduto da
	<lit>@</lit>, come in questo esempio:
      </para>
      <code>
	sprintf variabile "%g", x
	print "variabile ha il valore @variabile"
      </code>
    </description>

  </command>

  <command name="square" section="Transformations" label="Crea quadrati delle
    variabili" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
        <option>
	  <flag>--cross</flag>
	  <effect>genera anche i prodotti incrociati, oltre ai quadrati</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Genera nuove variabili che sono i quadrati delle variabili nella
	<repl>lista-variabili</repl> (con anche i prodotti incrociati,
        se si usa l'opzione <opt>cross</opt>). Ad esempio, <cmd>square
          x y</cmd> genera <lit>sq_x</lit> = <lit>x</lit> al quadrato,
          <lit>sq_y</lit> = <lit>y</lit> al quadrato e (opzionalmente)
          <lit>x_y</lit> = <lit>x</lit> per <lit>y</lit>.
	Se una particolare variabile è una dummy, non ne viene fatto il
        quadrato, visto che si otterrebbe la stessa variabile.
      </para>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Quadrati delle variabili selezionate</menu-path>
    </gui-access>

  </command>

  <command name="store" section="Dataset"
    label="Salvataggio dei dati">

    <usage>
      <arguments>
        <argument>file-dati</argument>
        <argument optional="true">lista-variabili</argument>
      </arguments>
      <options>
        <option>
	  <flag>--csv</flag>
	  <effect>usa il formato CSV</effect>
        </option>
        <option>
	  <flag>--omit-obs</flag>
	  <effect>si veda oltre, a proposito del formato CSV</effect>
        </option>
        <option>
	  <flag>--gnu-octave</flag>
	  <effect>usa il formato GNU Octave</effect>
        </option>
        <option>
	  <flag>--gnu-R</flag>
	  <effect>usa il formato GNU R</effect>
        </option>
         <option>
	  <flag>--gzipped</flag>
	  <effect>comprime con gzip</effect>
        </option>
        <option>
	  <flag>--jmulti</flag>
	  <effect>usa il formato ASCII di JMulti</effect>
        </option>
        <option>
	  <flag>--dat</flag>
	  <effect>usa il formato ASCII di PcGive</effect>
        </option>
        <option>
         <flag>--database</flag>
         <effect>usa il formato database di gretl</effect>
        </option>
        <option>
         <flag>--overwrite</flag>
         <effect>cfr oltre, a proposito del formato dei database</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Save data to <repl>filename</repl>. By default all currently
	defined series are saved but the optional <repl>varlist</repl>
	argument can be used to select a subset of series. If the
	dataset is sub-sampled, only the observations in the current
	sample range are saved.
      </para>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo. 
      </para>
      <para>
	The format in which the data are written may be controlled in
	the first instance by the extension or suffix of
	<repl>filename</repl>, as follows:
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>.gdt</lit>, or no extension: gretl's native XML
	    data format. (If no extension is provided,
	    <quote><lit>.gdt</lit></quote> is added automatically.)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.gtdb</lit>: gretl's native binary data format.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.csv</lit>: comma-separated values (CSV).
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.txt</lit> or <lit>.asc</lit>: space-separated
	    values.
	  </para>
	</li>	
	<li>
	  <para>
	    <lit>.R</lit>: GNU R format.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.m</lit>: GNU Octave format.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.dta</lit>: Stata dta format (version 113).
	  </para>
	</li>	
      </ilist>
      <para>
	The format-related option flags shown above can be used to
	force the issue of the save format independently of the
	filename (or to get gretl to write in the formats of PcGive or
	JMulTi). However, if <repl>filename</repl> has extension
	<lit>.gdt</lit> or <lit>.gdtb</lit> this necessarily implies
	use of native format and the addition of a conflicting
	option flag will generate an error.
      </para>
      <para>
	When data are saved in native format (only), the
	<opt>gzipped</opt> option may be used for data compression,
	which can be useful for large datasets. The optional parameter
	for this flag controls the level of compression (from 0 to 9):
	higher levels produce a smaller file, but compression takes
	longer. The default level is 1; a level of 0 means that no
	compression is applied.
      </para>
      
      <para>
	L'opzione <lit>--omit-obs</lit> è applicabile solo quando si salvano
        dati in formato CSV. In modalità predefinita, se i dati sono serie
        storiche o panel, o se il dataset include marcatori per osservazioni
        specifiche, il file CSV comprende una prima colonna che identifica le
        osservazioni (ad esempio per data). Se si usa <lit>--omit-obs</lit>,
        questa colonna verrà omessa e verranno salvati solo i dati effettivi.
      </para>

      <para>
	Si noti che le variabili scalari non saranno salvate
        automaticamente: per salvarle occorre includerle esplicitamente
        nella <repl>lista-variabili</repl>.
      </para>  

      <para>
        L'opzione di salvataggio in formato database di gretl è indicata se
        occorre costruire dei grandi dataset di serie, magari con frequenze
        diverse e diversi intervalli di osservazioni. Al momento questa opzione
        è disponibile solo per dati annuali, trimestrali o mensili. Salvando su
        un file che esiste già, il comportamento predefinito è quello di
        accodare le nuove serie al contenuto del database preesistente. In
        questo contesto, se una o più delle variabili da salvare hanno lo stesso
        nome di una delle variabili già presenti nel database si otterrà un
        messaggio di errore. L'opzione <opt>overwrite</opt> permette invece di
        sovrascrivere eventuali variabili del dataset che hanno lo stesso nome
        delle nuove variabili, in modo che queste ultime rimpiazzino le
        variabili preesistenti.
      </para>
      <para>
	The <opt>comment</opt> option is available when saving data
	as a database or in CSV format. The required parameter is a
	double-quoted one-line string, attached to the option flag
	with an equals sign. The string is inserted as a comment into
	the database index file or at the top of the CSV output.
      </para>
      <para>
	The <lit>store</lit> command behaves in a special manner in
	the context of a <quote>progressive loop</quote>.  See
	<guideref targ="chap:looping"/> for details.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Salva dati; /File/Esporta dati</menu-path>
    </gui-access>

  </command>

  <command name="summary" section="Statistics" 
	   label="Statistiche descrittive" context="cli">

    <usage>
      <arguments>
	<altform><lit>summary [</lit> <repl>lista</repl> ]</altform>
	<altform><lit>summary --matrix=</lit><repl>nomematrice</repl></altform>
      </arguments>
      <options>
        <option>
	  <flag>--simple</flag>
	  <effect>solo statistiche di base</effect>
        </option>
        <option>
	  <flag>--weight</flag>
	  <optparm>wvar</optparm>
	  <effect>variabile peso</effect>
        </option>
        <option>
	  <flag>--by</flag>
	  <optparm>byvar</optparm>
	  <effect>vedi sotto</effect>
        </option>
      </options>

    </usage>

    <description>
      <para>
	Nella prima forma, mostra le statistiche descrittive per le
	variabili nella <repl>lista-variabili</repl>, o per tutte le
	variabili nel dataset, se non si indica una
	<repl>lista-variabili</repl>.  L'output comprende media,
	scarto quadratico medio, coefficiente di variazione (= scarto
	quadratico medio / media), mediana, minimo, massimo,
	coefficiente di asimmetria, curtosi in eccesso. Dando
	l'opzione <opt>simple</opt>, si avranno soltanto media,
	minimo, massimo e scarto quadratico medio.
      </para>
      <para>
	L'opzione <opt>by</opt> (dove il parametro
	<repl>byvar</repl> dev'essere il nome di una variabile
	discreta), provoca la stampa delle statistiche per
	sottocampioni definiti dai diversi valori di
	<repl>byvar</repl>.  Ad esempio, se <repl>byvar</repl> è una
	variabile binaria (dummy), verranno riportate separatamente le
	statistiche relative ai sottocampioni definitia dai due casi
	<lit>byvar = 0</lit> e <lit>byvar = 1</lit>. Nota: al momento,
	questa opzione è incompatibile con l'altra opzione
	<opt>weight</opt>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Statistiche descrittive</menu-path>
      <other-access>Menù pop-up nella finestra principale</other-access>
    </gui-access>

  </command>

  <command name="system" section="Estimation" label="Sistemi di equazioni">

    <usage>
      <altforms>
	<altform><lit>system method=</lit><repl>stimatore</repl></altform>
	<altform><repl>nome-sistema</repl><lit> &lt;- system</lit></altform>
      </altforms>
      <examples>
	<example>"Klein Model 1" &lt;- system</example>
        <example>system method=sur</example>
	<example>system method=3sls</example>
	<demos>
	  <demo>klein.inp</demo>
	  <demo>kmenta.inp</demo>
	  <demo>greene14_2.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>

      <para context="gui">In questa finestra, è possibile stimare sistemi di
        equazioni e scegliere uno stimatore per il sistema. È possibile indicare
        i seguenti quattro tipi di comandi:
      </para>

      <para context="cli">
	Inizia un sistema di equazioni. Esistono due versioni del comando,
        a seconda che si voglia salvare il sistema per poterlo stimare in
        più modi diversi, oppure stimare il sistema una volta sola.
      </para>

      <para context="cli">
	Per salvare il sistema occorre dargli un nome, come nel primo esempio
        proposto (se il nome contiene spazi, occorre racchiuderlo tra virgolette).
        In questo caso, è possibile stimare il sistema con il comando
	<cmdref targ="estimate"/>. Una volta che il sistema è stato salvato, è
        possibile imporre dei vincoli su di esso (compresi vincoli incrociati
        tra equazioni) usando il comando <cmdref targ="restrict"/>.
      </para>

      <para context="cli">
	In alternativa, è possibile indicare uno stimatore per il sistema
	usando <lit>method=</lit> seguito da una stringa che identifica uno
        degli stimatori supportati: <cmd>ols</cmd> (ordinary least squares -
        minimi quadrati ordinari), <cmd>tsls</cmd> (two-stage least squares -
        minimi quadrati a due stadi), <cmd>sur</cmd> (seemingly unrelated
        regressions - regressioni apparentemente non collegate), <cmd>3sls</cmd>
        (three-stage least squares - minimi quadrati a tre stadi),
        <cmd>fiml</cmd> (full information maximum likelihood - massima
        verosimiglianza con informazione completa) o <cmd>liml</cmd> (limited
        information maximum likelihood - massima verosimiglianza con
        informazione limitata). In questo caso, il sistema viene stimato appena
        completata la sua definizione.
      </para>

      <para context="cli">Un sistema di equazioni termina con la riga
	<cmd>end system</cmd>.  All'interno del sistema possono essere
        definiti i quattro tipi di istruzioni seguenti.</para>

      <ilist>
	<li><para><cmdref targ="equation"/>: specifica un'equazione del sistema.
	    Occorre indicarne almeno due.</para>
	</li>
	<li><para><cmd>instr</cmd>: per i sistemi da stimare con i minimi
            quadrati a tre stadi, indica la lista degli strumenti (indicati
            dal nome o dal numero della variabile). In alternativa, è possibile
	    fornire questa informazione nella riga <cmd>equation</cmd> usando la
            stessa sintassi accettata dal comando <cmdref targ="tsls"/>.</para>
	</li>
	<li><para><cmd>endog</cmd>: per i sistemi di equazioni
	simultanee, indica la lista delle variabili endogene. È
	indicato principalmente per la stima FIML, ma può essere usato
	anche nella stima minimi quadrati a tre stadi al posto
	dell'istruzione <cmd>instr</cmd>: in questo modo tutte le
	variabili non identificate come endogene verranno usate come
	strumenti.</para>
	</li>
	<li><para><cmd>identity</cmd>: per la stima FIML, un'identità
	che collega due o più variabili del sistema. Questo tipo di
	istruzione è ignorata se viene usato uno stimatore diverso da
	FIML.
	  </para>
	</li>
      </ilist>
        
      <para context="cli">
	Dopo la stima eseguita con i comandi <cmd>system</cmd> o
	<cmd>estimate</cmd> è possibile recuperare informazioni aggiuntive dalle
        seguenti variabili accessorie:
      </para>

      <ilist context="cli">
	<li>
          <para><fncref targ="$uhat"/>: la matrice dei residui, una colonna per
            equazione.
	  </para>
	</li>
	<li>
          <para><fncref targ="$yhat"/>: la matrice dei valori stimati, una colonna
            per equazione.
	  </para>
	</li>
	<li>
          <para><fncref targ="$coeff"/>: il vettore colonna dei coefficienti
          (tutti i coefficienti della prima equazione, seguiti da
          quelli della seconda equazione, e così via).
	  </para>
	</li>
	<li>
          <para><fncref targ="$vcv"/>: la matrice di covarianza dei coefficienti.
            Se il vettore <fncref targ="$coeff"/> ha <math>k</math> elementi,
            questa matrice ha dimensione <math>k</math> per <math>k</math>.
	  </para>
	</li>
	<li>
          <para><fncref targ="$sigma"/>: la matrice di covarianza dei residui
          incrociata tra equazioni.
	  </para>
	</li>
	<li><para><fncref targ="$sysGamma"/>, <fncref targ="$sysA"/> e
	<fncref targ="$sysB"/>: matrici dei coefficienti in forma
	strutturale (si veda oltre).
	  </para>
	</li>
      </ilist>

      <para context="cli">
        Se si vuole salvare i residui o i valori stimati per una specifica
        equazione come serie di dati, basta selezionare la colonna dalla matrice
	<fncref targ="$uhat"/> o <fncref targ="$yhat"/> e assegnarla a una serie, come in
      </para>
      <code context="cli">
	series uh1 = $uhat[,1]
      </code>

      <para context="cli">
	Le matrici in forma strutturale corrispondono alla seguente
        rappresentazione di un modello ad equazioni simultanee:
	<equation status="display"
	  tex="\[\Gamma y_t=Ay_{t-1}+Bx_t+\epsilon_t\]"
	  ascii="Gamma y(t) = A y(t-1) + B x(t) + e(t)"
	  graphic="structural"/> Se ci sono <math>n</math> variabili endogene e
          <math>k</math> variabili esogene,
	<equation status="inline"
	  tex="$\Gamma$"
	  ascii="Gamma"
	  graphic="Gamma"/> è una matrice <by r="n" c="n"/> e <math>B</math> è
	<by r="n" c="k"/>. Se il sistema non contiene ritardi delle variabili
        endogene, la matrice <math>A</math> non è presente. Se il massimo
        ritardo di un regressore endogeno è <math>p</math>, la matrice
	<math>A</math> è <by r="n" c="np"/>.
       </para>
      
    </description>
    
    <gui-access>
      <menu-path>/Modello/Equazioni simultanee</menu-path>
    </gui-access>

  </command>

  <command name="tabprint" section="Printing" label="Stampa modelli in forma
    tabulare" context="cli">

    <usage>
      <options>
        <option>
	  <flag>--format="f1|f2|f3|f4"</flag>
	  <effect>Specifica un formato personalizzato</effect>
        </option>
        <option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>invia l'output al file specificato</effect>
        </option>	
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello.  Stampa il modello
	stimato sotto forma di tabella, in formato &latex; o in
	formato RTF o CSV, se viene usata l'opzione corrispondente.
	Se viene specificato un nome di file dopo l'opzione
	<opt>output</opt>, l'output viene scritto nel file, altrimenti
	viene scritto in un file col nome
	<filename>model_N.tex</filename> (o
	<filename>model_N.rtf</filename>), dove <lit>N</lit> è il
	numero dei modelli stimati finora nella sessione in corso.
      </para>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo. 
      </para>
      <para>
	Selezionando il formato CSV, i valori sono separati da
	virgole, a meno che il delimitatore decimale non sia esso
	stesso la virgola, nel qual caso viene usato il punto e
	virgola. Si noti che l'output in CSV potrebbe essere meno
	completo degli altri formati.
      </para>
      <para>
        Le opzioni illustrate di seguito sono disponibili solo per il
        formato &latex;.
      </para>
      <para>
	Usando l'opzione <opt>complete</opt>, il file &latex; è un
	documento completo, pronto per essere processato; altrimenti
	il file va incluso in un documento.
      </para>
      <para>
	Se si intende modificare lo stile del formato tabulare, è
	possibile specificare un formato personalizzato usando
	l'opzione <opt>format</opt>, seguita da una stringa di
	formato. La stringa di formato va inclusa tra virgolette
	doppie e deve essere unita all'opzione con un segno di
	uguale. La composizione della stringa di formato è la
	seguente: ci sono quattro campi, che rappresentano il
	coefficiente, l'errore standard, il rapporto <math>t</math> e
	il p-value. Questi campi vanno separati usando barre verticali
	e possono contenere una specificazione di formato per valori
	numerici nello stile della funzione <lit>printf</lit>, oppure
	possono essere lasciati in bianco, in modo da sopprimere la
	visualizzazione del campo nella rispettiva colonna dela
	tabella (con l'unico vincolo che non è possibile lasciare in
	bianco tutti i campi).  Ecco alcuni esempi:
      </para>
      <code>
	--format="%.4f|%.4f|%.4f|%.4f"
	--format="%.4f|%.4f|%.3f|"
	--format="%.5f|%.4f||%.4f"
	--format="%.8g|%.8g||%.4f"
      </code>
      <para>
	La prima specificazione stampa i valori di tutte le colonne usando 4
        cifre decimali. La seconda sopprime il p-value e mostra il rapporto
	<math>t</math> con 3 cifre decimali. La terza omette il rapporto
	<math>t</math>, mentre l'ultima omette il rapporto
	<math>t</math> e mostra sia il coefficiente che l'errore standard
        con 8 cifre significative.
      </para>
      <para>
	Una volta che si imposta un formato in questo modo, esso viene ricordato
        e usato per tutta la sessione di lavoro. Per tornare ad usare il formato
        predefinito, basta usare la parola chiave <lit>--format=default</lit>.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /LaTeX</menu-path>
    </gui-access>

  </command>

  <command name="textplot" section="Graphs" label="Grafici ASCII" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
        <option>
	  <flag>--time-series</flag>
	  <effect>disegna per osservazione</effect>
        </option>
        <option>
	  <flag>--one-scale</flag>
	  <effect>forza l'uso di un'unica scala</effect>
        </option>
        <option>
	  <flag>--tall</flag>
	  <effect>usa 40 linee</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Gafica ASCII nuda e cruda. Senza l'opzione
	<opt>time-series</opt>, <repl>varlist</repl> deve contenere
	almeno due serie, l'ultima delle quali va sull'asse delle
	ascisse, e verrà prodotto un diagramma a dispersione. In
	questo caso, si può usare l'opzione <opt>tall</opt> per
	produrre un grafico in cui l'asse <math>y</math> è
	rappresentato da 40 righe di caratteri (il default è 20
	righe).
      </para>
      <para>
	Con l'opzione <opt>time-series</opt>, viene prodotto un
	grafico per osservazione.  In questo caso, l'opzione
	<opt>one-scale</opt> forza l'uso di una scala singola;
	altrimenti, se <repl>varlist</repl> contiene più di una serie
	i dati potrebbero essere riscalati. Ogni riga rappresenta
	un'osservazione, con i dati disegnati orizzontalmente.
      </para>
      <para>
	Vedi anche <cmdref targ="gnuplot"/>.
      </para>
    </description>

  </command>

  <command name="tobit" section="Estimation" label="Stima Tobit">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>Stima un modello Tobit. Il modello può essere appropriato
      quando la variabile dipendente è <quote>censurata</quote>. Ad
      esempio, vengono osservati valori positivi o nulli della spesa dei
      consumatori per beni durevoli, ma non valori negativi; tuttavia le
      decisioni di spesa possono essere pensate come derivanti da una
      propensione al consumo, sottostante e non osservata, che può anche
      essere negativa in alcuni casi. Per i dettagli si veda il capitolo
      20 di <book>Econometric Analysis</book> di Greene.</para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli non lineari/Tobit</menu-path>
    </gui-access>

  </command>

  <command name="transpos" section="Dataset" label="Trasposizione dei dati"
  context="gui">

    <description>
      <para>
	Traspone il dataset attuale, ossia, ogni osservazione (riga) del
        dataset attuale verrà trattata come una variabile (colonna) e
        ogni variabile come un'osservazione. Questo comando è utile se
        sono stati importati da una fonte esterna dati in cui le righe
        rappresentano variabili e le colonne osservazioni.
      </para>
      <para>
	Si veda anche <cmdref targ="dataset"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Dati/Trasponi dati</menu-path>
    </gui-access>

  </command>

  <command name="tsls" section="Estimation"
    label="Stima minimi quadrati a due stadi">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
	<argument separated="true">strumenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
 	<option>
 	  <flag>--liml</flag>
 	  <effect>usa massima verosimiglianza a informazione limitata</effect>
         </option>
 	<option>
 	  <flag>--gmm</flag>
 	  <effect>usa il metodo generalizzato dei momenti</effect>
         </option>
      </options>      
      <examples>
        <example>tsls y1 0 y2 y3 x1 x2 ; 0 x1 x2 x3 x4 x5 x6</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
        Calcola le stime con variabili strumentali, per impostazione predefinita
        usando i minimi quadrati a due stadi (TSLS), ma è possibile scegliere
        altre opzioni. Occorre specificare la <repl>variabile-dipendente</repl>,
        la lista di <repl>variabili-indipendenti</repl> (che si intende includere
        alcuni regressori endogeni), e infine gli <repl>strumenti</repl>, la lista
        completa delle variabili esogene e predeterminate. Se la lista degli
        <repl>strumenti</repl> non è lunga almeno quanto quella delle
        <repl>variabili-indipendenti</repl>, il modello non è
        identificato.
      </para>

      <para context="cli">
	Nell'esempio precedente, le <lit>y</lit> sono le variabili
        endogene e le <lit>x</lit> sono le variabili esogene e
        predeterminate. Si noti che eventuali regressori esogeni devono essere
        inclusi in entrambe le liste.
      </para>

      <para context="gui">
	Questo comando richiede la scelta di due liste di variabili; le
        variabili indipendenti che appaiono nel modello e un elenco di
        strumenti. Questi ultimi comprendono le variabili esogene e/o
        altre variabili predeterminate che possono essere usate per
        derivare valori stimati dei regressori endogeni. Si noti che eventuali
        regressori esogeni devono essere inclusi in entrambe le liste.
      </para>
      
      <para>
	L'output delle stime TSLS comprende il test di Hausman e, se
	il modello è sovra-identificato, il test di Sargan per la
	sovra-identificazione. Nel test di Hausman, l'ipotesi nulla è
	che le stime OLS siano consistenti, o in altre parole che non
	sia richiesta la stima per mezzo di variabili strumentali. Un
	modello di questo tipo è sovra-identificato se ci sono più
	strumenti di quelli strettamente necessari. Il test di Sargan
	è basato su una regressione ausiliaria dei residui del modello
	minimi quadrati a due stadi sull'intera lista degli
	strumenti. L'ipotesi nulla è che tutti gli strumenti siano
	validi, cosa di cui si dovrebbe dubitare se la regressione
	ausiliaria ha un significativo potere esplicativo.  Davidson e
	MacKinnon (2004, capitolo 8) forniscono una buona spiegazione
	di entrambi i test.
      </para>

      <para>
	Il valore R-quadro mostrato i modelli stimati con i minimi quadrati a
        due stadi è il quadrato della correlazione tra la variabile dipendente
        e i valori stimati.
      </para>

      <para context="cli">
	In alternativa al metodo TSLS, il modello può essere stimato usando la
        massima verosimiglianza a informazione limitata (opzione <opt>liml</opt>)
        o il metodo generalizzato dei momenti (opzione <opt>gmm</opt>). Si noti che
        se il modello è esattamente identificato, questi metodi dovrebbero
        produrre gli stessi risultati del metodo TSLS, ma se il modello è
        sovraidentificato, i risultati saranno in genere diversi.
      </para>

      <para context="cli">
	Se si usa la stima GMM, è possibile usare le seguenti opzioni aggiuntive:
      </para>

      <ilist>
	<li>
	  <para>
	    <lit>--two-step</lit>: esegue la stima GMM in due passi, invece che
            in un passo solo.
	  </para>
	</li>
	<li>
	  <para>
	    <opt>iterate</opt>: itera il GMM fino alla convergenza.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>--weights=</lit><repl>Pesi</repl>: specifica una matrice
            quadrata di pesi da usare nel calcolo della funzione criterio del
            GMM. La dimensione di questa matrice deve essere pari al numero di
            strumenti. L'impostazione predefinita consiste nell'usare una
            matrice identità di dimensione opportuna.
 	  </para>
 	</li>	
       </ilist>

    </description>

    <gui-access>
      <menu-path>/Modello/TSLS - Minimi quadrati a due stadi</menu-path>
    </gui-access>

  </command>

  <command name="var" section="Estimation"
    label="Autoregressione vettoriale">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>lista-variabili</argument>
	<argument separated="true" optional="true">lista-esogene</argument>
      </arguments>
      <options>
        <option>
	  <flag>--nc</flag>
	  <effect>non include una costante</effect>
        </option>
	<option>
	  <flag>--trend</flag>
	  <effect>include un trend</effect>
	</option>
        <option>
	  <flag>--seasonals</flag>
	  <effect>include variabili dummy stagionali</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
        <option>
	  <flag>--impulse-responses</flag>
	  <effect>mostra impulso-risposta</effect>
        </option>
        <option>
	  <flag>--variance-decomp</flag>
	  <effect>mostra decomposizioni della varianza della previsione</effect>
        </option>
        <option>
	  <flag>--lagselect</flag>
	  <effect>mostra i criteri di informazione per la selezione dei ritardi</effect>
        </option>
      </options>
      <examples>
        <example>var 4 x1 x2 x3 ; time mydum</example>
	<example>var 4 x1 x2 x3 --seasonals</example>
	<example>var 12 x1 x2 x3 --lagselect</example>
      </examples>
    </usage>

    <description>

      <para context="gui">
	Questo comando richiede la specificazione dei seguenti elementi:</para>

      <ilist context="gui">
	<li><para context="gui">- L'ordine di ritardi, ossia il numero
        di ritardi di ogni variabile presente nel sistema;</para>
	</li>

        <li><para context="gui">- Eventuali termini esogeni
        (ma si noti che una costante viene inclusa automaticamente, a meno che
        non si richieda altrimenti; inoltre è possibile includere variabili
        dummy stagionali con l'apposita casella); e
        </para>
	</li>

	<li><para context="gui">- Una lista di variabili esogene,
        i cui ritardi saranno inclusi a destra delle equazioni (nota:
        non includere variabili ritardate in questa lista, verranno
        aggiunte automaticamente).</para>
	</li>
      </ilist>

      <para context="gui">Viene calcolata una regressione separata per
      ogni variabile del sistema; i risultati comprendono i test F per i
      vincoli di uguaglianza a zero su tutti i ritardi della variabili e
      un test F per il ritardo massimo, oltre (opzionalmente) alla
      scomposizione della varianza della previsione e alle funzioni di
      impulso-risposta.</para>  

      <para context="cli">
	Imposta e stima (usando OLS) un'autoregressione vettoriale
	(VAR).  Il primo argomento specifica l'ordine di ritardo (o il
	massimo ordine di ritardi se è stata usata l'opzione
	<opt>lagselect</opt>). L'ordine può essere indicato
	numericamente o con il nome di una variabile scalare
	preesistente.  Quindi segue l'impostazione della prima
	equazione. Non occorre includere i ritardi tra gli elementi
	della <repl>lista-variabili</repl>: verranno aggiunti
	automaticamente. Il punto e virgola separa le variabili
	stocastiche, per cui verrà incluso un numero di ritardi pari a
	<repl>ordine</repl>, dai termini deterministici o esogeni
	presenti nella <repl>lista-esogene</repl>. Si noti che viene
	inclusa automaticamente una costante, a meno che non si usi
	l'opzione <opt>nc</opt>; inoltre è possibile aggiungere un
	trend con l'opzione <opt>trend</opt> e variabili dummy
	stagionali con l'opzione <opt>seasonals</opt>.
      </para>

      <para context="cli">
	Viene calcolata una regressione separata per ognuna delle
        variabili nella <repl>lista-variabili</repl>. Il risultato di
        ogni equazione include i test <math>F</math> per i vincoli
        di uguaglianza a zero su tutti i ritardi delle variabili, un
        test <math>F</math> per la significatività del ritardo massimo e,
        se è stata usata l'opzione <lit>--impulse-responses</lit>, la
        scomposizione della varianza della previsione e le funzioni di
        impulso-risposta.</para>

      <para>
	Le decomposizioni della varianza della previsione e le funzioni di
        impulso-risposta sono basate sulla decomposizione di Cholesky
        della matrice di covarianza contemporanea, e in questo contesto
        l'ordine in cui vengono date le variabili stocastiche conta.
	La prima variabile nella lista viene considerata come la
	<quote>più esogena</quote> all'interno del periodo. L'orizzonte
        per le decomposizioni della varianza e le funzioni di impulso-risposta
        può essere impostato usando il comando <cmdref targ="set"/>.
      </para> 
      <para context="cli">
        Se si usa l'opzione <opt>lagselect</opt>, il primo parametro
        del comando <lit>var</lit> viene interpretato come il massimo
        ordine di ritardo.  In questo caso, il comando non produce il
        solito risultato della stima del VAR, ma una tabella che
        mostra i valori dei criteri di informazione di Akaike (AIC),
        Schwartz (BIC) e Hannan&ndash;Quinn (HQC) calcolati per VAR
        dall'ordine 1 fino all'ordine massimo indicato, in modo da
        aiutare nella scelta dell'ordine di ritardo ottimale.
       </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/VAR - Autoregressione vettoriale</menu-path>
    </gui-access>

  </command>
  
  <command name="VAR-lagselect" section="Tests" context="gui"
    label="Scelta dell'ordine di ritardi in un VAR">

    <description>
      <para>
        In questa finestra di dialogo è possibile testare la stima di un VAR
        per diversi ordini di ritardi; oltre a indicare la specificazione del
        VAR è possibile selezionare il massimo ordine di ritardi da testare.
      </para>

      <para>
        Il risultato consiste in una tabella che mostra i valori dei criteri
        di informazione di Akaike (AIC), Schwartz (BIC) e Hannan&ndash;Quinn (HQC)
        calcolati per VAR dall'ordine 1 fino all'ordine massimo indicato.
      </para>
    </description>

  </command>

  <command name="VAR-omit" section="Tests" context="gui"
    label="Test per variabili esogene in un VAR">

    <description>
      <para>
        In questa finestra di dialogo è possibile testare l'omissione da un VAR
        di un gruppo di variabili esogene.
      </para>
      <para>
        Viene calcolato un test del rapporto di verosimiglianza sotto l'ipotesi
        nulla che i coefficienti delle variabili indicate valgano zero in
        tutte le equazioni del VAR. Il test si basa sulla differenza tra il
        log-determinante della matrice di varianza per il modello non vincolato
        e per il modello con il vincolo che i coefficienti delle variabili
        indicate valgano zero.
      </para>
    </description>

  </command>

  <command name="varlist" section="Dataset" label="Elenca variabili" context="cli">

    <description>
      <para>
	Mostra un elenco delle variabili disponibili.
	<cmd>list</cmd> e <cmd>ls</cmd> sono sinonimi. 
      </para>
    </description>

  </command>

  <command name="vartest" section="Tests" label="Differenza delle varianze">

    <usage>
      <arguments>
        <argument>var1</argument>
        <argument>var2</argument>
      </arguments>
    </usage>

    <description>
      <para context="cli">
	Calcola la statistica <math>F</math> per l'ipotesi nulla
        che le varianze della popolazione per le variabili
	<repl>var1</repl> e <repl>var2</repl> siano uguali e mostra il
        p-value.
      </para>
      <para context="gui">
        Calcola la statistica <math>F</math> per l'ipotesi nulla
        che le varianze della popolazione per le variabili selezionate
        siano uguali e mostra il p-value.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Modelli bivariati/Differenza delle varianze</menu-path>
    </gui-access>

  </command>

  <command name="vecm" section="Estimation"
    label="Modello vettoriale a correzione d'errore">

    <usage>
      <arguments>
        <argument>ordine</argument>
	<argument>rango</argument>
        <argument>lista-y</argument>
	<argblock optional="true" separated="true">
	  <argument>lista-x</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>lista-rx</argument>
	</argblock>
      </arguments>
      <options>
        <option>
	  <flag>--nc</flag>
	  <effect>senza costante</effect>
        </option>
        <option>
	  <flag>--rc</flag>
	  <effect>costante vincolata</effect>
        </option>
        <option>
	  <flag>--crt</flag>
	  <effect>costante e trend vincolato</effect>
        </option>
        <option>
	  <flag>--ct</flag>
	  <effect>costante e trend non vincolato</effect>
        </option>
        <option>
	  <flag>--seasonals</flag>
	  <effect>include dummy stagionali centrate</effect>
        </option>
        <option>
	  <flag>--impulse-responses</flag>
	  <effect>mostra impulso-risposta</effect>
        </option>
        <option>
	  <flag>--variance-decomp</flag>
	  <effect>mostra decomposizioni della varianza delle previsioni</effect>
        </option>
      </options>
      <examples>
        <example>vecm 4 1 Y1 Y2 Y3</example>
        <example>vecm 3 2 Y1 Y2 Y3 --rc</example>
	<example>vecm 3 2 Y1 Y2 Y3 ; X1 --rc</example>
	<demos>
	  <demo>denmark.inp</demo>
	  <demo>hamilton.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Un VECM è un tipo di autoregressione vettoriale, o VAR (si veda <cmdref
	  targ="var"/>), applicabile quando le variabili del modello sono
        individualmente integrate di ordine 1 (ossia, sono <quote>random walk</quote>
        con o senza deriva), ma esibiscono cointegrazione. Questo comando è
        strettamente connesso al test di Johansen per la cointegrazione (si veda
	<cmdref targ="coint2"/>).
      </para>
      <para context="cli">
        Il parametro <repl>ordine</repl> rappresenta l'ordine di ritardo del
        sistema VAR. Il numero di ritardi nel VECM (dove la variabile dipendente
        è data da una differenza prima) è pari a <repl>ordine</repl> meno uno.
      </para>
      <para context="gui">
        L'ordine di ritardo selezionato nella finestra di dialogo del VECM è
        quello del sistema VAR.  Per ottenere il numero di ritardi nel VECM
        (dove la variabile dipendente è data da una differenza prima) occorre
        sottrarre uno da questo numero.
      </para>
      <para context="cli">
        Il parametro <repl>rango</repl> rappresenta il rango di cointegrazione,
        o in altre parole il numero di vettori di cointegrazione. Questo deve
        essere maggiore di zero e minore o uguale (in genere minore) al numero
        di variabili endogene contenute nella <repl>lista-y</repl>.
      </para>
      <para context="gui">
	Il <quote>rango di cointegrazione</quote> rappresenta il numero di
        vettori di cointegrazione. Questo deve essere maggiore di zero e minore
        o uguale (in genere minore) al numero di variabili endogene selezionate.
      </para>
      <para context="cli">
        La <repl>lista-y</repl> rappresenta l'elenco delle variabili
        endogene, nei livelli. L'inclusione di trend deterministici nel modello
        è controllata dalle opzioni del comando. Se non si indica alcuna
        opzione, viene inclusa una <quote>costante non vincolata</quote>, che
        permette la presenza di un'intercetta diversa da zero nelle relazioni di
        cointegrazione e di un trend nei livelli delle variabili endogene. Nella
        letteratura originata dal lavoro di Johansen (si veda ad esempio il suo
        libro del 1995), si fa riferimento a questo come al <quote>caso
        3</quote>.  Le prime quattro opzioni mostrate sopra, che sono
        mutualmente esclusive, producono rispettivamente i casi 1, 2, 4 e 5. Il
        significato di questi casi e i criteri per scegliere tra di essi sono
        spiegati nella <guideref targ="chap:vecm"/>.
      </para>
      <para context="gui">
        Nel riquadro <quote>Variabili endogene</quote>, è possibile selezionare
        il vettore delle variabili endogene, in livelli. L'inclusione di trend
        deterministici nel modello è controllata dai pulsanti opzionali.  Se non
        si seleziona alcuna opzione, viene inclusa una <quote>costante non
        vincolata</quote>, che permette la presenza di un'intercetta diversa da
        zero nelle relazioni di cointegrazione e di un trend nei livelli delle
        variabili endogene. Nella letteratura originata dal lavoro di Johansen
        (si veda ad esempio il suo libro del 1995), si fa riferimento a questo
        come al <quote>caso 3</quote>.  Le altre quattro opzioni producono
        rispettivamente i casi 1, 2, 4 e 5. Il significato di questi casi e i
        criteri per scegliere tra di essi sono spiegati nella <guideref
        targ="chap:vecm"/>.
      </para>
      <para context="gui">
        Nel riquadro <quote>Variabili esogene</quote> è possibile aggiungere
        specifiche variabili esogene. Per impostazione predefinita, le variabili
        vengono aggiunte al modello in forma non vincolata (indicata da una
        lettera <lit>N</lit> vicino al nome della variabile). Se si vuole che
        una certa variabile esogena sia vincolata allo spazio di cointegrazione,
        basta fare clic col tasto destro e selezionare <quote>Vincolata</quote>
        dal menu pop-up. Il simbolo vicino alla variabile diventerà una V.
      </para>
      <para context="cli">
	Le liste opzionali <repl>lista-x</repl> e <repl>lista-rx</repl>
        permettono di specificare insiemi di variabili esogene che entrano nel
        modello in modo non vincolato (<repl>lista-x</repl>) o in modo vincolato
        allo spazio di cointegrazione (<repl>lista-rx</repl>). Queste liste
        vanno separate dalla <repl>lista-y</repl> (e tra di loro) da caratteri
        punto e virgola.
      </para>
      <para context="cli">
        L'opzione <opt>seasonals</opt>, che può accompagnare una qualsiasi
        delle altre opzioni, specifica l'inclusione di un gruppo di variabili
        dummy stagionali centrate. Questa opzione è disponibile solo per dati
        trimestrali o mensili.
      </para>
      <para context="gui">
	Se i dati sono trimestrali o mensili, è presente anche una casella che
        permette di includere un gruppo di variabili dummy stagionali centrate.
	In tutti i casi, la casella <quote>Mostra dettagli</quote> permette di
        vedere il risultato delle regressioni ausiliarie che sono il punto di
        partenza per la procedura di stima di massima verosimiglianza di
        Johansen.
      </para>
      <para context="cli">
        Il primo degli esempi mostrati sopra specifica un VECM con ordine di
        ritardo pari a 4 e un unico vettore di cointegrazione. Le variabili
        endogene sono <lit>Y1</lit>, <lit>Y2</lit> e <lit>Y3</lit>. Il secondo
        esempio usa le stesse variabili ma specifica un ritardo di ordine 3 e
        due vettori di cointegrazione, oltre a specificare una <quote>costante
        vincolata</quote>, che è appropriata se i vettori di cointegrazione
        possono avere un'intercetta diversa da zero, ma le variabili
        <lit>Y</lit> non hanno trend.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/VECM</menu-path>
    </gui-access>

  </command>

  <command name="vif" section="Tests" context="cli"
    label="Fattori di inflazione della varianza">

    <description>
      <para>
	Deve seguire la stima di un modello che includa almeno due variabili
	indipendenti. Calcola e mostra i fattori di inflazione della varianza
	(Variance Inflation Factors - VIF) per i regressori.  Il VIF
	per il regressore <math>j</math> è definito come
	<equation status="display" 
	  tex="\[\frac{1}{1-R_j^2}\]"
	  ascii="1/(1 - Rj^2)"
	  graphic="vif"/> dove <math>R</math><sub>j</sub> è il
	coefficiente di correlazione multipla tra il regressore
	<math>j</math> e gli altri regressori. Il fattore ha un valore
        minimo di 1.0 quando la variabile in questione è ortogonale alle altre
        variabili indipendenti.  Neter, Wasserman e Kutner (1990) suggeriscono
        di usare il VIF maggiore come test diagnostico per la collinearità; un
        valore superiore a 10 è in genere considerato indice di un grado di
        collinearità problematico.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/collinearità</menu-path>
    </gui-access>

  </command>

  <command name="wls" section="Estimation" label="Minimi quadrati ponderati">

    <usage>
      <arguments>
        <argument>variabile-pesi</argument>
        <argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
      </options> 
    </usage>

    <description>
      <para context="cli">
	Calcola stime con minimi quadrati ponderati (WLS - Weighted Least
        Squares), prendendo i pesi da <repl>variabile-pesi</repl>.
        In pratica, detta <repl>w</repl> la radice quadrata positiva della
        <lit>variabile-pesi</lit>, viene calcolata una regressione OLS di
        <repl>w</repl> <lit>*</lit> <repl>variabile-dipendente</repl> rispetto a
        <repl>w</repl> <lit>*</lit> <repl>variabili-indipendenti</repl>.
        L'<emphasis>R</emphasis>-quadro, comunque, è calcolato in un modo
        speciale, ossia come
        <equation status="display"
          tex="\[R^2 = 1 - \frac{\rm ESS}{\rm WTSS}\]"
          ascii="R^2 = 1 - ESS / WTSS"
          graphic="wlsr2"/> dove ESS è la somma dei quadrati degli errori (somma
        dei quadrati dei residui) dalla regressione ponderata, mentre WTSS
        denota la <quote>somma totale ponderata dei quadrati</quote>, che è pari 
        alla somma dei quadrati dei residui della regressione della variabile
        dipendente ponderata sulla sola costante ponderata.
      </para>
      <para>
        Se <repl>variabile-pesi</repl> è una variabile dummy, la stima WLS
        equivale a eliminare tutte le osservazioni per cui essa vale zero.
      </para>
      <para context="gui">
	Detta "variabile-pesi" la variabile scelta nel campo "Variabile
        pesi", viene stimata una regressione OLS in cui la variabile
        dipendente è il prodotto della variabile dipendente selezionata
        e della radice quadrata della variabile-pesi, e anche le variabili
        indipendenti sono moltiplicate per la radice quadrata della variabile-pesi.
        Le statistiche della regressione, come l'<emphasis>R</emphasis>-quadro
        sono basate sui dati ponderati. Se la variabile-pesi è una
        variabile dummy, ciò equivale a eliminare tutte le osservazioni
        per cui essa vale zero.</para>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/WLS - Minimi quadrati ponderati</menu-path>
    </gui-access>

  </command>

  <command name="workdir" section="Utilities" label="Directory di lavoro"
    context="gui">

    <description>
      <para>
       La <quote>directory di lavoro</quote> è quella usata da gretl in modo
       predefinito nelle operazioni di letura o scrittura di file di dati o
       comandi, usando i comandi Apri e Salva.
      </para>
      <para>
       Inoltre, la directory di lavoro è usata anche per:
      </para>
      <ilist>
       <li>
         <para>
           leggere i file attraverso i comandi testuali <lit>append</lit>,
           <lit>open</lit>, <lit>run</lit> e <lit>include</lit>;
         </para>
       </li>
       <li>
         <para>
           scrivere i file attraverso i comandi <lit>eqnprint</lit>,
           <lit>tabprint</lit>, <lit>gnuplot</lit>, <lit>outfile</lit>
           e <lit>store</lit>.
         </para>
       </li>
      </ilist>
      <para>
       Se si è abituati ad avviare gretl da un terminale testuale
       invece che da un menù o icona, può essere utile l'opzione che
       permette di usare la directory attuale (determinata dalla
       shell) al momento dell'avvio del programma.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Directory di lavoro</menu-path>
    </gui-access>

  </command>

  <command name="x12a" section="Utilities" context="gui"
    label="X-12-ARIMA">

    <description>
      <para>
	Qui ci sono duo opzioni procedurali, controllate dal set
	inferiore di bottoni radio.
      </para>
      <para>
	Selezionando <quote>Esegui X-12-ARIMA direttamente</quote>
	gretl scriverà un file di comandi per X-12-ARIMA e chiamerà il
	programmma x12aper eseguirli. In questo caso, è possibile
	produrre un grafico e/o salvare le serie di output nel dataset
	di gretl.
      </para>
      <para>
	Selezionando invece <quote>Scrivi file di comandi
	X-12-ARIMA</quote> gretl scriverà un file di comandi per
	X-12-ARIMA, come sopra, ma poi questo file verrà aperto in una
	finestra di editor, così da poter apportare modifiche e
	salvarlo col nome voluto. Sarà anche possibile mandarlo in
	esecuzione con x12a (cliccando il bottone <quote>Run</quote>
	sulla barra degli strumenti dell'editor) e visualizzarne
	l'output. In questo caso, tuttavia, non c'è possibilità di
	salvare i dati prodotti o di di produrre grafici.
      </para>
    </description>
  </command>

  <command name="xcorrgm" section="Statistics" label="Correlogramma incrociato">

    <usage>
      <arguments>
        <argument>var1</argument>
        <argument>var2</argument>
        <argument optional="true">maxlag</argument>
      </arguments>
      <examples>
        <example>xcorrgm x y 12</example>
      </examples>
    </usage>

    <description>
      <para>
	Mostra il correlogramma incrociato per le variabili
	<repl>var1</repl> e <repl>var2</repl>, che possono essere
	specificate per nome o per numero. I valori sono i
	coefficienti di correlazione campionari tra il valore presente
	di <repl>var1</repl> e i valori ritardati e anticipati di
	<repl>var2</repl>.
      </para>
      <para>
	Se si indica un valore <repl>maxlag</repl>, la lunghezza del
	correlogramma è limitata al numero di ritardi e anticipi
	indicati, altrimenti è determinata automaticamente in funzione
	della frequenza dei dati e del numero di osservazioni.
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Correlogramma</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione multipla)</other-access>
    </gui-access>

  </command>
 
  <command name="xtab" section="Statistics" label="Tabulazione incrociata">

    <usage>
      <arguments>
        <argument>lista-y</argument>
        <argument optional="true" separated="true">lista-x</argument>
      </arguments>
      <options>
        <option>
	  <flag>--row</flag>
	  <effect>mostra le percentuali per riga</effect>
        </option>
        <option>
	  <flag>--column</flag>
	  <effect>mostra le percentuali per colonna</effect>
        </option>
        <option>
	  <flag>--zeros</flag>
	  <effect>mostra i valori pari a zero</effect>
        </option>
      </options>
    </usage>

    <description context="cli">
      <para>
        Mostra la tabella di contingenza, o la
        tabulazione incrociata, tra ogni combinazione delle variabili della
        <repl>lista-y</repl>; se si indica anche una seconda lista,
        <repl>lista-x</repl>, ogni variabile della <repl>lista-y</repl> viene
        tabulata (per riga) rispetto ad ogni variabile della <repl>lista-x</repl>
        (per colonna). Le variabili in queste liste possono essere referenziate per
        nome o per numero, e devono essere state marcate come discrete.
      </para>
      <para>
	Per impostazione predefinita le celle indicano la frequenza assoluta.
        Le opzioni <opt>row</opt> e <opt>column</opt> (che sono mutualmente
        esclusive) sostituiscono la frequenza assoluta con le frequenze in
        percentuale relativamente a ciascuna riga o colonna. Le celle con valore
        di frequenza nullo sono lasciate vuote, a meno che non venga usata l'opzione
	<opt>zeros</opt>, che mostra esplicitamente i valori pari a zero;
        questa opzione può essere comoda se occorre importare la tabella in un
        altro programma, come un foglio di calcolo.
      </para>
      <para>
        Il test chi quadro di Pearson per l'indipendenza viene mostrato
        se la frequenza attesa nell'ipotesi di indipendenza è pari almeno a
        1.0e-7 per tutte le celle. Una regola approssimativa usata spesso nel
        giudicare la validità di questa statistica richiede che la frequenza
        attesa sia superiore a 5 per almeno l'80 per cento delle celle; se
        questa condizione non viene soddisfatta viene mostrato un messaggio di
        avvertimento.
      </para>
      <para>
	Se la tabella di contingenza è 2 x 2, viene calcolato il test esatto di
        Fisher per l'indipendenza. Si noti che questo test si basa sull'ipotesi
        che i totali per riga e colonna siano fissi; questo può essere
        appropriato o meno a seconda di come sono stati generati i dati.
	Il p-value sinistro va usato nel caso in cui l'ipotesi alternativa a
        quella di indipendenza sia quella dell'associazione negativa (ossia i
        valori tendono ad accumularsi nelle celle che non appartengono alla
        diagonale della tabella), mentre il p-value destro va usato nell'ipotesi
        alternativa di associazione positiva. Il p-value a due code di questo
        test è calcolato seguendo il metodo (b) descritto in Agresti
	(1992, capitolo 2.1): esso è la somma delle probabilità di tutte le
        possibili tabelle che hanno i totali per riga e per colonna pari a
        quelli della tabella data e che hanno una probabilità minore o uguale a
        quella della tabella data.
      </para>
    </description>

    <description context="gui">
      <para>
        Mostra la tabella di contingenza, o la tabulazione incrociata, tra ogni
        combinazione delle variabili selezionate. Si noti che tutte le variabili
        devono essere discrete.
      </para>
      <para>
	Per impostazione predefinita le celle indicano la frequenza assoluta, ma
        è possibile scegliere di avere le percentuali relative alle righe o alle
        colonne.
      </para>
      <para>
        Inoltre, le celle con un valore di frequenza nullo sono lasciate vuote,
        ma è possibile scegliere di avere i valori pari a zero esplicitamente.
      </para>
      <para>
        Il test chi quadro di Pearson per l'indipendenza viene mostrato
        se la frequenza attesa nell'ipotesi di indipendenza è pari almeno a
        1.0e-7 per tutte le celle. Una regola approssimativa usata spesso nel
        giudicare la validità di questa statistica richiede che la frequenza
        attesa sia superiore a 5 per almeno l'80 per cento delle celle; se
        questa condizione non viene soddisfatta viene mostrato un messaggio di
        avvertimento.
      </para>
      <para>
	Se la tabella di contingenza è 2 x 2, viene calcolato il test esatto di
        Fisher per l'indipendenza. Si noti che questo test si basa sull'ipotesi
        che i totali per riga e colonna siano fissi; questo può essere
        appropriato o meno a seconda di come sono stati generati i dati.
	Il p-value sinistro va usato nel caso in cui l'ipotesi alternativa a
        quella di indipendenza sia quella dell'associazione negativa (ossia i
        valori tendono ad accumularsi nelle celle che non appartengono alla
        diagonale della tabella), mentre il p-value destro va usato nell'ipotesi
        alternativa di associazione positiva. Il p-value a due code di questo
        test è calcolato seguendo il metodo (b) descritto in Agresti
	(1992, capitolo 2.1): esso è la somma delle probabilità di tutte le
        possibili tabelle che hanno i totali per riga e per colonna pari a
        quelli della tabella data e che hanno una probabilità minore o uguale a
        quella della tabella data.
      </para>
    </description>

  </command>

</commandref>

