\chapter{Forecasting}
\label{chap:forecast}

\section{Introduction}
\label{sec:fcast-intro}

In some econometric contexts forecasting is the prime objective: one
wants estimates of the future values of certain variables to reduce
the uncertainty attaching to current decision making.  In other
contexts where real-time forecasting is not the focus prediction
may nonetheless be an important moment in the analysis.  For example,
out-of-sample prediction can provide a useful check on the validity of
an econometric model.  In other cases we are interested in questions
of ``what if'': for example, how might macroeconomic outcomes have
differed over a certain period if a different policy had been pursued?
In the latter cases ``prediction'' need not be a matter of actually
projecting into the future but in any case it involves generating
fitted values from a given model.  The term ``postdiction'' might be
more accurate but it is not commonly used; we tend to talk of
prediction even when there is no true forecast in view.

This chapter offers an overview of the methods available within
gretl for forecasting or prediction (whether forward in time or
not) and explicates some of the finer points of the relevant commands.

\section{Saving and inspecting fitted values}
\label{sec:fcast-fitted}

In the simplest case, the ``predictions'' of interest are just the
(within sample) fitted values from an econometric model.  For the
single-equation linear model, $y_t = X_t \beta + u_t$, these are
$\hat{y}_t = X_t \hat{\beta}$.  

In command-line mode, the $\hat{y}$ series can be retrieved, after
estimating a model, using the accessor \verb|$yhat|, as in
%
\begin{code}
series yh = $yhat
\end{code}
% 
If the model in question takes the form of a system of equations,
\verb|$yhat| returns a matrix, each column of which contains the
fitted values for a particular dependent variable.  To extract
the fitted series for, e.g., the dependent variable in the second
equation, do
%
\begin{code}
matrix Yh = $yhat
series yh2 = Yh[,2]
\end{code}

Having obtained a series of fitted values, you can use the
\texttt{fcstats} function to produce a vector of statistics that
characterize the accuracy of the predictions (see
section~\ref{sec:fcast-stats} below).

The gretl GUI offers several ways of accessing and examining
within-sample predictions.  In the model display window the
\textsf{Save} menu contains an item for saving fitted values, the
\textsf{Graphs} menu allows plotting of fitted versus actual values,
and the \textsf{Analysis} menu offers a display of actual, fitted and
residual values.


\section{The \texttt{fcast} command}
\label{sec:fcast-fcast}

The \texttt{fcast} command (and its equivalent GUI invocation, see 
below) generates predictions based on the last
estimated model.  Several questions arise here: How to control the
range over which predictions are generated?  How to control the
forecasting method (where a choice is available)?  How to control the
printing and/or saving of the results?  Basic answers can be found in
the \GCR; we add some more details here.

\subsection{The forecast range}

The range defaults to the currently defined sample range.  If this
remains unchanged following estimation of the model in question, the
forecast will be ``within sample'' and (with some qualifications noted
below) it will essentially duplicate the information available via the
retrieval of fitted values (see section~\ref{sec:fcast-fitted} above).

A common situation is that a model is estimated over a given sample
and then forecasts are wanted for a subsequent out-of-sample range.  The
simplest way to accomplish this is via the \verb|--out-of-sample|
option to \texttt{fcast}.  For example, assuming we have a quarterly
time-series dataset containing observations from 1980:1 to 2008:4,
four of which are to be reserved for forecasting:
%
\begin{code}
# reserve the last 4 observations
smpl 1980:1 2007:4
ols y 0 xlist
fcast --out-of-sample
\end{code}
%
This will generate a forecast from 2008:1 to 2008:4.

There are two other ways of adjusting the forecast range, offering
finer control:
%
\begin{itemize}
\item Use the \texttt{smpl} command to adjust the sample range
  prior to invoking \texttt{fcast}.
\item Use the optional \textsl{startobs} and \textsl{endobs} arguments
  to \texttt{fcast} (which should come right after the command word).
  These values set the forecast range independently of the
  sample range.
\end{itemize}

What if one wants to generate a true forecast that goes beyond the
available data?  In that case one can use the \texttt{dataset} command
with the \texttt{addobs} parameter to add extra observations before 
forecasting.  For example:
%
\begin{code}
# use the entire dataset, which ends in 2008:4
ols y 0 xlist
dataset addobs 4
fcast 2009:1 2009:4
\end{code}
%
But this will work as stated only if the set of regressors in
\texttt{xlist} does not contain any stochastic regressors other than
lags of \texttt{y}.  The \texttt{dataset addobs} command attempts to detect
and extrapolate certain common deterministic variables (e.g., time
trend, periodic dummy variables).  In addition, lagged values of the
dependent variable can be supported via a dynamic forecast (see below
for discussion of the static/dynamic distinction).  But ``future''
values of any other included regressors must be supplied before such a
forecast is possible.  Note that specific values in a series can be
set directly by date, for example: \texttt{x1[2009:1] = 120.5}.  Or,
if the assumption of no change in the regressors is warranted, one can
do something like this:
%
\begin{code}
loop t=2009:1..2009:4
    loop foreach i xlist
        $i[t] = $i[2008:4]
    endloop
endloop
\end{code}

In single-equation OLS models a \verb|--recursive| forecast option is
also available, expanding the estimation sample one-by-one and 
re-calculating the forecasts again and again for the constantly updated
information set. In this case a number must be given of how many periods
ahead should be forecast for each of the estimation samples. Note that
only this $k$-steps-ahead forecast will be printed (or accessible in 
\dollar{fcast}), not the interim values from step 1 through $k-1$ (if 
$k>1$). If those interim values are also needed, then several 
\verb|fcast ... --recursive| rounds would have to be done with different
steps-ahead numbers.

\subsection{Static and dynamic forecasts}

The distinction between static and dynamic forecasts applies only to
dynamic models, i.e., those that feature one or more lags of the
dependent variable. The simplest case is the AR(1) model,
%
\begin{equation}
\label{eq:ar1}
y_t = \alpha_0 + \alpha_1 y_{t-1} + \epsilon_t
\end{equation}
%
In some cases the presence of a lagged dependent variable is implicit
in the dynamics of the error term, for example
%
\begin{align*}
  y_t &=  \beta + u_t \\
  u_t &= \rho u_{t-1} + \epsilon_t
\end{align*}
%
which implies that
%
\[
y_t = (1-\rho) \beta + \rho y_{t-1} + \epsilon_t
\]

Suppose we want to forecast $y$ for period $s$ using a dynamic model,
say (\ref{eq:ar1}) for example.  If we have data on $y$ available for
period $s-1$ we could form a fitted value in the usual way: $\hat{y}_s
= \hat{\alpha}_0 + \hat{\alpha}_1 y_{s-1}$.  But suppose that data are
available only up to $s-2$.  In that case we can apply the chain rule
of forecasting:
%
\begin{align*}
  \hat{y}_{s-1} &= \hat{\alpha}_0 + \hat{\alpha}_1 y_{s-2} \\
  \hat{y}_{s} &= \hat{\alpha}_0 + \hat{\alpha}_1 \hat{y}_{s-1}
\end{align*}
%
This is what is called a dynamic forecast.  A static forecast, on the
other hand, is simply a fitted value (even if it happens to be computed
out-of-sample).

\subsection{Printing, displaying, and saving forecasts}

When working from the GUI, the way to perform and access forecasts is to
first estimate a model with some inherently dynamic features, and then 
in the model window navigate to the Forecasts entry in the Analysis 
menu. If some out-of-sample observations are already available (see 
above) a dialog window is presented where the discussed forecasting 
options can be chosen by pointing and clicking. Executing the forecasts
then automatically yields two result windows: one with a time-series
plot of the forecasts along with their confidence bands (if those were
chosen), and another one with tabular output.

The produced plot can be saved to the current session or exported like
any other plot in gretl by right-clicking. Notice that in the textual
result window there is a ``+'' button at the top which offers to save
the point forecasts and their standard errors as new series to the
active dataset. 

In a command line context the \cmd{fcast} command automatically prints 
out the tables with the produced forecasts, their standard errors, and 
associated confidence intervals---unless you wish to suppress this 
verbose output with the options \verb|--stats-only| or \verb|--quiet|. 
The former option restricts output to the forecast evaluation statistics
as explained in the next section; the latter option silences output 
altogether. Another accepted syntax variant is to supply the name of a
new series for the point forecasts after the \cmd{fcast} command, as for
example in \verb|fcast Yfc --out-of-sample|. At the same time this also
suppresses printout. 

Accessing and saving the produced forecast time series along with the 
estimated standard errors also works through 
the \dollar{fcast} and \dollar{fcse} accessors available after 
\cmd{fcast} execution. These return vectors as gretl matrix objects, not
series, so if you want to add the results to the dataset in this way you
would have to set the active sample to the forecast range first. (You 
can of course first access and store the matrices and then later after 
resetting the sample assign them to series.) Note that the estimated 
standard errors do not incorporate parameter uncertainty in the case
of dynamic models.

But if you want to create forecast plots within a
script the relevant option already has to be appended to the \cmd{fcast}
command. As explained in the 
command reference, specify \verb|--plot=<filename>| (without the < > 
symbols) to save the plot file directly to disc, namely by default to 
the active working directory if no full path is specified.\footnote{%
Being a single plot, this is currently not available
for forecasts based on multiple equation systems. If the path contains
spaces it must be enclosed in quotes.} 

\section{Univariate forecast evaluation statistics}
\label{sec:fcast-stats}

Let $y_t$ be the value of a variable of interest at time $t$ and let
$f_t$ be a forecast of $y_t$.  We define the forecast error as
$e_t = y_t - f_t$.  Given a series of $T$ observations and associated
forecasts we can construct several measures of the overall accuracy of
the forecasts.  Some commonly used measures are the Mean Error (ME),
Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean
Percentage Error (MPE) and Mean Absolute Percentage Error (MAPE).
These are defined as follows.
%
\[ {\rm ME} = \frac{1}{T} \sum_{t=1}^T e_t \qquad 
   {\rm RMSE} = \sqrt{\frac{1}{T} \sum_{t=1}^T e_t^2} \qquad 
   {\rm MAE} = \frac{1}{T} \sum_{t=1}^T |e_t|
\] 
%
\[ {\rm MPE} = \frac{1}{T} \sum_{t=1}^T 100\, \frac{e_t}{y_t} \qquad
   {\rm MAPE} = \frac{1}{T} \sum_{t=1}^T 100\, \left|\frac{e_t}{y_t}\right| 
\]
%
A further relevant statistic is Theil's $U$ \citep{theil66}, defined as
the positive square root of
%
\[ 
U^2 = \frac{1}{T}
     \sum_{t=1}^{T-1} \left(\frac{f_{t+1} - y_{t+1}}{y_t}\right)^2
     \cdot \left[
     \frac{1}{T} \sum_{t=1}^{T-1} 
        \left(\frac{y_{t+1} - y_t}{y_t}\right)^2 \right]^{-1}
\]

The more accurate the forecasts, the lower the value of Theil's $U$,
which has a minimum of 0.\footnote{This statistic is sometimes called
  $U_2$, to distinguish it from a related but different $U$ defined in
  an earlier work by \cite{theil61}.  It seems to be generally accepted
  that the later version of Theil's $U$ is a superior statistic, so we
  ignore the earlier version here.} This measure can be interpreted as
the ratio of the RMSE of the proposed forecasting model to the RMSE of
a na\"ive model which simply predicts $y_{t+1} = y_t$ for all $t$.
The na\"ive model yields $U = 1$; values less than 1 indicate an
improvement relative to this benchmark and values greater than 1 a
deterioration.

In addition, Theil (\citeyear{theil66}, pp.\ 33--36) proposed a
decomposition of the MSE which can be useful in evaluating a set of
forecasts.  He showed that the MSE could be broken down into three
non-negative components as follows
%
\[
{\rm MSE} = \left(\bar{f}-\bar{y}\right)^2 + 
  \left(s_f - rs_y\right)^2 + 
  \left(1-r^2\right) s_y^2
\]
%
where $\bar{f}$ and $\bar{y}$ are the sample means of the forecasts
and the observations, $s_f$ and $s_y$ are the respective standard
deviations (using $T$ in the denominator), and $r$ is the sample
correlation between $y$ and $f$.  Dividing through by MSE we get
%
\begin{equation}
\label{eq:theil}
\frac{\left(\bar{f}-\bar{y}\right)^2}{\rm MSE} +
\frac{\left(s_f - rs_y\right)^2}{\rm MSE} + 
\frac{\left(1-r^2\right) s_y^2}{\rm MSE} = 1
\end{equation}
%
Theil labeled the three terms on the left-hand side of
(\ref{eq:theil}) the bias proportion ($U^M$), regression proportion
($U^R$) and disturbance proportion ($U^D$), respectively. If $y$ and
$f$ represent the in-sample observations of the dependent variable and
the fitted values from a linear regression then the first two
components, $U^M$ and $U^R$, will be zero (apart from rounding error),
and the entire MSE will be accounted for by the unsystematic part,
$U^D$.  In the case of out-of-sample prediction, however (or
``prediction'' over a sub-sample of the data used in the regression),
$U^M$ and $U^R$ are not necessarily close to zero, although this is a
desirable property for a forecast to have. $U^M$ differs from zero if
and only if the mean of the forecasts differs from the mean of the
realizations, and $U^R$ is non-zero if and only if the slope of a
simple regression of the realizations on the forecasts differs from
1.

The above-mentioned statistics are printed as part of the output of
the \texttt{fcast} command.  They can also be retrieved in the form of
a column vector using the function \texttt{fcstats}, which takes two
series arguments corresponding to $y$ and $f$.  The vector returned is
%
\[
\left(
\begin{array}{lllllllll}
{\rm ME} & {\rm RMSE} & {\rm MAE} & {\rm MPE} & {\rm MAPE} &
U & U^M & U^R & U^D
\end{array}
\right)'
\]
%
(Note that the MSE is not included since it can easily be obtained
given the RMSE.)  The series given as arguments to \texttt{fcstats}
must not contain any missing values in the currently defined sample
range; use the \texttt{smpl} command to adjust the range if needed.

\section{Forecasts based on VAR models}
\label{sec:fcast-VAR}

The interface to perform forecasts from a VAR model is quite similar to 
the one for single equations. Let us start with a concrete and commented
script example in the command line context; the code:

\begin{code}
# open sample data file
open sw_ch14.gdt --quiet
# generate the "inflation" series
series INFL = 100 * sdiff(log(PUNEW))
# put last year aside for out-of-sample forecast
smpl ; -4
# estimate a 5-lag VAR
var 5 LHUR INFL --silent
# store fitted values (note: result is a 2-column matrix)
YH = $yhat
# perform out-of-sample forecast (both versions)
fcast LHUR --static --out-of-sample
# note that omission of the variable specification means "all" 
fcast --dynamic --out-of-sample
\end{code}
%$
yields
\begin{code}
 For 95% confidence intervals, t(140, 0.025) = 1.977

               LHUR    prediction    std. error        95% interval

1999:1     4.300000     4.335004     0.222784     3.894549 - 4.775460
1999:2     4.300000     4.243244     0.222784     3.802788 - 4.683699
1999:3     4.233333     4.290981     0.222784     3.850525 - 4.731436
1999:4     4.100000     4.178030     0.222784     3.737575 - 4.618486

  Forecast evaluation statistics

  Mean Error                       -0.028481
  Root Mean Squared Error           0.058861
  Mean Absolute Error               0.05686
  Mean Percentage Error            -0.68977
  Mean Absolute Percentage Error    1.3497
  Theil's U                         0.75027
  Bias proportion, UM               0.23414
  Regression proportion, UR         0.0081804
  Disturbance proportion, UD        0.75768


 For 95% confidence intervals, t(140, 0.025) = 1.977

               LHUR    prediction    std. error        95% interval

1999:1     4.300000     4.335004     0.222784     3.894549 - 4.775460
1999:2     4.300000     4.312724     0.401960     3.518028 - 5.107421
1999:3     4.233333     4.272764     0.539582     3.205982 - 5.339547
1999:4     4.100000     4.223213     0.642001     2.953943 - 5.492482

  Forecast evaluation statistics

  Mean Error                       -0.052593
  Root Mean Squared Error           0.067311
  Mean Absolute Error               0.052593
  Mean Percentage Error            -1.2616
  Mean Absolute Percentage Error    1.2616
  Theil's U                         0.87334
  Bias proportion, UM               0.61049
  Regression proportion, UR         0.29203
  Disturbance proportion, UD        0.097478

               INFL    prediction    std. error        95% interval

1999:1     1.651245     1.812250     0.431335     0.959479 - 2.665022
1999:2     2.048545     2.088185     0.777834     0.550366 - 3.626004
1999:3     2.298952     2.266445     1.075855     0.139423 - 4.393467
1999:4     2.604836     2.610037     1.409676    -0.176969 - 5.397043

  Forecast evaluation statistics

  Mean Error                       -0.043335
  Root Mean Squared Error           0.084525
  Mean Absolute Error               0.059588
  Mean Percentage Error            -2.6178
  Mean Absolute Percentage Error    3.3248
  Theil's U                         0.095932
  Bias proportion, UM               0.26285
  Regression proportion, UR         0.45311
  Disturbance proportion, UD        0.28404
\end{code}

One of the main differences is that specifying a variable name after the
\cmd{fcast} command does not mean to save something under that name, but 
now it serves to pick one of the $N$ variables of the VAR for printing
out the forecasts. That leaves only the \dollar{fcast} and \dollar{fcse}
accessors to obtain and save the produced forecasts---in this system 
case the returned matrix objects will have as many columns as equations.

In the GUI the relevant menu entry is again Forecasts in the Analysis
menu in the window of the estimated VAR model. Here the user must pick
the variable of interest, after which a dialog window with relevant
options is presented. As in the single-equation context a plot and a
textual output windows are created. Again, forecast series can be
added to the dataset through the ``+'' button, and the plot can be
saved or exported.

\subsection{Special VAR cases: exogenous variables, cointegration}

It may be worth noting that when a VAR is specified with additional
(non-deterministic) exogenous regressors a similar issue as with single
equations arises: the forecast is conditional and requires some
assumptions about the development of those regressors out of sample.
 As before, these values
can be easily filled in after the dataset has been extended with the
observations for the forecasting sample, but naturally only the user,
not gretl, can and must decide what those values should be. This 
includes hand-crafted deterministic variables like shift dummies; but
on the other hand standard deterministic terms like trends and
seasonals will be extrapolated by gretl automatically.

Using a cointegrated VAR model with gretl's \cmd{vecm} command does not
change the way a forecast is obtained afterwards. The VECM can be 
internally represented as a VAR (in levels) that automatically contains
the reduced-rank restrictions of cointegration, and this VAR form is
then used to calculate the forecasts. Providing forecast standard errors
and the associated confidence bands is also straightforward since only
the innovation uncertainty is captured in those. This ease of use also
carries over to the situation when a VECM with additional exogenous
terms is used for forecasting---provided that future values of
the exogenous variables are specified, of course.   

\section{Forecasting from simultaneous systems}
\label{sec:fcast-system}

To be interesting for a forecasting application, a
simultaneous-equation system must be dynamic, including some lags of
endogenous variables as regressors. Otherwise we would be conducting a
scenario analysis purely conditional on assumed exogenous
developments. For the following discussion we therefore presuppose
that we are dealing with such a dynamic system. Then the difference
between such a model set up with gretl's \cmd{system} block and a VAR
system concerns mainly two aspects: First, a VAR model is already
given as a so-called reduced form and as such is ready to be used for
forward simulation a.k.a.\ forecasting. In contrast, a simultaneous
system can come in a structural form with some contemporaneous
endogenous variables as regressors in the equations; the future values
of those regressors are unknown, however. Second, a plain VAR is
estimated by OLS, whereas a simultaneous system can be estimated with
different methods for reasons of efficiency.

Neither of these differences present any deep challenge for forecasting,
however.

\begin{itemize}
\item As explained at the end of the previous chapter on multivariate
  models (see the subsection titled ``Structural and reduced forms''),
  it is easy to obtain the reduced form of any such simultaneous
  equation system. This reduced form is used by gretl to simulate the
  system forward in time, just as with a VAR model. The slight
  complication for computing the forecast variances is merely that the
  estimated error term $\epsilon_t$ from the structural form must be
  mapped to the reduced-form innovations $v_t$ using the (inverse of
  the) estimated structural relations matrix $\Gamma$. This is
  automatically taken into account.

\item The estimation method through which the coefficient values of
  the system are determined does not matter for forecasting. The
  prediction algorithm can simply take these point estimates as given,
  use these for calculating the associated reduced form, and use that
  representation to iterate the model forward over the desired
  forecasting horizon. It should nonetheless be obvious that different
  estimators entail different forecast values.
\end{itemize} 

As a consequence of these considerations, the way to handle forecasts
from simultaneous systems in gretl is exactly as discussed before in the
context of VARs (possibly with exogenous regressors). This applies
to the command-line interface as well as the GUI.


    
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide"
%%% End: 
