\chapter{Cointegration and Vector Error Correction Models}
\label{chap:vecm}

\section{Introduction}
\label{sec:VECM-intro}

The twin concepts of cointegration and error correction have drawn a
good deal of attention in macroeconometrics over recent years.  The
attraction of the Vector Error Correction Model (VECM) is that it
allows the researcher to embed a representation of economic
equilibrium relationships within a relatively rich time-series
specification.  This approach overcomes the old dichotomy between (a)
structural models that faithfully represented macroeconomic theory but
failed to fit the data, and (b) time-series models that were
accurately tailored to the data but difficult if not impossible to
interpret in economic terms.

The basic idea of cointegration relates closely to the concept of unit
roots (see section~\ref{sec:uroot}).  Suppose we have a set of
macroeconomic variables of interest, and we find we cannot reject the
hypothesis that these variables, considered individually, are
non-stationary.  Specifically, suppose we judge that the
variables are individually integrated of order 1, or I(1).  That is,
while they are non-stationary in their levels, their first differences
are stationary.  Given the statistical problems associated with the
analysis of non-stationary data (for example, the threat of spurious
regression), the traditional approach in this case was to take first
differences of all the variables before proceeding with the analysis.

But this can result in the loss of important information.  It may be
that while the variables in question are I(1) when taken individually,
there exists a linear combination of the variables that is stationary
without differencing, or I(0).  (There could be more than one such
linear combination.)  That is, while the ensemble of variables may be
``free to wander'' over time, nonetheless the variables are ``tied
together'' in certain ways.  And it may be possible to interpret these
ties, or \emph{cointegrating vectors}, as representing equilibrium
conditions.

For example, suppose we find that money stock, $M$, the price level,
$P$, the nominal interest rate, $R$, and output, $Y$, are all I(1).
According to standard theories of the demand for money, we would
nonetheless expect there to be an equilibrium relationship between
real balances, interest rate and output; for example
\[
m - p = \gamma_0 + \gamma_1 y + \gamma_2 r \qquad \gamma_1 > 0,
\gamma_2 < 0
\]
where lower-case variable names denote logs.  In equilibrium, then,
\[
m - p - \gamma_1 y - \gamma_2 r = \gamma_0
\]
Realistically, we should not expect this condition to be satisfied
each period.  We need to allow for the possibility of short-run
disequilibrium.  But if the system moves back towards equilibrium
following a disturbance, it follows that the vector $x = (m, p, y,
r)'$ is bound by a cointegrating vector $\beta = (\beta_1, \beta_2,
\beta_3, \beta_4)$, such that $\beta x$ is stationary (with a mean of
$\gamma_0$).  Furthermore, if equilibrium is correctly characterized
by the simple model above, we have $\beta_2 = -\beta_1$, $\beta_3 < 0$
and $\beta_4 > 0$.  These things are testable within the context of
cointegration analysis.

There are typically three steps in this sort of analysis:
\begin{enumerate}
\item Test to determine the number of cointegrating vectors, the 
  \emph{cointegrating rank} of the system.
\item Estimate a VECM with the appropriate rank, but subject to no
  further restrictions.
\item Probe the interpretation of the cointegrating vectors as
  equilibrium conditions by means of restrictions on the elements
  of these vectors.
\end{enumerate}

The following sections expand on each of these points, giving further
econometric details and explaining how to implement the analysis using
\app{gretl}.


\section{Vector Error Correction Models as representation of a
  cointegrated system}
\label{sec:VECM-rep}

Consider a VAR of order $p$ with a deterministic part given by $\mu_t$
(typically, a polynomial in time). One can write the $n$-variate
process $y_t$ as
\begin{equation}
  \label{eq:VECM-VAR}
  y_t = \mu_t + A_1 y_{t-1} + A_2 y_{t-2} + \cdots + A_p y_{t-p} +
  \epsilon_t 
\end{equation}
But since $y_t \equiv y_{t-1} - \Delta y_t$ and $y_{t-i} \equiv
y_{t-1} - (\Delta y_{t-1} + \Delta y_{t-2} + \cdots + \Delta
y_{t-i+1})$, we can re-write the above as
\begin{equation}
  \label{eq:VECM}
  \Delta y_t = \mu_t + \Pi y_{t-1} + \sum_{i=1}^p \Gamma_i \Delta
  y_{t-i} + \epsilon_t ,
\end{equation}
where $\Pi = \sum_{i=1}^p A_i$ and $\Gamma_k = -\sum_{i=k}^p A_i$.
This is the VECM representation of (\ref{eq:VECM-VAR}).

The interpretation of (\ref{eq:VECM}) depends crucially on $r$, the rank of
the matrix $\Pi$.
\begin{itemize}
\item If $r = 0$, the processes are all I(1).
\item If $r = n$, then $\Pi$ is invertible and the processes are all I(0).
\item In between, $\Pi$ can be written as $\alpha \beta'$ and you have
  cointegration. In this case, $y_t$ is I(1), but the combination $z_t
  = \beta'y_t$ is I(0). If, for example, $r=1$ and the first element of
  $\beta$ was $-1$, then one could write $z_t = -y_{1,t} + \beta_2
  y_{2,t} + \cdots + \beta_n y_{n,t}$, which is equivalent to saying
  that
  \[
    y_{1_t} = \beta_2 y_{2,t} + \cdots + \beta_n y_{n,t} 
  \]
  is a long-run equilibrium relationship: the deviations $z_t$
  may not be 0 but they are stationary. In this case, (\ref{eq:VECM})
  can be written as 
  \begin{equation}
    \label{eq:VECMab}
    \Delta y_t = \mu_t + \alpha \beta' y_{t-1} + \sum_{i=1}^p \Gamma_i 
    \Delta y_{t-i} + \epsilon_t ,
  \end{equation}
  and estimation is carried out on all parameters simultaneously.
\end{itemize}

The rank of $\Pi$ is investigated by computing the eigenvalues of a
closely related matrix (call it $M$) whose rank is the same as $\Pi$:
however, $M$ is by construction symmetric and positive semidefinite.
As a consequence, all its eigenvalues are real and non-negative; tests
on the rank of $\Pi$ can therefore be carried out by testing how many
eigenvalues of $M$ are 0.

If all the eigenvalues are significantly different from 0, then all the
processes are stationary. If, on the contrary, there is at least one
zero eigenvalue, then the $y_t$ process is integrated, although some
linear combination $\beta'y_t$ might be stationary. On the other
extreme, if no eigenvalues are significantly different from 0, then not
only the process $y_t$ is non-stationary, but the same holds for any
linear combination $\beta'y_t$; in other words, no cointegration
occurs.

Estimation typically proceeds in two stages: first, a sequence of
tests is run to determine $r$, the cointegration rank. Then, for a
given rank the parameters in equation (\ref{eq:VECMab}) are estimated.
The two commands that \app{gretl} offers for estimating these systems
are \texttt{coint2} and \texttt{vecm}, respectively. 

The syntax for \texttt{coint2} is 
\begin{code}
  coint2 p ylist [ ; xlist ]
\end{code}
where \texttt{p} is the number of lags in (\ref{eq:VECM-VAR}),
\texttt{ylist} is a list containing the $y_t$ variables and
\texttt{xlist} is an optional list of exogenous variables.

The syntax for \texttt{vecm} is 
\begin{code}
  vecm p r ylist [ ; xlist [; zlist] ]
\end{code}
where \texttt{p} is the number of lags in (\ref{eq:VECM-VAR}),
\texttt{r} is the cointegration rank, \texttt{ylist} is a list
containing the $y_t$ variables, \texttt{xlist} is an optional list of
exogenous variables and \texttt{zlist} is an optional list of
exogenous variables which are assumed to enter the cointegration
relationships.

Both commands can be given specific options to handle the treatment of
the deterministic kernel $\mu_t$. These are illustrated in the
following section.

\section{Interpretation of the deterministic kernel}
\label{sec:coint-5cases}

Several important inferential aspect of cointegrated systems depend on
what hypotheses one is willing to make on the deterministic terms,
which leads to the famous ``five cases.''

In equation (\ref{eq:VECM}), the term $\mu_t$ is usually understood to
take the form
\[
  \mu_t = \mu_0 + \mu_1 \cdot t .
\]
In order to have the model mimic as closely as possible the features
of the observed data, there is one preliminary question to settle. Do
the data appear to follow a deterministic trend? And if so, is it
linear or quadratic?

Once this is established, one should impose restrictions on $\mu_0$
and $\mu_1$ that are consistent with this choice. For example, suppose
that the data do not exhibit a discernible trend. This means
that $\Delta y_t$ is on average zero, so it is reasonable to assume
that its expected value is also zero. Write equation (\ref{eq:VECM})
as

\begin{equation}
  \label{eq:VECM-poly}
  \Gamma(L) \Delta y_t = \mu_0 + \mu_1 \cdot t + \alpha z_{t-1} +
  \epsilon_t ,
\end{equation}
where $z_{t} = \beta' y_{t}$ is assumed to be stationary and therefore
to possess finite moments. Taking unconditional expectations, we get
\[ 
  0 = \mu_0 + \mu_1 \cdot t + \alpha m_z .
\]
Since the left-hand side does not depend on $t$, the restriction
$\mu_1 = 0$ is a safe bet. As for $\mu_0$, there are just two ways to
make the above expression true: either $\mu_0 = 0$ or, less
restrictively, $\mu_0$ happens to be exactly equal to $-\alpha m_z$.
This possibility is less restrictive in that the vector $\mu_0$ may be
non-zero, but it is constrained to be a linear combination of the
columns of $\alpha$. But if this is the case, $\mu_0$ can be written
as $\alpha \cdot c$, and one may write (\ref{eq:VECM-poly}) as
\[
  \Gamma(L) \Delta y_t = \alpha \left[ \beta' \quad c \right] 
  \left[ \begin{array}{c} y_{t-1} \\ 1 \end{array} \right]  
  + \epsilon_t ,
\]
and the long-run relationship contains an intercept. This type of
restriction is usually written
\[
  \alpha'_{\perp} \mu_0 = 0 ,
\]
where $\alpha_{\perp}$ is the left null space of the matrix $\alpha$.

An intuitive understanding of the issue can be gained by means of a
simple example. Consider a series $x_t$ which behaves as follows
%      
\[ x_t = m + x_{t-1} + \varepsilon_t \] 
%
where $m$ is a real number and $\varepsilon_t$ is a white noise
process. As is easy to show, $x_t$ is a random walk which fluctuates
around a deterministic trend with slope $m$. In the special case $m$ =
0, the deterministic trend disappears and $x_t$ is a pure random walk.
    
Consider now another process $y_t$, defined by
%      
\[ y_t = k + x_t + u_t \] 
%
where, again, $k$ is a real number and $u_t$ is a white noise process.
Since $u_t$ is stationary by definition, $x_t$ and $y_t$ cointegrate:
that is, their difference
%      
\[ z_t = y_t - x_t = k + u_t \]
%	
is a stationary process. For $k$ = 0, $z_t$ is simple zero-mean white
noise, whereas for $k$ $\ne$ 0 the process $z_t$ is white noise with a
non-zero mean.
  
After some simple substitutions, the two equations above can be
represented jointly as a VAR(1) system
%      
\[ \left[ \begin{array}{c} y_t \\ x_t \end{array} \right] = \left[
  \begin{array}{c} k + m \\ m \end{array} \right] + \left[
  \begin{array}{rr} 0 & 1 \\ 0 & 1 \end{array} \right] \left[
  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \left[
  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array}
\right] \]
%	
or in VECM form
%      
\begin{eqnarray*}
  \left[  \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{rr} -1 & 1 \\ 0 & 0 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = & 
  \left[  \begin{array}{c} k + m \\ m \end{array} \right] +
  \left[  \begin{array}{r} -1 \\ 0 \end{array} \right]
  \left[  \begin{array}{rr} 1 & -1 \end{array} \right] 
  \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + 
  \left[  \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t \end{array} \right] = \\
  & = & 
  \mu_0 + \alpha \beta^{\prime} \left[  \begin{array}{c} y_{t-1} \\ x_{t-1} \end{array} \right] + \eta_t = 
  \mu_0 + \alpha z_{t-1} + \eta_t ,
\end{eqnarray*}
%	
where $\beta$ is the cointegration vector and $\alpha$ is the
``loadings'' or ``adjustments'' vector.
     
We are now ready to consider three possible cases:
    
\begin{enumerate}
\item $m$ $\ne$ 0: In this case $x_t$ is trended, as we just saw; it
  follows that $y_t$ also follows a linear trend because on average it
  keeps at a distance $k$ from $x_t$. The vector $\mu_0$ is
  unrestricted.  This case is the default for gretl's \cmd{vecm}
  command.
	
\item $m$ = 0 and $k$ $\ne$ 0: In this case, $x_t$ is not trended and
  as a consequence neither is $y_t$. However, the mean distance
  between $y_t$ and $x_t$ is non-zero. The vector
  $\mu_0$ is given by
%	  
  \[
  \mu_0 = \left[ \begin{array}{c} k \\ 0 \end{array} \right]
  \]
%	    
  which is not null and therefore the VECM shown above does have a
  constant term. The constant, however, is subject to the restriction
  that its second element must be 0. More generally,
  $\mu_0$ is a multiple of the vector $\alpha$. Note
  that the VECM could also be written as
%	  
  \[
  \left[ \begin{array}{c} \Delta y_t \\ \Delta x_t \end{array} \right]
  = \left[ \begin{array}{r} -1 \\ 0 \end{array} \right] \left[
    \begin{array}{rrr} 1 & -1 & -k \end{array} \right] \left[
    \begin{array}{c} y_{t-1} \\ x_{t-1} \\ 1 \end{array} \right] +
  \left[ \begin{array}{c} u_t + \varepsilon_t \\ \varepsilon_t
    \end{array} \right]
  \]
%	   
  which incorporates the intercept into the cointegration vector. This
  is known as the ``restricted constant'' case.
	
\item $m$ = 0 and $k$ = 0: This case is the most restrictive: clearly,
  neither $x_t$ nor $y_t$ are trended, and the mean distance between
  them is zero. The vector $\mu_0$ is also 0, which explains why this
  case is referred to as ``no constant.''
	
\end{enumerate}

In most cases, the choice between the three possibilities is based on
a mix of empirical observation and economic reasoning. If the
variables under consideration seem to follow a linear trend then we
should not place any restriction on the intercept. Otherwise, the
question arises of whether it makes sense to specify a cointegration
relationship which includes a non-zero intercept. One example where
this is appropriate is the relationship between two interest rates:
generally these are not trended, but the VAR might still have an
intercept because the difference between the two (the ``interest rate
spread'') might be stationary around a non-zero mean (for example,
because of a risk or liquidity premium).
    
The previous example can be generalized in three directions:
    
\begin{enumerate}
\item If a VAR of order greater than 1 is considered, the algebra gets
  more convoluted but the conclusions are identical.
\item If the VAR includes more than two endogenous variables the
  cointegration rank $r$ can be greater than 1. In this case, $\alpha$
  is a matrix with $r$ columns, and the case with restricted constant
  entails the restriction that $\mu_0$ should be some linear
  combination of the columns of $\alpha$.
\item If a linear trend is included in the model, the deterministic
  part of the VAR becomes $\mu_0 + \mu_1 t$. The reasoning is
  practically the same as above except that the focus now centers on
  $\mu_1$ rather than $\mu_0$.  The counterpart to the ``restricted
  constant'' case discussed above is a ``restricted trend'' case, such
  that the cointegration relationships include a trend but the first
  differences of the variables in question do not.  In the case of an
  unrestricted trend, the trend appears in both the cointegration
  relationships and the first differences, which corresponds to the
  presence of a quadratic trend in the variables themselves (in
  levels).
\end{enumerate}

In order to accommodate the five cases, \app{gretl} provides the
following options to the \texttt{coint2} and \texttt{vecm} commands:
\begin{center}
  \begin{tabular}{cc}
    \hline
    $\mu_t$ & command option \\
    \hline
    0 & \verb|--nc| \\
    $\mu_0, \alpha_{\perp}'\mu_0 = 0 $ &  \verb|--rc| \\
    $\mu_0$ &  default \\
    $\mu_0 + \mu_1 t , \alpha_{\perp}'\mu_1 = 0$ &  \verb|--crt| \\
    $\mu_0 + \mu_1 t$ &  \verb|--ct| \\
    \hline
  \end{tabular}
\end{center}
Note that for this command the above options are mutually exclusive.
In addition, you have the option of using the \verb|--seasonal|
options, for augmenting $\mu_t$ with centered seasonal dummies.  In
each case, p-values are computed via the approximations by Doornik
(1998).

\section{The Johansen cointegration test}
\label{sec:johansen-test}

The two Johansen tests for cointegration are used to establish the rank of
$\beta$; in other words, how many cointegration vectors the system
has.  These are the ``$\lambda$-max'' test, for hypotheses
on individual eigenvalues, and the ``trace'' test, for joint
hypotheses.  The \app{gretl} command \cmd{coint2} performs these two
tests.  

As in the ADF test, the asymptotic distribution of the tests varies
with the deterministic kernel $\mu_t$ one includes in the VAR (see
section \ref{sec:coint-5cases} above). The following code uses the
\cmd{denmark} database, supplied with \app{gretl}, to replicate
Johansen's example found in his 1995 book.
%
\begin{code}
open denmark
coint2 2 LRM LRY IBO IDE --rc --seasonal
\end{code}
%
In this case, the vector $y_t$ in equation (\ref{eq:VECM})
comprises the four variables \cmd{LRM}, \cmd{LRY}, \cmd{IBO},
\cmd{IDE}. The number of lags equals $p$ in (\ref{eq:VECM}) plus
one. Part of the output is reported below:

\begin{center}
\begin{code}
Johansen test:
Number of equations = 4
Lag order = 2
Estimation period: 1974:3 - 1987:3 (T = 53)

Case 2: Restricted constant
Rank Eigenvalue Trace test p-value   Lmax test  p-value
   0    0.43317     49.144 [0.1284]     30.087 [0.0286]
   1    0.17758     19.057 [0.7833]     10.362 [0.8017]
   2    0.11279     8.6950 [0.7645]     6.3427 [0.7483]
   3   0.043411     2.3522 [0.7088]     2.3522 [0.7076]
\end{code}
\end{center}

Since both the trace and $\lambda$-max accept the null hypothesis that
the smallest eigenvalue is in fact 0, we may conclude that the series
are in fact non-stationary. However, some linear combination may be
$I(0)$, as indicated by the rejection of the $\lambda$-max of the
hypothesis that the rank of $\Pi$ is 0 (the trace test gives less
clear-cut evidence for this).

\section{Identification of the cointegration vectors}
\label{sec:johansen-ident}

The core problem in the estimation of equation (\ref{eq:VECM}) is to
find an estimate of $\Pi$ that has by construction rank $r$, so it can
be written as $\Pi = \alpha \beta'$, where $\beta$ is the matrix
containing the cointegration vectors.

Without further indications, the problem has multiple solutions (in
fact, infinitely many). The parameters $\alpha$ and $\beta$ are
under-identified: if all columns of $\beta$ are cointegration vectors,
then any arbitrary linear combinations of those columns is a
cointegration vector too. In order to find a unique solution, it is
necessary to impose some restrictions on $\alpha$ and/or $\beta$. It
can be shown that the minimum number of restrictions that is necessary
to guarantee identification is $r^2$.

The method default method that \app{gretl} uses is known as the
``Phillips normalization''. The starting point is writing $\beta$ in
partitioned form as in
\[
  \beta = \left[
    \begin{array}{c} \beta_1 \\ \beta_2  \end{array}
    \right] ,
\]
where $\beta_1$ is an $r \times r$ matrix and  $\beta_2$ is $(n-r)
\times r$. Assuming that $\beta_1$ has full rank, $\beta$ can be
post-multiplied by $\beta_1^{-1}$, giving
\[
  \hat{\beta} = \left[
    \begin{array}{c} I \\ \beta_2 \beta_1^{-1}  \end{array}
    \right] =
    \left[
    \begin{array}{c} I \\ \hat{\beta_2} \end{array}
  \right]  ,
\]

The coefficients that \app{gretl} produces are $\hat{\beta}$, with
$\hat{\beta_2}$ known as the matrix of unrestricted coefficients. In
terms of the underlying equilibrium relationship, the Phillips
normalisation expresses the system of $r$ equilibrium relations as
\begin{eqnarray*}
  y_{1,t} & = & \beta_{1,r+1} y_{r+1,t} + \ldots + \beta_{1,n} y_{n,t} \\
  y_{2,t} & = & \beta_{2,r+1} y_{r+1,t} + \ldots + \beta_{2,n} y_{n,t} \\
  & \vdots & \\
  y_{r,t} & = & \beta_{r,r+1} y_{r+1,t} + \ldots + \beta_{r,n} y_{r,t} 
\end{eqnarray*}
wher the first $r$ variables are expressed as functions of the
remaining $n-r$.

Although this representation ensures that the statistical problem of
estimating $\beta$ is solved, the resulting equilibrium relationships
may be difficult to interpret. In this case, the user may want to
achieve identification by specifying manually the system of $r^2$
constraints that \app{gretl} uses to produce an estimate of $\beta$.

As an example, consider the money demand system presented in section
9.6 of Verbeek (2004). The estimation of the matrix $\beta$ can be performed via
the commands
\begin{code}
  open money.gdt 
  smpl 1954:1 1994:4 
  vecm 6 2 m infl cpr y tbr --rc
\end{code}
and the relevant portion of the output reads
\begin{code}
Maximum likelihood estimates, observations 1954:1-1994:4 (T = 164)
Cointegration rank = 2
Case 2: Restricted constant

beta (cointegrating vectors, standard errors in parentheses)

m           1.0000       0.0000 
           (0.0000)     (0.0000) 
infl        0.0000       1.0000 
           (0.0000)     (0.0000) 
cpr        0.56108      -24.367 
          (0.10638)     (4.2113) 
y         -0.40446     -0.91166 
          (0.10277)     (4.0683) 
tbr       -0.54293       24.786 
          (0.10962)     (4.3394) 
const      -3.7483       16.751 
          (0.78082)     (30.909) 
\end{code}
Interpretation of the coefficients of the cointegration matrix $\beta$
would be easier if a meaning could be attached to each of its
columns. This is possible by hypothesizing the existence of two
long-run relationships: a money demand equation
\begin{equation}
  \label{eq:verbeek-mondem}
  m = \beta_1 \pi + \beta_2 y + \beta_3 tbr
\end{equation}
and a risk premium equation
\begin{equation}
  \label{eq:verbeek-premium}
  cpr = \beta_4 \pi + \beta_5 y + \beta_6 tbr ,
\end{equation}
which imply that the cointegration matrix can be normalized as
\[
  \beta = \left[
    \begin{array}{rr}
      -1 & 0 \\ \beta_1 & \beta_4 \\ 0 & -1 \\ \beta_2 & \beta_4
      \\ \beta_3 & \beta_6
    \end{array}
    \right]
\]

This renormalization can be accomplished by means of the
\texttt{restrict} command, to be given after the \texttt{vecm} command
or, in the graphical interface, by selecting the ``Test, Linear
Restrictions'' menu entry. The syntax for entering the restrictions
should be fairly obvious:
\begin{code}
restrict
  b[1,1] = -1
  b[1,3] = 0
  b[2,1] = 0
  b[2,3] = -1
end restrict
\end{code}
which produces

\begin{code}
Cointegrating vectors (standard errors in parentheses)

m          -1.0000       0.0000 
           (0.0000)     (0.0000) 
infl     -0.023026     0.041039 
        (0.0054666)   (0.027790) 
cpr         0.0000      -1.0000 
           (0.0000)     (0.0000) 
y          0.42545    -0.037414 
         (0.033718)    (0.17140) 
tbr      -0.027790       1.0172 
        (0.0045445)   (0.023102) 
const       3.3625      0.68744 
          (0.25318)     (1.2870) 
\end{code}


\section{Over-identifying restrictions on the cointegration vectors}
\label{sec:johansen-overid}

\textbf{To be written yet}

Example \ref{brand-cassola-script} replicates Table 4 in Brand and
Cassola (2004).

\begin{script}[htbp]
  \caption{Estimation a Money demand System}
  \label{brand-cassola-script}
\begin{scode}
open brand_cassola.gdt

# perform a few transformations

m_p = m_p*100
y = y*100
infl = infl/4
rs = rs/4
rl = rl/4

# replicate table 4, page 824

vecm 2 3 m_p infl rl rs y -q

restrict --full
  b[1,1] = 1
  b[1,2] = 0
  b[1,4] = 0

  b[2,1] = 0
  b[2,2] = 1
  b[2,4] = 0
  b[2,5] = 0

  b[3,1] = 0
  b[3,2] = 0
  b[3,3] = 1
  b[3,4] = -1
  b[3,5] = 0
end restrict
\end{scode}
%$
\end{script}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide"
%%% End: 
